---
title: PCA
date: 2019-03-20 20:51:27
categories: machine learning
tags: pac
mathjax: true
---

-----------------

输入：样本集 $D = \lbrace x_1, x_2, ... ,x_m\rbrace$;

​	    低维空间维度 $d'$.

过程：

1. 对所有样本进行centering中心化： $x_i \leftarrow x_i - \frac{1}{m}\sum_{i=1}^m x_i$;

2. 计算所有样本的协方差矩阵 $XX^T$;

3. 对协方差矩阵$XX^T$做特征值分解；

4. 取最大的 $d'$ 个特征值对应的特征向量 $w_1, w_2, ... , w_{d'}$.

输出：投影矩阵 $W=(w_1, w_2, ... , w_{d'})$.

-----------------

<!-- more -->

将维后低维空间的维度$d'$通常是由用户事先指定的

主成分分析法是一种数据转换的技术，当我们对一个物体进行衡量时，我们将其特征用向量$（a_1,a_2,a_3,…a_n）$进行表示，每一维都有其对应的variance（表示在其均值附近离散的程度）；其所有维的 variance 之和，我们叫做总的variance；我们对物体进行衡量时，往往其特征值之间是 correlated 的，比如我们测量飞行员时，有两个指标一个是飞行技术 $x_1$, 另一个是对飞行的喜好程度 $x_2$，这两者之间是有关联的，即correlated的。

​	我们进行PCA（主成分分析时），我们并没有改变维数，但是我们却做了如下变换，设新的特征为$（x_1,x_2,x_3...,x_n）$;

其中

1. $x_1​$ 的variance占总的variance比重最大；
2. 除去 $x_1$,$x_2$ 的variance占剩下的variance比重最大；
3. ....

依次类推；

​	最后，我们转换之后得到的 $(x_1,x_2,…x_n)$ 之间都是incorrelated，我们做PCA时，仅取$（x_1，x_2,....x_k）$来表示我们测量的物体，其中，$k$ 要小于 $n$。主成分的贡献率就是某主成分的**方差在全部方差中的比值**。这个值越大，表明该主成分综合$X_1$，$X_2$，…，$X_P$信息的能力越强。如果前k个主成分的贡献率达到85%，表明取前 $k​$ 个主成分基本包含了全部测量指标所具有的信息，这样既减少了变量的个数又方便于对实际问题的分析和研究。

​    **注意，当$（a_1,a_2,a_3,…a_n）$之间都是incorrelated时，我们就没有做PCA的必要了**。

[1].https://blog.csdn.net/guoxinian/article/details/50433014



对降维的语言描述:

- 已知:一个数据集 $D$ 记录(或者样本, 或input pattern) $x_i∈D$ 是 $d$ 维列向量.

- 目标:将每个 $x∈D$ 映射到另一个$p$维空间, $p<d$虽然等于也是可以的, 但没什么意义). 得到一个新的数据集 $Z$ , 对 $Z$ 的要求是**尽量保存 $D$ 中的有效信息**.

  

那么, 问题就来了. 如何将一个 $d$ 维向量映射成一个 $p$ 维向量? 答案是基变换. 然而基变换方式不是唯一的, **如何确保变换是最优的**? 这就由优化目标"**尽量保存原数据集中的信息**" 决定了: 最好的基变换能保存最多的信息. 注意了, 这里的比较都是在同一个 $p$ 下进行的, 也就是说, 参与竞争的基集(**basis set**)们, 都把 $d$ 维 $D$ 映射到了一个新的 $p$ 维 $Z$.

从**香农**Shannon的信息论角度考虑，**数据的差异越大，信息越丰富**。如果都是相同的东西，量再多，信息也没多少。PCA算法采用方差(variance)来度量信息量.

那么, 如何用variance来度量数据集$D$包含的信息量呢? 一个基(**basis**)一个基地衡量. **数据集在某个基上的投影值(也是在这个基上的坐标值)越分散, 方差越大, 这个基保留的信息也就越多**. 不严格的说, **一个基集保留下的信息量是每个基保留下的信息量的和.**

基于上面的理念, 或者说假设, 我们已经有一种可以有效地找出最优基集的方法了: **贪心算法**---先找出保留信息量最大的基向量, 然后是第二大的, 然后然后, 直到找满$p$个基向量.

[2].https://www.cnblogs.com/dengdan890730/p/5495078.html



