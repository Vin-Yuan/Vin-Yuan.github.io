<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Vin&#39;s Blog</title>
  
  
  <link href="http://yoursite.com/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2025-06-04T10:33:14.758Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Residual</title>
    <link href="http://yoursite.com/2025/06/04/residual/"/>
    <id>http://yoursite.com/2025/06/04/residual/</id>
    <published>2025-06-04T00:55:01.000Z</published>
    <updated>2025-06-04T10:33:14.758Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.youtube.com/watch?v=Q1JCrG1bJ-A"><img src="https://galaxy.ai/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FQ1JCrG1bJ-A%2Fmaxresdefault.jpg&amp;w=3840&amp;q=75" alt="residual explain"></a></p><p><a href="https://www.youtube.com/watch?v=Q1JCrG1bJ-A">residual explain</a><br>some notes from this video</p><p>神经网络初始化时，权重是随机的 —— 每一层的权重矩阵都是随机生成的。<br>前向传播时，输入数据经过每一层都会被随机的权重矩阵变换，换句话说：输入信号在每一层都被“打乱”一次。<br>如果层数很深（比如几十层），输入数据就会被这些随机变换一遍又一遍，到了最后一层时，输出结果几乎不再携带原始输入的“有效信息” —— 变成了一堆“随机激活”（noise）。<br>这就像把一个信号通过几十个带随机旋转的transpose处理之后，最后剩下的根本不知道是什么。<br>我们可以说：<strong>原始输入被“扰乱”成了随机噪声</strong>。这种情况下，模型的输出和输入几乎没有实际联系。<br>训练时，我们计算 loss，并进行反向传播（backpropagation）以更新权重。<br>反向传播的梯度来源于输出误差，但<strong>如果输出本身已经是“随机激活”</strong>，那这个误差根本不能反映输入的真实特征，所以它对靠后的几层的更新意义也不大。<br>在反向传播过程中，每一层的梯度也会被它的权重矩阵（也就是在前向传播时使用的那个）反向变换。因为这些矩阵是随机的，所以：<br>梯度回传到早期层时，已经<strong>被多层的随机变换“扰乱”</strong>，<strong>梯度本身也变得和数据无关了</strong>。<br>后面的层（靠近输出）的输入是随机的，因此即使我们对它们做了梯度更新，也是在优化一些“无意义的东西”——所以这个更新 <strong>“不是很有意义”</strong>（not very meaningful）。<br>早期层的输入其实还比较接近原始输入，但 <strong>梯度本身已经被“污染”了</strong>，所以即使这些层“想学”，也无法从错误中获得有效信息。<br>这就解释了<strong>为什么深层网络在训练初期进展缓慢</strong>，甚至基本不学习 —— 因为梯度下降没有清晰的方向，就像“在黑夜里瞎走”。  </p><blockquote><ul><li>对于<strong>后面的层</strong>，它们的输入已经像噪声，所以即使 loss 传回来，<strong>更新的目标本身就没什么意义</strong>。  </li><li>对于<strong>前面的层</strong>，它们的输入还比较“干净”，但传回来的梯度已经乱掉了，<strong>更新的方向也没有意义</strong>。  </li><li>所以，这些更新不是完全错误，而是<strong>无效、低效、方向性差</strong>，因此叫 <strong>“not very meaningful”</strong>。  </li></ul></blockquote><h2 id="gradient-和-weight的关系"><a href="#gradient-和-weight的关系" class="headerlink" title="gradient 和 weight的关系"></a>gradient 和 weight的关系</h2><p>在两层神经网络中，<strong>反向传播（Backpropagation）</strong> 的目的是计算损失函数关于每一层权重（weights）的梯度，用于更新权重。<br>下面步步说明梯度是如何与权重相关联的。</p><p>假设一个简单的两层神经网络结构：</p><h3 id="网络结构："><a href="#网络结构：" class="headerlink" title="网络结构："></a>网络结构：</h3><p>输入 → 第一层（Linear + Activation） → 第二层（Linear） → 输出（Loss）</p><ul><li>输入：$\mathbf{x} \in \mathbb{R}^d$</li><li>第一层权重：$\mathbf{W}_1 \in \mathbb{R}^{h \times d}$，偏置：$\mathbf{b}_1 \in \mathbb{R}^h$</li><li>激活函数：ReLU 或 Sigmoid（记为 $f$）</li><li>第二层权重：$\mathbf{W}_2 \in \mathbb{R}^{o \times h}$，偏置：$\mathbf{b}_2 \in \mathbb{R}^o$</li><li>输出层无激活（或直接用 MSE）</li></ul><span id="more"></span><h3 id="1-前向传播公式："><a href="#1-前向传播公式：" class="headerlink" title="1. 前向传播公式："></a>1. 前向传播公式：</h3><ol><li><p>第一层输出（隐层激活）：<br>$\mathbf{z}_1 = \mathbf{W}_1 \mathbf{x} + \mathbf{b}_1$<br>$\mathbf{a}_1 = f(\mathbf{z}_1)$</p></li><li><p>第二层输出（模型最终输出）：<br>$\mathbf{z}_2 = \mathbf{W}_2 \mathbf{a}_1 + \mathbf{b}_2$</p></li><li><p>损失函数（以 MSE 为例，标签为 $\mathbf{y}$）：<br>$L = \frac{1}{2} |\mathbf{z}_2 - \mathbf{y}|^2$</p></li></ol><hr><h3 id="2-反向传播计算梯度："><a href="#2-反向传播计算梯度：" class="headerlink" title="2. 反向传播计算梯度："></a>2. 反向传播计算梯度：</h3><p>目标是求 $\frac{\partial L}{\partial \mathbf{W}_2}$ 和 $\frac{\partial L}{\partial \mathbf{W}_1}$。</p><h4 id="第一步：从输出层反向传播"><a href="#第一步：从输出层反向传播" class="headerlink" title="第一步：从输出层反向传播"></a>第一步：从输出层反向传播</h4><p><strong>输出层梯度（loss 对 $\mathbf{z}_2$ 的导数）</strong><br>$\delta_2 = \frac{\partial L}{\partial \mathbf{z}_2} = \mathbf{z}_2 - \mathbf{y}$</p><p><strong>对第二层权重的梯度</strong><br>$\frac{\partial L}{\partial \mathbf{W}_2} = \delta_2 \cdot \mathbf{a}_1^T$</p><blockquote><p>这个公式说明：第二层权重的梯度是误差 $\delta_2$ 与前一层激活 $\mathbf{a}_1$ 的外积。通过式子可以理解到，误差被乘以了一个权重，那些<strong>对误差贡献比较大的激活单元</strong>所对应的<strong>weight</strong>会被更大程度的减小</p></blockquote><hr><h4 id="第二步：继续向前传播误差到第一层"><a href="#第二步：继续向前传播误差到第一层" class="headerlink" title="第二步：继续向前传播误差到第一层"></a>第二步：继续向前传播误差到第一层</h4><p><strong>传播误差到第一层</strong><br>$\delta_1 = \left(\mathbf{W}_2^T \delta_2\right) \odot f’(\mathbf{z}_1)$</p><blockquote><ul><li>$\odot$ 表示按元素相乘（Hadamard product）</li><li>$f’(\mathbf{z}_1)$ 是激活函数的导数（例如 ReLU 的导数是 0 或 1）</li></ul></blockquote><p><strong>对第一层权重的梯度</strong><br>$\frac{\partial L}{\partial \mathbf{W}_1} = \delta_1 \cdot \mathbf{x}^T$</p><hr><h3 id="3-总结：梯度与权重的关系"><a href="#3-总结：梯度与权重的关系" class="headerlink" title="3. 总结：梯度与权重的关系"></a>3. 总结：梯度与权重的关系</h3><div class="table-container"><table><thead><tr><th>权重</th><th>对应梯度表达式</th><th>梯度依赖于</th></tr></thead><tbody><tr><td>$\mathbf{W}_2$</td><td>$\frac{\partial L}{\partial \mathbf{W}_2} = \delta_2 \cdot \mathbf{a}_1^T$</td><td>当前层误差 $\delta_2$ 和前一层输出 $\mathbf{a}_1$</td></tr><tr><td>$\mathbf{W}_1$</td><td>$\frac{\partial L}{\partial \mathbf{W}_1} = \delta_1 \cdot \mathbf{x}^T$</td><td>当前层误差 $\delta_1$ 和输入 $\mathbf{x}$</td></tr></tbody></table></div><p>因此，<strong>每层权重的梯度取决于该层输出误差与前一层的输出（或输入）的乘积</strong>。<br>这个过程是反向传播的核心：误差从输出层一步步反传，每层的权重根据其对最终误差的贡献进行调整。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Q1JCrG1bJ-A&quot;&gt;&lt;img src=&quot;https://galaxy.ai/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FQ1JCrG1bJ-A%2Fmaxresdefault.jpg&amp;amp;w=3840&amp;amp;q=75&quot; alt=&quot;residual explain&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Q1JCrG1bJ-A&quot;&gt;residual explain&lt;/a&gt;&lt;br&gt;some notes from this video&lt;/p&gt;
&lt;p&gt;神经网络初始化时，权重是随机的 —— 每一层的权重矩阵都是随机生成的。&lt;br&gt;前向传播时，输入数据经过每一层都会被随机的权重矩阵变换，换句话说：输入信号在每一层都被“打乱”一次。&lt;br&gt;如果层数很深（比如几十层），输入数据就会被这些随机变换一遍又一遍，到了最后一层时，输出结果几乎不再携带原始输入的“有效信息” —— 变成了一堆“随机激活”（noise）。&lt;br&gt;这就像把一个信号通过几十个带随机旋转的transpose处理之后，最后剩下的根本不知道是什么。&lt;br&gt;我们可以说：&lt;strong&gt;原始输入被“扰乱”成了随机噪声&lt;/strong&gt;。这种情况下，模型的输出和输入几乎没有实际联系。&lt;br&gt;训练时，我们计算 loss，并进行反向传播（backpropagation）以更新权重。&lt;br&gt;反向传播的梯度来源于输出误差，但&lt;strong&gt;如果输出本身已经是“随机激活”&lt;/strong&gt;，那这个误差根本不能反映输入的真实特征，所以它对靠后的几层的更新意义也不大。&lt;br&gt;在反向传播过程中，每一层的梯度也会被它的权重矩阵（也就是在前向传播时使用的那个）反向变换。因为这些矩阵是随机的，所以：&lt;br&gt;梯度回传到早期层时，已经&lt;strong&gt;被多层的随机变换“扰乱”&lt;/strong&gt;，&lt;strong&gt;梯度本身也变得和数据无关了&lt;/strong&gt;。&lt;br&gt;后面的层（靠近输出）的输入是随机的，因此即使我们对它们做了梯度更新，也是在优化一些“无意义的东西”——所以这个更新 &lt;strong&gt;“不是很有意义”&lt;/strong&gt;（not very meaningful）。&lt;br&gt;早期层的输入其实还比较接近原始输入，但 &lt;strong&gt;梯度本身已经被“污染”了&lt;/strong&gt;，所以即使这些层“想学”，也无法从错误中获得有效信息。&lt;br&gt;这就解释了&lt;strong&gt;为什么深层网络在训练初期进展缓慢&lt;/strong&gt;，甚至基本不学习 —— 因为梯度下降没有清晰的方向，就像“在黑夜里瞎走”。  &lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;对于&lt;strong&gt;后面的层&lt;/strong&gt;，它们的输入已经像噪声，所以即使 loss 传回来，&lt;strong&gt;更新的目标本身就没什么意义&lt;/strong&gt;。  &lt;/li&gt;
&lt;li&gt;对于&lt;strong&gt;前面的层&lt;/strong&gt;，它们的输入还比较“干净”，但传回来的梯度已经乱掉了，&lt;strong&gt;更新的方向也没有意义&lt;/strong&gt;。  &lt;/li&gt;
&lt;li&gt;所以，这些更新不是完全错误，而是&lt;strong&gt;无效、低效、方向性差&lt;/strong&gt;，因此叫 &lt;strong&gt;“not very meaningful”&lt;/strong&gt;。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;gradient-和-weight的关系&quot;&gt;&lt;a href=&quot;#gradient-和-weight的关系&quot; class=&quot;headerlink&quot; title=&quot;gradient 和 weight的关系&quot;&gt;&lt;/a&gt;gradient 和 weight的关系&lt;/h2&gt;&lt;p&gt;在两层神经网络中，&lt;strong&gt;反向传播（Backpropagation）&lt;/strong&gt; 的目的是计算损失函数关于每一层权重（weights）的梯度，用于更新权重。&lt;br&gt;下面步步说明梯度是如何与权重相关联的。&lt;/p&gt;
&lt;p&gt;假设一个简单的两层神经网络结构：&lt;/p&gt;
&lt;h3 id=&quot;网络结构：&quot;&gt;&lt;a href=&quot;#网络结构：&quot; class=&quot;headerlink&quot; title=&quot;网络结构：&quot;&gt;&lt;/a&gt;网络结构：&lt;/h3&gt;&lt;p&gt;输入 → 第一层（Linear + Activation） → 第二层（Linear） → 输出（Loss）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入：$\mathbf{x} \in \mathbb{R}^d$&lt;/li&gt;
&lt;li&gt;第一层权重：$\mathbf{W}_1 \in \mathbb{R}^{h \times d}$，偏置：$\mathbf{b}_1 \in \mathbb{R}^h$&lt;/li&gt;
&lt;li&gt;激活函数：ReLU 或 Sigmoid（记为 $f$）&lt;/li&gt;
&lt;li&gt;第二层权重：$\mathbf{W}_2 \in \mathbb{R}^{o \times h}$，偏置：$\mathbf{b}_2 \in \mathbb{R}^o$&lt;/li&gt;
&lt;li&gt;输出层无激活（或直接用 MSE）&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="LLM, deeplearning" scheme="http://yoursite.com/categories/LLM-deeplearning/"/>
    
    
    <category term="LLM, deeplearning" scheme="http://yoursite.com/tags/LLM-deeplearning/"/>
    
  </entry>
  
  <entry>
    <title>Agent</title>
    <link href="http://yoursite.com/2025/06/03/Agent/"/>
    <id>http://yoursite.com/2025/06/03/Agent/</id>
    <published>2025-06-03T07:12:59.000Z</published>
    <updated>2025-06-05T08:20:36.913Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Bonus-架构图-现代-Function-Calling-Agent-流程"><a href="#Bonus-架构图-现代-Function-Calling-Agent-流程" class="headerlink" title="Bonus 架构图 (现代 Function Calling Agent 流程)"></a>Bonus 架构图 (现代 Function Calling Agent 流程)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">User Input</span><br><span class="line">   ↓</span><br><span class="line">Embedding Model ───────→ 语义索引 (FAISS / Qdrant / Weaviate)</span><br><span class="line">                             ↓</span><br><span class="line">                 Top-K Function Candidates</span><br><span class="line">                             ↓</span><br><span class="line">            Inject into Prompt <span class="keyword">as</span> JSON Schema</span><br><span class="line">                             ↓</span><br><span class="line">               LLM 生成 Function Call</span><br><span class="line">                             ↓</span><br><span class="line">          调用工具 / API + 结构校验 + 反馈</span><br></pre></td></tr></table></figure><h2 id="MCP-server-流程图"><a href="#MCP-server-流程图" class="headerlink" title="MCP server 流程图"></a>MCP server 流程图</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">               +-------------+</span><br><span class="line">               | MCP Client |</span><br><span class="line">               +------+-----+</span><br><span class="line">                      |</span><br><span class="line">                      | submit task / query result</span><br><span class="line">                      v</span><br><span class="line">               +------+------+</span><br><span class="line">               | MCP Server  |</span><br><span class="line">               +------+------+</span><br><span class="line">                      |</span><br><span class="line">       +--------------+---------------+</span><br><span class="line">       |                              |</span><br><span class="line">       v                              v</span><br><span class="line">+-------------+               +---------------+</span><br><span class="line">|   Agent 1   |               |    Agent 2    |</span><br><span class="line">+-------------+               +---------------+</span><br><span class="line">    |   ^                          |   ^</span><br><span class="line">    |   | Task Execution           |   | Task Execution</span><br><span class="line">    +---+--------------------------+---+</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Bonus-架构图-现代-Function-Calling-Agent-流程&quot;&gt;&lt;a href=&quot;#Bonus-架构图-现代-Function-Calling-Agent-流程&quot; class=&quot;headerlink&quot; title=&quot;Bonus 架构图 (现代 Fu</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>build GPT from scratch</title>
    <link href="http://yoursite.com/2025/05/21/GPT/"/>
    <id>http://yoursite.com/2025/05/21/GPT/</id>
    <published>2025-05-21T04:02:14.000Z</published>
    <updated>2025-06-04T10:04:56.305Z</updated>
    
    <content type="html"><![CDATA[<h1 id="build-GPT-from-scratch"><a href="#build-GPT-from-scratch" class="headerlink" title="build GPT from scratch"></a>build GPT from scratch</h1><h2 id="cross-entropy-损失函数估计"><a href="#cross-entropy-损失函数估计" class="headerlink" title="cross_entropy 损失函数估计"></a>cross_entropy 损失函数估计</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BigramLanguageModel</span>(nn.Module):</span><br><span class="line">……</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, idx, targets=<span class="literal">None</span></span>):</span><br><span class="line">            B, T, C = logits.shape</span><br><span class="line">            logits = logits.view(B*T, C)</span><br><span class="line">            targets = targets.view(B*T)</span><br><span class="line">            loss = F.cross_entropy(logits, targets)</span><br><span class="line"></span><br><span class="line">m = BigramLanguageModel(vocab_size)</span><br><span class="line">logits, loss = m(xb, yb)</span><br><span class="line"><span class="built_in">print</span>(logits.shape)</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">torch.Size([<span class="number">32</span>, <span class="number">65</span>])</span><br><span class="line">tensor(<span class="number">4.8786</span>, grad_fn=&lt;NllLossBackward0&gt;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = F.cross_entropy(logits, targets)</span><br></pre></td></tr></table></figure><p>其实计算的是</p><script type="math/tex; mode=display">\text{CrossEntropy}(p,y) = -log(p_y)</script><p>其中：</p><p>$p$ 是 softmax 后的概率分布<br>$y$ 是 ground-truth label (目标token)<br>$p_y$ 是对应ground-truth 类别的概率    </p><p>对于这个Loss如果我们想估计一下是什么水平，那就对比随机猜的情况,，这个可以作为baseline  </p><script type="math/tex; mode=display">\text{loss} = -\text{log}(\frac{1}{65}) = \text{log}(65) \approx 4.17</script><span id="more"></span><p>如果模型刚初始化，或者毫无学习能力，其交叉熵损失函数就会非常接近这个值</p><p>why loss=4.87 &gt; 4.17 ?<br>这是因为：模型还没开始训练（刚初始化），预测可能不均匀分布，而是更糟糕的“错误分布”，这会导致预测目标token概率 $p_y \lt fra$</p><h2 id="multitorch-multinomial"><a href="#multitorch-multinomial" class="headerlink" title="multitorch.multinomial"></a>multitorch.multinomial</h2><p>这个函数用来采样，会根据传入的数据所提供的概率来采样<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一维概率分布</span></span><br><span class="line">probs = torch.tensor([<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>])</span><br><span class="line"><span class="comment"># 采样 3 个样本，不重复采样</span></span><br><span class="line">samples = torch.multinomial(probs, num_samples=<span class="number">3</span>, replacement=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Samples:&quot;</span>, samples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二维概率分布</span></span><br><span class="line">probs = torch.tensor([[<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>], [<span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0.2</span>]])</span><br><span class="line"><span class="comment"># 采样 2 个样本，允许重复采样</span></span><br><span class="line">samples = torch.multinomial(probs, num_samples=<span class="number">2</span>, replacement=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Samples:&quot;</span>, samples)</span><br></pre></td></tr></table></figure></p><h2 id="temperature"><a href="#temperature" class="headerlink" title="temperature"></a>temperature</h2><script type="math/tex; mode=display">\text{adjusted logits} = \frac{logits}{T}</script><p>temperature通过在softmax之前修改logits 来平滑或尖锐logits分布<br>T=1.5：调整后的 logits 更小，概率分布更加平滑，所有类别的概率更加接近。<br>T=0.5：调整后的 logits 更大，概率分布更加尖锐，最高概率的类别更加突出。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义原始 logits</span></span><br><span class="line">logits = torch.tensor([[<span class="number">0.1</span>, <span class="number">0.7</span>, <span class="number">0.2</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义温度参数</span></span><br><span class="line">temperature_high = <span class="number">1.5</span></span><br><span class="line">temperature_low = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整 logits</span></span><br><span class="line">adjusted_logits_high = logits / temperature_high</span><br><span class="line">adjusted_logits_low = logits / temperature_low</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为概率分布</span></span><br><span class="line">probs_high = F.softmax(adjusted_logits_high, dim=-<span class="number">1</span>)</span><br><span class="line">probs_low = F.softmax(adjusted_logits_low, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original logits:&quot;</span>, logits)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Adjusted logits (T=1.5):&quot;</span>, adjusted_logits_high)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Adjusted logits (T=0.5):&quot;</span>, adjusted_logits_low)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Probs (T=1.5):&quot;</span>, probs_high)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Probs (T=0.5):&quot;</span>, probs_low)</span><br></pre></td></tr></table></figure></p><h2 id="weighted-sum"><a href="#weighted-sum" class="headerlink" title="weighted sum"></a>weighted sum</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">B, T, C = <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span></span><br><span class="line">x = torch.arange(<span class="number">0</span>, B*T*C, <span class="number">1</span>, dtype=torch.float32).reshape(B, T, C)</span><br><span class="line">wei = torch.tril(torch.ones(T,T))</span><br><span class="line">wei = wei/wei.<span class="built_in">sum</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">res = wei @ x</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;wei = &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(wei)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x = &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;res = &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure><p>能理解到把x的每一行看做一个2维向量， W每一行对4个2维向量加权求和，如果从矩阵乘法角度去推导，用分块矩阵方式如何具象化这一过程？<br>关键的地方是只将w分块化，看做行向量的stack, 而x不做分块考虑，这样就直观了.<br>每一行 output 是对所有 xᵢ（2D 向量）线性加权求和，权重是 W 的一行，这就是 attention 机制里 “加权求和” 的本质。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">W =</span><br><span class="line">⎡ w₀ᵀ ⎤</span><br><span class="line">⎢ w₁ᵀ ⎥</span><br><span class="line">⎢ w₂ᵀ ⎥</span><br><span class="line">⎣ w₃ᵀ ⎦   ∈ ℝ^&#123;<span class="number">4</span>×<span class="number">4</span>&#125;</span><br><span class="line"></span><br><span class="line">W @ x =</span><br><span class="line">⎡ w₀ᵀ @ x ⎤</span><br><span class="line">⎢ w₁ᵀ @ x ⎥</span><br><span class="line">⎢ w₂ᵀ @ x ⎥</span><br><span class="line">⎣ w₃ᵀ @ x ⎦</span><br></pre></td></tr></table></figure></p><h2 id="Query-Key"><a href="#Query-Key" class="headerlink" title="Query * Key"></a>Query * Key</h2><p>$\mathrm{res} = \mathrm{Q} \cdot \mathrm{K}^{\top}$ 分块矩阵的理解<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Q =</span><br><span class="line">---q1---</span><br><span class="line">---q2---</span><br><span class="line">---q3---</span><br><span class="line"></span><br><span class="line">K^&#123;T&#125; = </span><br><span class="line">  |  |  |</span><br><span class="line">  k1 k2 k3</span><br><span class="line">  |  |  |</span><br><span class="line"></span><br><span class="line">res = </span><br><span class="line">  [w1, w2, w3]</span><br><span class="line">  ……</span><br><span class="line"><span class="comment"># Q @ K^&#123;T&#125; 是q和K中的emb算sim, 得到weight</span></span><br></pre></td></tr></table></figure></p><h2 id="attention-vs-convolution"><a href="#attention-vs-convolution" class="headerlink" title="attention vs convolution"></a>attention vs convolution</h2><ul><li>Attention is a <strong>communication mechanism</strong>. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from <strong>all nodes that point to them</strong>, with <strong>data-dependent</strong> weights.aggregating at each other.  </li><li>There is <strong>no notion of space</strong>. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.<br>想象一下transformer里<br>K, Q, V shape is (B, T, C) = (4, 8, 16)<br>weight = K @ $\mathrm{Q}^{\mathrm{T}}$ is (B, T, T)<br>weight @ V = (B, T, C)  </li></ul><p>没有space 概念，这也是为什么需要add positin embedding的缘故.<br>虽然通过batch做了并行计算，但从始至终都是每个样本各自<strong>independent</strong>通信,没有communicate across batch，每个样本是一个有向图结构，各自通信，同一个batch里样本之间所构成的graph是不通信的  </p><ul><li>encoder: look all the tokens</li><li>decoder: only look T-1 tokens</li></ul><p><strong>self</strong>-attention: X -&gt; K, Q, V<br><strong>cross</strong>-attention: X -&gt; K, others-&gt; Q, V<br>cross attention:<br>Cross Attention（交叉注意力）是一种注意力机制，常用于需要处理 两个不同输入源之间的交互 的任务中，比如：<br>图像和文本之间的对齐（如图文生成、视觉问答）<br>编码器-解码器结构（如机器翻译中的Transformer）<br>多模态模型（比如 Qwen-VL 这类处理图像+文本输入的模型）<br>Cross Attention 的核心思想是：<br>一个序列（称为Query）通过注意力机制来关注另一个序列（称为Key和Value）中的关键信息。<br>例如：<br>假设你有一段文本：“这张图片上有什么？”<br>同时你有一张图片作为输入。<br>在 cross-attention 中：<br>文本被当作 Query（提问）<br>图像特征被当作 Key 和 Value（知识源）<br>模型会根据文本的每个位置，去图像中找最相关的区域来生成输出  </p><h2 id="divided-by-sqrt"><a href="#divided-by-sqrt" class="headerlink" title="divided by sqrt"></a>divided by sqrt</h2><script type="math/tex; mode=display">\mathrm{Attention}(Q,K,V) = \mathrm{sofltmax}(\frac{QK^{T}}{\sqrt{d_k}})V</script><p>“Scaled” attention additional divides wei by 1/sqrt(head_size). This makes it so when input Q,K are <strong>unit variance</strong>, wei will be <strong>unit variance</strong> too and Softmax will stay diffuse and not saturate too much. Illustration below<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">B,T,C = <span class="number">4</span>,<span class="number">8</span>,<span class="number">32</span> <span class="comment"># batch, time, channels</span></span><br><span class="line">head_size = <span class="number">16</span></span><br><span class="line">k = torch.randn(B,T,head_size)</span><br><span class="line">q = torch.randn(B,T,head_size)</span><br><span class="line"><span class="comment">#wei = q @ k.transpose(-2, -1) * head_size**-0.5</span></span><br><span class="line">wei = q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sqrt version 方差接近1,diffusion</span></span><br><span class="line">tensor(<span class="number">1.0752</span>)</span><br><span class="line">tensor(<span class="number">0.9134</span>)</span><br><span class="line">tensor(<span class="number">0.9560</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># no sqrt version 方差极端</span></span><br><span class="line">tensor(<span class="number">0.9716</span>)</span><br><span class="line">tensor(<span class="number">1.0322</span>)</span><br><span class="line">tensor(<span class="number">14.1379</span>)</span><br></pre></td></tr></table></figure><br>这样 Softmax 的输出就会比较“分散”（diffuse），而不会“过度饱和”（saturate too much）。<br>Diffuse” 指 Softmax 输出的分布比较“均匀”，不会只有几个值接近 1，其它都是 0。<br>“Saturate” 是指当输入非常大或非常小，Softmax 的输出趋近于极值（0 或 1），梯度会消失或训练不稳定。<br>如果没有 scale（√d），Q·K 的 dot product 会随 head_size 增大而变大 → 造成 Softmax 输出饱和 → 注意力只盯住很少几个 token → 学不到全局信息。<br><strong>数学解释</strong><br>$\mathrm{Var}(QK) = \mathrm{E}[(QK)^2] - (\mathrm{E}[QK])^2 = 1-0 = 1$<br>因为Q, K 相互独立，所Q, K的联合概率密度可以表示为他们的边缘概率分布乘积(平方也是)<br>it means:<br>$\mathrm{E}[QK] = \mathrm{E}[Q]\cdot\mathrm{E}[K]$<br>那么  </p><script type="math/tex; mode=display">Var[S] = Var[\sum_{i=1}^{d_k}Q_iK_i] = \sum_{i=1}^{d_k}1 = d_k</script><p>所以这是后除以$\sqrt{d_k}$会使得方差恒定，不会变化非常大</p><h2 id="register-buffer"><a href="#register-buffer" class="headerlink" title="register_buffer"></a>register_buffer</h2><p>一些不需要train的变量可以注册为buffer, 例如统计量mean, std, mask</p><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p><a href="https://poloclub.github.io/transformer-explainer/https://docs.python.org/">transformer-explainer</a>  </p><h2 id="Query-Key-and-Value-Matrics"><a href="#Query-Key-and-Value-Matrics" class="headerlink" title="Query, Key, and Value Matrics"></a>Query, Key, and Value Matrics</h2><p>Q, K, V 的生成式并行化的，通过把Weight stack在一起，通过一次矩阵乘法得到<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(T, C) @ (C, C*<span class="number">3</span>) -&gt; (T, C*<span class="number">3</span>)</span><br></pre></td></tr></table></figure><br>here T = 6, C = 768<br><a href="https://poloclub.github.io/transformer-explainer/"><img src="https://poloclub.github.io/transformer-explainer/article_assets/QKV.png" alt="Query,Key,Value Matrics"></a></p><h2 id=""><a href="#" class="headerlink" title=" "></a> </h2>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;build-GPT-from-scratch&quot;&gt;&lt;a href=&quot;#build-GPT-from-scratch&quot; class=&quot;headerlink&quot; title=&quot;build GPT from scratch&quot;&gt;&lt;/a&gt;build GPT from scratch&lt;/h1&gt;&lt;h2 id=&quot;cross-entropy-损失函数估计&quot;&gt;&lt;a href=&quot;#cross-entropy-损失函数估计&quot; class=&quot;headerlink&quot; title=&quot;cross_entropy 损失函数估计&quot;&gt;&lt;/a&gt;cross_entropy 损失函数估计&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title class_&quot;&gt;BigramLanguageModel&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;……&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title function_&quot;&gt;forward&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;self, idx, targets=&lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            B, T, C = logits.shape&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            logits = logits.view(B*T, C)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            targets = targets.view(B*T)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            loss = F.cross_entropy(logits, targets)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;m = BigramLanguageModel(vocab_size)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;logits, loss = m(xb, yb)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(logits.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# output&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;torch.Size([&lt;span class=&quot;number&quot;&gt;32&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;65&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tensor(&lt;span class=&quot;number&quot;&gt;4.8786&lt;/span&gt;, grad_fn=&amp;lt;NllLossBackward0&amp;gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;loss = F.cross_entropy(logits, targets)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;其实计算的是&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{CrossEntropy}(p,y) = -log(p_y)&lt;/script&gt;&lt;p&gt;其中：&lt;/p&gt;
&lt;p&gt;$p$ 是 softmax 后的概率分布&lt;br&gt;$y$ 是 ground-truth label (目标token)&lt;br&gt;$p_y$ 是对应ground-truth 类别的概率    &lt;/p&gt;
&lt;p&gt;对于这个Loss如果我们想估计一下是什么水平，那就对比随机猜的情况,，这个可以作为baseline  &lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{loss} = -\text{log}(\frac{1}{65}) = \text{log}(65) \approx 4.17&lt;/script&gt;</summary>
    
    
    
    <category term="LLM" scheme="http://yoursite.com/categories/LLM/"/>
    
    
    <category term="LLM" scheme="http://yoursite.com/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>Normlization</title>
    <link href="http://yoursite.com/2025/05/19/Normlization/"/>
    <id>http://yoursite.com/2025/05/19/Normlization/</id>
    <published>2025-05-19T04:05:44.000Z</published>
    <updated>2025-06-04T10:04:56.305Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h1><p>验证LayerNorm的，通过使用torch.mean和torch.var复现的时候发现不一致<br>LayerNorm默认使用的是bias的整体方差, divided by N<br>torch.var默认使用的是无bias的样本方差, devided by N-1</p><p>对于每一个样本的特征向量 $x \in \mathbb{R}^d$ ，LayerNorm 执行以下操作：</p><script type="math/tex; mode=display">\operatorname{LayerNorm}(x)=\gamma \cdot \frac{x-\mu}{\sqrt{\sigma^2+\epsilon}}+\beta</script><ul><li>$\mu, \sigma^2$ ：当前样本的均值和方差（仅用于归一化）</li><li>$\gamma$ ：可学习的缩放参数（scale，类似于权重）</li><li>$\beta$ ：可学习的偏移参数（bias，偏置）</li></ul><p><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0257ddec-b348-41d7-905d-5bc2b54fd557_1280x720.png" alt="LayerNomr"></a></p><span id="more"></span><p>对于这两个偏移参数如何更新，探究了一下底层实现<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">layer_norm = nn.LayerNorm(<span class="number">2</span>)</span><br><span class="line">x = torch.tensor([[<span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.tensor([[<span class="number">0.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]])  <span class="comment"># 目标全为 0</span></span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD(layer_norm.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    out = layer_norm(x)</span><br><span class="line">    loss = ((out - target)**<span class="number">2</span>).mean()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Step <span class="subst">&#123;i&#125;</span>, beta: <span class="subst">&#123;layer_norm.bias.data&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>$\gamma$ 和 $\beta$ 的维度是 (batch_size, seq_len)<br>$\sigma$ 以及 $\mu$ 的维度是 (batch_size, seq_len, feature_dim), 在完成标准化后，这两个会以向量的形式<br>例如:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x = [[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>],</span><br><span class="line">     [<span class="number">5.0</span>, <span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]]</span><br><span class="line"></span><br><span class="line">LayerNorm 会对每一行做标准化：</span><br><span class="line">=&gt; 每行变成均值=<span class="number">0</span>，方差=<span class="number">1</span> 的向量</span><br><span class="line"></span><br><span class="line">gamma, beta = [γ<span class="number">1</span>, γ<span class="number">2</span>, γ<span class="number">3</span>, γ<span class="number">4</span>], [β<span class="number">1</span>, β<span class="number">2</span>, β<span class="number">3</span>, β<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">最后输出 = normalized * gamma + beta</span><br></pre></td></tr></table></figure><br>底层在相乘的时候，一般会向量化<br>$ \hat{x} * {\gamma}^{T} + \beta$<br>其中 $\hat{x} ,\gamma, \beta \in \mathbb{R}^d$</p><p>$\hat{x} = \frac{x-\mu}{\sqrt{\sigma^2}}$<br>$ y = \hat{x} \cdot \gamma + \beta $<br>对于$\beta$, 反向传播的梯度： $\frac{\partial L}{\partial \beta}=\frac{\partial L}{\partial y}$<br>对于$\gamma$, 反向传播梯度： $\frac{\partial L}{\partial \gamma}=\frac{\partial L}{\partial y} \cdot \hat{x}$</p><p>那么，为什么 γ 和 β 要共享？</p><h3 id="1-归一化后丢失了尺度和偏移信息，需要-γ、β-来恢复表达能力"><a href="#1-归一化后丢失了尺度和偏移信息，需要-γ、β-来恢复表达能力" class="headerlink" title="1. 归一化后丢失了尺度和偏移信息，需要 γ、β 来恢复表达能力"></a>1. 归一化后丢失了尺度和偏移信息，需要 γ、β 来恢复表达能力</h3><p>归一化本质上是把数据变成了零均值、单位方差。</p><p>这样虽然有助于稳定训练，但会损失一些特征的表达能力（例如，“这个神经元原本输出很大是有意义的”）。</p><p>所以通过引入 γ 和 β 这两个 可学习参数，网络可以在训练中学习“是否需要放大某些维度”或“整体平移”，以恢复这种表达能力。</p><p>🎯 关键点：γ 和 β 是 模型的一部分，并不是用来适配每个样本，而是学习一种在所有样本上都有效的变换方式，这符合深度学习模型“共享参数”的理念。</p><h3 id="2-不对每个样本单独学习-γ-和-β-是为了避免过拟合-保持参数效率"><a href="#2-不对每个样本单独学习-γ-和-β-是为了避免过拟合-保持参数效率" class="headerlink" title="2. 不对每个样本单独学习 γ 和 β 是为了避免过拟合 + 保持参数效率"></a>2. 不对每个样本单独学习 γ 和 β 是为了避免过拟合 + 保持参数效率</h3><p>如果 γ 和 β 对每个样本都有独立的一套，那意味着参数量将随着 batch size 成倍增长。</p><p>这会：</p><p>大幅增加计算和内存负担</p><p>破坏模型的泛化能力（相当于为每个样本定制归一化，可能会过拟合）</p><p>所以：共享 γ 和 β 是一种在保持模型表达能力和计算效率之间的权衡。</p><h3 id="3-与-BatchNorm-的区别也体现出这种设计哲学"><a href="#3-与-BatchNorm-的区别也体现出这种设计哲学" class="headerlink" title="3. 与 BatchNorm 的区别也体现出这种设计哲学"></a>3. 与 BatchNorm 的区别也体现出这种设计哲学</h3><p>BatchNorm 使用的是 batch 内的统计量（跨样本统计），适用于图像等同分布样本。</p><p>LayerNorm 使用的是 样本内的统计量，避免依赖 batch 大小（适合 Transformer 这种序列建模）。</p><p>但无论哪种归一化，γ 和 β 始终是共享的参数，因为它们是模型本身的一部分，不依赖于输入样本。</p><p>🧪 举个比喻：<br>你有一个归一化后的图像数据集，每张图都被标准化成亮度为 0，标准差为 1。但你知道有些图像本该亮一些、有些本该暗一些。于是你训练一个“亮度增益”和“亮度偏移”参数，用来统一地调整所有图像。你不会为每张图学一个增益，而是找出一组对所有图都适用的参数。</p><p>✅ 总结：<br>问题    解释<br>为什么 γ 和 β 要 batch 共享？    因为它们是模型的一部分，用于恢复表达能力，不是输入的一部分；共享可以减少参数量、避免过拟合<br>为什么不对每个样本独立学习 γ 和 β？    这样会大大增加参数、容易过拟合，并且不符合深度学习“参数共享”的核心设计哲学<br>γ 和 β 的作用是什么？    恢复归一化过程丢失的尺度和偏移信息，使模型保留学习能力</p><h1 id="Batch-Normliazation"><a href="#Batch-Normliazation" class="headerlink" title="Batch Normliazation"></a>Batch Normliazation</h1><p>Batch Normalization（批量归一化）中的一个重要概念：运行统计量（running statistics） 的更新和使用。在训练过程中，Batch Normalization 会计算每个批次的均值和方差，并用这些统计量来归一化当前批次的数据。然而，这些批次内的统计量并不直接用于最终的归一化，而是用来更新运行统计量，这些运行统计量会在推理（inference）阶段使用。</p><h2 id="1-计算当前批次的均值和方差"><a href="#1-计算当前批次的均值和方差" class="headerlink" title="1. 计算当前批次的均值和方差"></a>1. 计算当前批次的均值和方差</h2><script type="math/tex; mode=display">\begin{aligned}&\mu_B=\frac{1}{m} \sum_{i=1}^m x_i\\&\sigma_B^2=\frac{1}{m} \sum_{i=1}^m\left(x_i-\mu_B\right)^2\end{aligned}</script><h2 id="2-归一化当前批次的数据"><a href="#2-归一化当前批次的数据" class="headerlink" title="2. 归一化当前批次的数据"></a>2. 归一化当前批次的数据</h2><script type="math/tex; mode=display">\hat{x}_i=\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}</script><h2 id="3-更新运行统计量："><a href="#3-更新运行统计量：" class="headerlink" title="3. 更新运行统计量："></a>3. 更新运行统计量：</h2><script type="math/tex; mode=display">\begin{aligned}&\mu_{\text {running }}=(1-\alpha) \mu_{\text {running }}+\alpha \mu_B\\&\sigma_{\text {running }}^2=(1-\alpha) \sigma_{\text {running }}^2+\alpha \sigma_B^2\end{aligned}</script><p>其中，α 是动量参数（momentum），通常设置为 0.1, 可以看出来这是小范围递增的更新运行统计量，old 占比0.9， $\delta$ 占比0.1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomBatchNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, momentum=<span class="number">0.1</span>, eps=<span class="number">1e-5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.momentum = momentum</span><br><span class="line">        self.eps = eps</span><br><span class="line">        self.running_mean = torch.zeros(num_features)</span><br><span class="line">        self.running_var = torch.ones(num_features)</span><br><span class="line">        self.gamma = nn.Parameter(torch.ones(num_features))</span><br><span class="line">        self.beta = nn.Parameter(torch.zeros(num_features))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">if</span> self.training:</span><br><span class="line">            <span class="comment"># 计算当前批次的均值和方差</span></span><br><span class="line">            batch_mean = x.mean(dim=<span class="number">0</span>)</span><br><span class="line">            batch_var = x.var(dim=<span class="number">0</span>, unbiased=<span class="literal">False</span>)</span><br><span class="line">            <span class="comment"># 更新运行统计量</span></span><br><span class="line">            self.running_mean = (<span class="number">1</span> - self.momentum) * self.running_mean + self.momentum * batch_mean</span><br><span class="line">            self.running_var = (<span class="number">1</span> - self.momentum) * self.running_var + self.momentum * batch_var</span><br><span class="line">            <span class="comment"># 归一化当前批次的数据</span></span><br><span class="line">            x_norm = (x - batch_mean) / torch.sqrt(batch_var + self.eps)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 使用运行统计量归一化数据</span></span><br><span class="line">            x_norm = (x - self.running_mean) / torch.sqrt(self.running_var + self.eps)</span><br><span class="line">        <span class="comment"># 应用缩放和偏移</span></span><br><span class="line">        <span class="keyword">return</span> self.gamma * x_norm + self.beta</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Layer-Normalization&quot;&gt;&lt;a href=&quot;#Layer-Normalization&quot; class=&quot;headerlink&quot; title=&quot;Layer Normalization&quot;&gt;&lt;/a&gt;Layer Normalization&lt;/h1&gt;&lt;p&gt;验证LayerNorm的，通过使用torch.mean和torch.var复现的时候发现不一致&lt;br&gt;LayerNorm默认使用的是bias的整体方差, divided by N&lt;br&gt;torch.var默认使用的是无bias的样本方差, devided by N-1&lt;/p&gt;
&lt;p&gt;对于每一个样本的特征向量 $x \in \mathbb{R}^d$ ，LayerNorm 执行以下操作：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\operatorname{LayerNorm}(x)=\gamma \cdot \frac{x-\mu}{\sqrt{\sigma^2+\epsilon}}+\beta&lt;/script&gt;&lt;ul&gt;
&lt;li&gt;$\mu, \sigma^2$ ：当前样本的均值和方差（仅用于归一化）&lt;/li&gt;
&lt;li&gt;$\gamma$ ：可学习的缩放参数（scale，类似于权重）&lt;/li&gt;
&lt;li&gt;$\beta$ ：可学习的偏移参数（bias，偏置）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html&quot;&gt;&lt;img src=&quot;https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0257ddec-b348-41d7-905d-5bc2b54fd557_1280x720.png&quot; alt=&quot;LayerNomr&quot;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="deeplearning LLM" scheme="http://yoursite.com/tags/deeplearning-LLM/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch常用例子</title>
    <link href="http://yoursite.com/2025/02/19/Pytorch/"/>
    <id>http://yoursite.com/2025/02/19/Pytorch/</id>
    <published>2025-02-19T10:34:58.000Z</published>
    <updated>2025-05-22T05:50:40.064Z</updated>
    
    <content type="html"><![CDATA[<p>本文档记录了一些pytorch常用操作以及概念</p><span id="more"></span><h2 id="1-构造数据"><a href="#1-构造数据" class="headerlink" title="1. 构造数据"></a>1. 构造数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 全 0 / 全 1 / 常数</span></span><br><span class="line">torch.zeros(<span class="number">3</span>, <span class="number">4</span>)           <span class="comment"># shape=(3, 4)</span></span><br><span class="line">torch.ones(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">torch.full((<span class="number">2</span>, <span class="number">2</span>), <span class="number">7.0</span>)</span><br><span class="line">x = torch.randn(<span class="number">10</span>,<span class="number">8</span>,<span class="number">4</span>)</span><br><span class="line">y = torch.ones_like(x)   <span class="comment"># 复制shape</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 随机数据</span></span><br><span class="line">torch.randn(<span class="number">5</span>, <span class="number">10</span>)          <span class="comment"># 标准正态分布 N(0,1)</span></span><br><span class="line">torch.rand(<span class="number">3</span>, <span class="number">3</span>)            <span class="comment"># 均匀分布 [0, 1)</span></span><br><span class="line">torch.randint(<span class="number">0</span>, <span class="number">10</span>, (<span class="number">2</span>, <span class="number">4</span>)) <span class="comment"># 整数随机数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 类似 numpy 的方式</span></span><br><span class="line">torch.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>)      <span class="comment"># [0, 2, 4, 6, 8]</span></span><br><span class="line">torch.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>)     <span class="comment"># [0., 0.25, 0.5, 0.75, 1.]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 从 numpy 转换</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">torch.from_numpy(np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]))</span><br></pre></td></tr></table></figure><h2 id="2-常用输入数据"><a href="#2-常用输入数据" class="headerlink" title="2. 常用输入数据"></a>2. 常用输入数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假数据：10 张 RGB 图片（3 通道，32x32），每张图一个标签</span></span><br><span class="line">x = torch.randn(<span class="number">10</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)     <span class="comment"># 图像张量</span></span><br><span class="line">y = torch.randint(<span class="number">0</span>, <span class="number">5</span>, (<span class="number">10</span>,))     <span class="comment"># 标签：5 类分类任务</span></span><br></pre></td></tr></table></figure><h2 id="3-向量化操作"><a href="#3-向量化操作" class="headerlink" title="3. 向量化操作"></a>3. 向量化操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">b = torch.randn(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 矩阵乘法</span></span><br><span class="line">out = a @ b                    <span class="comment"># shape=(3,5)</span></span><br><span class="line">out = torch.matmul(a, b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 广播加法</span></span><br><span class="line">x = torch.randn(<span class="number">10</span>, <span class="number">5</span>)      <span class="comment"># 广播机制，自动扩展</span></span><br><span class="line">bias = torch.randn(<span class="number">5</span>)</span><br><span class="line">x = x + bias                  </span><br><span class="line">x = torch.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">1</span>).reshape(<span class="number">2</span>, <span class="number">5</span>) </span><br><span class="line">bias = torch.tensor(<span class="number">1.0</span>)    <span class="comment"># 广播机制，scalar 自动扩展</span></span><br><span class="line">y = x + bias</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 拼接</span></span><br><span class="line">torch.cat([a, a], dim=<span class="number">0</span>)      <span class="comment"># 拼接行</span></span><br><span class="line">torch.cat([a, a], dim=<span class="number">1</span>)      <span class="comment"># 拼接列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. reshape &amp; transpose</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">x.view(<span class="number">6</span>, <span class="number">4</span>)                  <span class="comment"># 改形状</span></span><br><span class="line">x.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)            <span class="comment"># 交换维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 选择/掩码</span></span><br><span class="line">x = torch.randn(<span class="number">10</span>)</span><br><span class="line">mask = x &gt; <span class="number">0</span></span><br><span class="line">x[mask]                       <span class="comment"># 选出正数元素</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="eval-和-train的切换"><a href="#eval-和-train的切换" class="headerlink" title="eval 和 train的切换"></a>eval 和 train的切换</h2><p>eval和train类似现场保护功能，开关切换switch off<br>model.train()<br>将模型设置为“训练模式”。这会启用诸如 Dropout 和 BatchNorm 这样的层的训练行为（如参数更新、随机失活等）。通常在训练阶段调用。</p><p>model.eval()<br>将模型设置为“评估/推理模式”。这会关闭 Dropout、BatchNorm 等层的训练特性，使用固定参数进行推理。通常在验证或测试阶段调用<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">for</span> split <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]:</span><br><span class="line">    losses = torch.zeros(eval_iters)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(eval_iters):</span><br><span class="line">        X, Y = get_batch(split)</span><br><span class="line">        logits, loss = model(X, Y)</span><br><span class="line">        losses[k] = loss.item()</span><br><span class="line">    out[split] = losses.mean()</span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文档记录了一些pytorch常用操作以及概念&lt;/p&gt;</summary>
    
    
    
    
    <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>integer solutions</title>
    <link href="http://yoursite.com/2024/11/08/integer-solutions/"/>
    <id>http://yoursite.com/2024/11/08/integer-solutions/</id>
    <published>2024-11-08T08:57:53.000Z</published>
    <updated>2025-05-22T05:50:40.064Z</updated>
    
    <content type="html"><![CDATA[<p>linear regession 或者mpl 会涉及到weight decay, 提及整数解的问题：<br>k个变量，d阶的项一共有多少种？</p><p>问题描述<br>我们有 $ k $ 个变量 $ x_1, x_2, \ldots, x_k $，要求它们的和等于 $ d $，即：</p><p>$ x_1 + x_2 + \cdots + x_k = d $</p><h2 id="自然数解"><a href="#自然数解" class="headerlink" title="自然数解"></a>自然数解</h2><p>从 ( d - 1 ) 个位置中选择 ( k - 1 ) 个位置放置隔板，其余的位置放置星星。</p><p>这可以用组合数表示为：</p><p>$ \binom{d - 1}{k - 1} = \frac{(d - 1)!}{(k - 1)! \cdot (d - k)!} $</p><h2 id="非负整数解"><a href="#非负整数解" class="headerlink" title="非负整数解"></a>非负整数解</h2><p>在这个问题中，每个变量 $ x_i $ 可以取0。这意味着在分配过程中，某些变量可能不会获得任何单位。因此，为了表示这种情况，我们需要在星（单位）之间允许隔板（分隔符）彼此相邻，甚至位于首尾位置。这就增加了排列组合的灵活性。</p><span id="more"></span><p>具体解释：</p><p>单位和隔板的表示：</p><p>单位（星）：表示要分配的 $ d $ 个单位，用符号 $\bullet$ 表示。<br>隔板（杠）：用于分隔 $ k $ 个变量，用符号 $|$ 表示。需要 $ k - 1 $ 个隔板来分隔 $ k $ 个变量。<br>位置总数：</p><p>我们有 $ d $ 个单位和 $ k - 1 $ 个隔板。<br>因此，总共有 $ d + k - 1 $ 个位置，用于放置单位和隔板。<br>组合数计算：</p><p>在这 $ d + k - 1 $ 个位置中，选择 $ k - 1 $ 个位置放置隔板，<strong>其余位置放置单位</strong>(注意这里选完隔板的位置后，其他的放置单位用来放置星星)。<br>这种选择的方式数为组合数：<br>$ \binom{d + k - 1}{k - 1} = \frac{(d + k - 1)!}{d! \cdot (k - 1)!} $</p><p>例子<br>假设 $ k = 3 $ 且 $ d = 4 $，我们有：</p><p>$ x_1 + x_2 + x_3 = 4 $</p><p>使用星与杠法表示为：</p><p>$ \bullet \bullet | \bullet | \bullet $</p><p>这表示 $ x_1 = 2 $、$ x_2 = 1 $、$ x_3 = 1 $。</p><p>另一种分配方式：</p><p>$ \bullet \bullet \bullet | | \bullet $</p><p>这表示 $ x_1 = 3 $、$ x_2 = 0 $、$ x_3 = 1 $。</p><p>这里要注意的是，隔板和单位要放在一起考虑</p><h2 id="从kimi得到的解释"><a href="#从kimi得到的解释" class="headerlink" title="从kimi得到的解释:"></a>从kimi得到的解释:</h2><p>要理解为什么方程 $x_1 + x_2 + \ldots + x_k = d$ 的非负整数解的个数是 $\binom{d + k - 1}{k - 1}$，我们可以使用星条定理的直观解释。</p><ol><li><p><strong>星号和条形</strong>：想象你有 $d$ 个星号（代表总和），你需要将这些星号分配到 $k$ 个箱子（代表变量）中。每个箱子至少可以放0个星号，这意味着我们处理的是非负整数解。</p></li><li><p><strong>放置条形</strong>：为了将星号分成 $k$ 组，你需要 $k-1$ 个条形来分隔这些组。例如，如果你有3个箱子，你需要2个条形来分隔星号。</p></li><li><p><strong>总位置数</strong>：现在，我们有 $d$ 个星号和 $k-1$ 个条形，总共有 $d + k - 1$ 个位置需要填充。</p></li><li><p><strong>选择条形位置</strong>：问题现在变成了从这 $d + k - 1$ 个位置中选择 $k-1$ 个位置来放置条形。<strong>剩下的位置将自动被星号填充</strong>。</p></li><li><p><strong>组合计算</strong>：从 $d + k - 1$ 个位置中选择 $k-1$ 个位置的方法数由组合公式 $\binom{d + k - 1}{k - 1}$ 给出。</p></li></ol><p>因此，方程 $x_1 + x_2 + \ldots + x_k = d$ 的非负整数解的个数是 $\binom{d + k - 1}{k - 1}$。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;linear regession 或者mpl 会涉及到weight decay, 提及整数解的问题：&lt;br&gt;k个变量，d阶的项一共有多少种？&lt;/p&gt;
&lt;p&gt;问题描述&lt;br&gt;我们有 $ k $ 个变量 $ x_1, x_2, \ldots, x_k $，要求它们的和等于 $ d $，即：&lt;/p&gt;
&lt;p&gt;$ x_1 + x_2 + \cdots + x_k = d $&lt;/p&gt;
&lt;h2 id=&quot;自然数解&quot;&gt;&lt;a href=&quot;#自然数解&quot; class=&quot;headerlink&quot; title=&quot;自然数解&quot;&gt;&lt;/a&gt;自然数解&lt;/h2&gt;&lt;p&gt;从 ( d - 1 ) 个位置中选择 ( k - 1 ) 个位置放置隔板，其余的位置放置星星。&lt;/p&gt;
&lt;p&gt;这可以用组合数表示为：&lt;/p&gt;
&lt;p&gt;$ \binom{d - 1}{k - 1} = \frac{(d - 1)!}{(k - 1)! \cdot (d - k)!} $&lt;/p&gt;
&lt;h2 id=&quot;非负整数解&quot;&gt;&lt;a href=&quot;#非负整数解&quot; class=&quot;headerlink&quot; title=&quot;非负整数解&quot;&gt;&lt;/a&gt;非负整数解&lt;/h2&gt;&lt;p&gt;在这个问题中，每个变量 $ x_i $ 可以取0。这意味着在分配过程中，某些变量可能不会获得任何单位。因此，为了表示这种情况，我们需要在星（单位）之间允许隔板（分隔符）彼此相邻，甚至位于首尾位置。这就增加了排列组合的灵活性。&lt;/p&gt;</summary>
    
    
    
    <category term="math" scheme="http://yoursite.com/categories/math/"/>
    
    
    <category term="math,combination" scheme="http://yoursite.com/tags/math-combination/"/>
    
  </entry>
  
  <entry>
    <title>使用pandas 对比csv 文件</title>
    <link href="http://yoursite.com/2024/11/08/compare-csv-file/"/>
    <id>http://yoursite.com/2024/11/08/compare-csv-file/</id>
    <published>2024-11-08T05:43:34.000Z</published>
    <updated>2025-05-22T05:50:40.064Z</updated>
    
    <content type="html"><![CDATA[<p>通过pandas 的compare function， 可以对比两个csv 文件<br>用途，例如升级或修改code之后，输出是csv文本文件，对于同样input的数据，预期应该一样<br>input -&gt; program -&gt; output<br>input -&gt; program(optimize) -&gt; output_new<br>expect output == output_new</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sample data</span></span><br><span class="line">data_control = &#123;</span><br><span class="line">    <span class="string">&#x27;ProductEntityId&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">    <span class="string">&#x27;ColumnA&#x27;</span>: [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>],</span><br><span class="line">    <span class="string">&#x27;ColumnB&#x27;</span>: [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;E&#x27;</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data_treatment = &#123;</span><br><span class="line">    <span class="string">&#x27;ProductEntityId&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">    <span class="string">&#x27;ColumnA&#x27;</span>: [<span class="number">10</span>, <span class="number">25</span>, <span class="number">30</span>, <span class="number">40</span>],</span><br><span class="line">    <span class="string">&#x27;ColumnB&#x27;</span>: [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;X&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">df_control = pd.DataFrame(data_control)</span><br><span class="line">df_treatment = pd.DataFrame(data_treatment)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set ProductEntityId as the index</span></span><br><span class="line">df_control.set_index(<span class="string">&#x27;ProductEntityId&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df_treatment.set_index(<span class="string">&#x27;ProductEntityId&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the intersection of the indices</span></span><br><span class="line">common_indices = df_control.index.intersection(df_treatment.index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter both dataframes to only include the common indices</span></span><br><span class="line">df_control_common = df_control.loc[common_indices]</span><br><span class="line">df_treatment_common = df_treatment.loc[common_indices]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ensure both dataframes have the same columns</span></span><br><span class="line">df_treatment_common = df_treatment_common[df_control_common.columns]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compare the dataframes</span></span><br><span class="line">comparison_df = df_control_common.compare(df_treatment_common, keep_shape=<span class="literal">True</span>, keep_equal=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Highlight the differences</span></span><br><span class="line">first_level_columns = comparison_df.columns.get_level_values(<span class="number">0</span>).unique()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">highlight_differences</span>(<span class="params">row</span>):</span><br><span class="line">    styles = []</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> comparison_df.columns.levels[<span class="number">0</span>]:</span><br><span class="line">        self_val = row[(col, <span class="string">&#x27;self&#x27;</span>)]</span><br><span class="line">        other_val = row[(col, <span class="string">&#x27;other&#x27;</span>)]</span><br><span class="line">        <span class="keyword">if</span> (~pd.isna(self_val) <span class="keyword">or</span> ~pd.isna(other_val)) &amp; (self_val != other_val):</span><br><span class="line">            styles.append(<span class="string">&#x27;background-color: yellow&#x27;</span>)</span><br><span class="line">            styles.append(<span class="string">&#x27;background-color: yellow&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            styles.append(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            styles.append(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> styles</span><br><span class="line">highlighted_df = comparison_df.style.apply(highlight_differences, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the highlighted dataframe</span></span><br><span class="line"><span class="comment"># highlighted_df</span></span><br><span class="line"><span class="comment"># write hightlighted dataframe to a file</span></span><br><span class="line">highlighted_df.to_excel(<span class="string">&quot;./highlighted_output.xlsx&quot;</span>, engine=<span class="string">&#x27;openpyxl&#x27;</span>, index=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;通过pandas 的compare function， 可以对比两个csv 文件&lt;br&gt;用途，例如升级或修改code之后，输出是csv文本文件，对于同样input的数据，预期应该一样&lt;br&gt;input -&amp;gt; program -&amp;gt; output&lt;br&gt;input -&amp;gt; program(optimize) -&amp;gt; output_new&lt;br&gt;expect output == output_new&lt;/p&gt;</summary>
    
    
    
    
    <category term="pandas" scheme="http://yoursite.com/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>raspberry</title>
    <link href="http://yoursite.com/2024/06/04/raspberry/"/>
    <id>http://yoursite.com/2024/06/04/raspberry/</id>
    <published>2024-06-04T07:19:57.000Z</published>
    <updated>2025-05-22T05:50:40.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>64-bit镜像：<br><a href="https://downloads.raspberrypi.org/raspios_lite_arm64/images/raspios_lite_arm64-2021-05-28/">https://downloads.raspberrypi.org/raspios_lite_arm64/images/raspios_lite_arm64-2021-05-28/</a></p><h2 id="获取树莓派ip"><a href="#获取树莓派ip" class="headerlink" title="获取树莓派ip"></a>获取树莓派ip</h2><p>树莓派在接入路由器后是动态分配的，需要使用路由器的管理界面查看链接设备的MAC和ip地址<br>另外一种方式是扫描当前局域网的设备信息，比如可以使用IOS的Fing App去发现当前连接设备，一般树莓派的设备名称是Raspberry开头的</p><h2 id="挂载移动硬盘"><a href="#挂载移动硬盘" class="headerlink" title="挂载移动硬盘"></a>挂载移动硬盘</h2><p><a href="https://shumeipai.nxez.com/2013/09/08/raspberry-pi-to-mount-the-removable-hard-disk.html">https://shumeipai.nxez.com/2013/09/08/raspberry-pi-to-mount-the-removable-hard-disk.html</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mount -o uid=pi,gid=pi /dev/sda1 /mnt/1GB_USB_flash</span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="安装samba"><a href="#安装samba" class="headerlink" title="安装samba"></a>安装samba</h2><p><a href="https://www.cnblogs.com/xiaowuyi/p/4051238.html">https://www.cnblogs.com/xiaowuyi/p/4051238.html</a></p><h2 id="DLNA"><a href="#DLNA" class="headerlink" title="DLNA"></a>DLNA</h2><p><a href="https://shumeipai.nxez.com/2015/07/12/raspberry-pi-install-dlna-streaming-media-server.html">https://shumeipai.nxez.com/2015/07/12/raspberry-pi-install-dlna-streaming-media-server.html</a></p><h2 id="开机执行指定脚本"><a href="#开机执行指定脚本" class="headerlink" title="开机执行指定脚本"></a>开机执行指定脚本</h2><p>例如脚本路径/home/pi/Documents/start.sh</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">mount -o uid=pi,gid=pi /dev/sda1 /home/pi/Share</span><br><span class="line">/etc/init.d/smbd restart</span><br><span class="line">/etc/init.d/nmbd restart</span><br></pre></td></tr></table></figure><p>然后修改文件：/etc/rc.local<br>sudo vi /etc/rc.local<br>在exit 0之前添加要执行脚本的命令即可，例如</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/rc.local</span></span><br><span class="line">……</span><br><span class="line">sh /home/pi/Documents/start.sh</span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure><h2 id="格式化U盘"><a href="#格式化U盘" class="headerlink" title="格式化U盘"></a>格式化U盘</h2><p>格式化硬盘（U盘）<br>1.树莓派成功识别硬盘<br>sudo fdisk -l | grep ‘^Disk’<br>2.查看硬盘格式<br>sudo blkid<br>3.格式化为ext4<br>sudo mkfs.ext4 /dev/sda<br>挂载硬盘（U盘）<br>1.建立挂载点<br>sudo mkdir /media/xxx        #xxx代表你的挂载点名称，可以自定义<br>2.设置目录的所有人和所有组<br>sudo chown pi:pi /media/xxx<br>3.挂载<br>sudo mount -t ext4 /dev/sda /media/xxx<br>4.确认挂载<br>cd /media/xxx<br>5.卸载<br>sudo umount /media/xxx<br>6.开机自动挂载<br>查看UUID：sudo blkid<br>记下UUID：将UUID复制下来（不要带引号）<br>备份文件：sudo cp /etc/fstab /etc/fstab.bakup<br>编辑文件：sudo nano /etc/fstab<br>最后行加上： UUID=@@@ （@@@表示刚刚复制下来的UUID）（注意此处有一个空格）/media/xxx ext4 defaults 0 0</p><h2 id="To-Be-Continue"><a href="#To-Be-Continue" class="headerlink" title="To Be Continue"></a>To Be Continue</h2><p>安装<a href="https://pigallery2.herokuapp.com/gallery/">https://pigallery2.herokuapp.com/gallery/</a><br><a href="https://github.com/bpatrik/pigallery2/blob/master/docker/README.md">https://github.com/bpatrik/pigallery2/blob/master/docker/README.md</a><br><a href="https://github.com/bpatrik/pigallery2">https://github.com/bpatrik/pigallery2</a></p><h2 id="出现问题"><a href="#出现问题" class="headerlink" title="出现问题"></a>出现问题</h2><p>docker 安装完成后测试hello-world出现问题（Unable to find image ‘hello-world:latest’ locally）<br><a href="https://blog.csdn.net/wireless911/article/details/88989620">https://blog.csdn.net/wireless911/article/details/88989620</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;p&gt;64-bit镜像：&lt;br&gt;&lt;a href=&quot;https://downloads.raspberrypi.org/raspios_lite_arm64/images/raspios_lite_arm64-2021-05-28/&quot;&gt;https://downloads.raspberrypi.org/raspios_lite_arm64/images/raspios_lite_arm64-2021-05-28/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;获取树莓派ip&quot;&gt;&lt;a href=&quot;#获取树莓派ip&quot; class=&quot;headerlink&quot; title=&quot;获取树莓派ip&quot;&gt;&lt;/a&gt;获取树莓派ip&lt;/h2&gt;&lt;p&gt;树莓派在接入路由器后是动态分配的，需要使用路由器的管理界面查看链接设备的MAC和ip地址&lt;br&gt;另外一种方式是扫描当前局域网的设备信息，比如可以使用IOS的Fing App去发现当前连接设备，一般树莓派的设备名称是Raspberry开头的&lt;/p&gt;
&lt;h2 id=&quot;挂载移动硬盘&quot;&gt;&lt;a href=&quot;#挂载移动硬盘&quot; class=&quot;headerlink&quot; title=&quot;挂载移动硬盘&quot;&gt;&lt;/a&gt;挂载移动硬盘&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://shumeipai.nxez.com/2013/09/08/raspberry-pi-to-mount-the-removable-hard-disk.html&quot;&gt;https://shumeipai.nxez.com/2013/09/08/raspberry-pi-to-mount-the-removable-hard-disk.html&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo mount -o uid=pi,gid=pi /dev/sda1 /mnt/1GB_USB_flash&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>computer_version</title>
    <link href="http://yoursite.com/2024/06/04/computer-version/"/>
    <id>http://yoursite.com/2024/06/04/computer-version/</id>
    <published>2024-06-04T07:18:59.000Z</published>
    <updated>2025-05-22T05:50:40.064Z</updated>
    
    <content type="html"><![CDATA[<h1 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h1><h2 id="1-YOLO-损失函数第二部分"><a href="#1-YOLO-损失函数第二部分" class="headerlink" title="1. YOLO 损失函数第二部分"></a>1. YOLO 损失函数第二部分</h2><p>对于width, height的loss, 作者在论文中说明使用square root的原因：</p><blockquote><p>Our error metric should reflect that small deviations in large boxes matter less than in small boxes. To partially address this we predict the square root of the bounding box width and height instead of the width and height directly.<br>经过实际计算演示如下：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">width_height_loss</span>(<span class="params">w, h, error_shift=<span class="number">30</span></span>):</span><br><span class="line">    <span class="keyword">return</span> math.<span class="built_in">pow</span>((math.sqrt(w)-math.sqrt(w-erro_shift)),<span class="number">2</span>) + math.<span class="built_in">pow</span>((math.sqrt(h)-math.sqrt(h+erro_shift)),<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(width_height_loss(<span class="number">300</span>,<span class="number">500</span>))</span><br><span class="line"><span class="built_in">print</span>(width_height_loss(<span class="number">100</span>,<span class="number">150</span>))</span><br><span class="line">&gt;&gt; <span class="number">1.22700707099</span></span><br><span class="line">&gt;&gt; <span class="number">4.03446019009</span></span><br></pre></td></tr></table></figure><p>可以发现如此设计后，确实能起到如其所说loss对小的bbox比较敏感，惩罚度较大，而对大bbbox则反之。<br>究其原因，需要画一下此函数的曲线：</p><script type="math/tex; mode=display">f(x) = (\sqrt{x} -\sqrt{x-10})^2</script><p>从曲线可以直观的看到单调性<br><span id="more"></span></p><h1 id="YOLOV3"><a href="#YOLOV3" class="headerlink" title="YOLOV3"></a>YOLOV3</h1><h2 id="1-资料链接"><a href="#1-资料链接" class="headerlink" title="1. 资料链接"></a>1. 资料链接</h2><p>YOLO-V3 的网络结构图解析：<br><a href="https://blog.csdn.net/qq_37541097/article/details/81214953">https://blog.csdn.net/qq_37541097/article/details/81214953</a></p><p><a href="https://zhuanlan.zhihu.com/p/25052190">https://zhuanlan.zhihu.com/p/25052190</a><br><a href="https://zhuanlan.zhihu.com/p/70387154">https://zhuanlan.zhihu.com/p/70387154</a><br><a href="https://zhuanlan.zhihu.com/p/76802514">https://zhuanlan.zhihu.com/p/76802514</a></p><h2 id="2-网络结构"><a href="#2-网络结构" class="headerlink" title="2. 网络结构"></a>2. 网络结构</h2><p>Yolov3 architecture<br><a href="https://blog.csdn.net/qq_37541097/article/details/81214953">https://blog.csdn.net/qq_37541097/article/details/81214953</a><br><img src="https://img-blog.csdnimg.cn/2019040211084050.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTQxMDk3,size_16,color_FFFFFF,t_70" alt="此处输入图片的描述"></p><h2 id="3-实现部分"><a href="#3-实现部分" class="headerlink" title="3. 实现部分"></a>3. 实现部分</h2><p>Yolov3.cfg各参数说明：<a href="https://blog.csdn.net/ll_master/article/details/81487844">https://blog.csdn.net/ll_master/article/details/81487844</a><br>Yolov3.cfg输出的网络结构，输入416x416x3，代码：<a href="https://pjreddie.com/darknet/yolo/">https://pjreddie.com/darknet/yolo/</a><br>运行darknet.py中接口输出的网络结构，可以对比上面YOLOv3结构理解</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line">Using TensorFlow backend.</span><br><span class="line">layer     filters    size              input                output</span><br><span class="line">    0 conv     32  3 x 3 / 1   416 x 416 x   3   -&gt;   416 x 416 x  32  0.299 BFLOPs</span><br><span class="line">    1 conv     64  3 x 3 / 2   416 x 416 x  32   -&gt;   208 x 208 x  64  1.595 BFLOPs</span><br><span class="line">    2 conv     32  1 x 1 / 1   208 x 208 x  64   -&gt;   208 x 208 x  32  0.177 BFLOPs</span><br><span class="line">    3 conv     64  3 x 3 / 1   208 x 208 x  32   -&gt;   208 x 208 x  64  1.595 BFLOPs</span><br><span class="line">    4 res    1                 208 x 208 x  64   -&gt;   208 x 208 x  64</span><br><span class="line">    5 conv    128  3 x 3 / 2   208 x 208 x  64   -&gt;   104 x 104 x 128  1.595 BFLOPs</span><br><span class="line">    6 conv     64  1 x 1 / 1   104 x 104 x 128   -&gt;   104 x 104 x  64  0.177 BFLOPs</span><br><span class="line">    7 conv    128  3 x 3 / 1   104 x 104 x  64   -&gt;   104 x 104 x 128  1.595 BFLOPs</span><br><span class="line">    8 res    5                 104 x 104 x 128   -&gt;   104 x 104 x 128</span><br><span class="line">    9 conv     64  1 x 1 / 1   104 x 104 x 128   -&gt;   104 x 104 x  64  0.177 BFLOPs</span><br><span class="line">   10 conv    128  3 x 3 / 1   104 x 104 x  64   -&gt;   104 x 104 x 128  1.595 BFLOPs</span><br><span class="line">   11 res    8                 104 x 104 x 128   -&gt;   104 x 104 x 128</span><br><span class="line">   12 conv    256  3 x 3 / 2   104 x 104 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">   13 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128  0.177 BFLOPs</span><br><span class="line">   14 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">   15 res   12                  52 x  52 x 256   -&gt;    52 x  52 x 256</span><br><span class="line">   16 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128  0.177 BFLOPs</span><br><span class="line">   17 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">   18 res   15                  52 x  52 x 256   -&gt;    52 x  52 x 256</span><br><span class="line">   19 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128  0.177 BFLOPs</span><br><span class="line">   20 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">   21 res   18                  52 x  52 x 256   -&gt;    52 x  52 x 256</span><br><span class="line">   22 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128  0.177 BFLOPs</span><br><span class="line">   23 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">   24 res   21                  52 x  52 x 256   -&gt;    52 x  52 x 256</span><br><span class="line">   25 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128  0.177 BFLOPs</span><br><span class="line">   26 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">   27 res   24                  52 x  52 x 256   -&gt;    52 x  52 x 256</span><br><span class="line">   28 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128  0.177 BFLOPs</span><br><span class="line">   29 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">   30 res   27                  52 x  52 x 256   -&gt;    52 x  52 x 256</span><br><span class="line">   31 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128  0.177 BFLOPs</span><br><span class="line">   32 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">   33 res   30                  52 x  52 x 256   -&gt;    52 x  52 x 256</span><br><span class="line">   34 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128  0.177 BFLOPs</span><br><span class="line">   35 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">   36 res   33                  52 x  52 x 256   -&gt;    52 x  52 x 256</span><br><span class="line">   37 conv    512  3 x 3 / 2    52 x  52 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   38 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256  0.177 BFLOPs</span><br><span class="line">   39 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   40 res   37                  26 x  26 x 512   -&gt;    26 x  26 x 512</span><br><span class="line">   41 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256  0.177 BFLOPs</span><br><span class="line">   42 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   43 res   40                  26 x  26 x 512   -&gt;    26 x  26 x 512</span><br><span class="line">   44 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256  0.177 BFLOPs</span><br><span class="line">   45 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   46 res   43                  26 x  26 x 512   -&gt;    26 x  26 x 512</span><br><span class="line">   47 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256  0.177 BFLOPs</span><br><span class="line">   48 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   49 res   46                  26 x  26 x 512   -&gt;    26 x  26 x 512</span><br><span class="line">   50 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256  0.177 BFLOPs</span><br><span class="line">   51 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   52 res   49                  26 x  26 x 512   -&gt;    26 x  26 x 512</span><br><span class="line">   53 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256  0.177 BFLOPs</span><br><span class="line">   54 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   55 res   52                  26 x  26 x 512   -&gt;    26 x  26 x 512</span><br><span class="line">   56 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256  0.177 BFLOPs</span><br><span class="line">   57 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   58 res   55                  26 x  26 x 512   -&gt;    26 x  26 x 512</span><br><span class="line">   59 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256  0.177 BFLOPs</span><br><span class="line">   60 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   61 res   58                  26 x  26 x 512   -&gt;    26 x  26 x 512</span><br><span class="line">   62 conv   1024  3 x 3 / 2    26 x  26 x 512   -&gt;    13 x  13 x1024  1.595 BFLOPs</span><br><span class="line">   63 conv    512  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 512  0.177 BFLOPs</span><br><span class="line">   64 conv   1024  3 x 3 / 1    13 x  13 x 512   -&gt;    13 x  13 x1024  1.595 BFLOPs</span><br><span class="line">   65 res   62                  13 x  13 x1024   -&gt;    13 x  13 x1024</span><br><span class="line">   66 conv    512  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 512  0.177 BFLOPs</span><br><span class="line">   67 conv   1024  3 x 3 / 1    13 x  13 x 512   -&gt;    13 x  13 x1024  1.595 BFLOPs</span><br><span class="line">   68 res   65                  13 x  13 x1024   -&gt;    13 x  13 x1024</span><br><span class="line">   69 conv    512  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 512  0.177 BFLOPs</span><br><span class="line">   70 conv   1024  3 x 3 / 1    13 x  13 x 512   -&gt;    13 x  13 x1024  1.595 BFLOPs</span><br><span class="line">   71 res   68                  13 x  13 x1024   -&gt;    13 x  13 x1024</span><br><span class="line">   72 conv    512  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 512  0.177 BFLOPs</span><br><span class="line">   73 conv   1024  3 x 3 / 1    13 x  13 x 512   -&gt;    13 x  13 x1024  1.595 BFLOPs</span><br><span class="line">   74 res   71                  13 x  13 x1024   -&gt;    13 x  13 x1024</span><br><span class="line">   --------------------------------------------------------------------------------</span><br><span class="line">   75 conv    512  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 512  0.177 BFLOPs</span><br><span class="line">   76 conv   1024  3 x 3 / 1    13 x  13 x 512   -&gt;    13 x  13 x1024  1.595 BFLOPs</span><br><span class="line">   77 conv    512  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 512  0.177 BFLOPs  Convolutional Set</span><br><span class="line">   78 conv   1024  3 x 3 / 1    13 x  13 x 512   -&gt;    13 x  13 x1024  1.595 BFLOPs</span><br><span class="line">   79 conv    512  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 512  0.177 BFLOPs</span><br><span class="line">   --------------------------------------------------------------------------------</span><br><span class="line">   80 conv   1024  3 x 3 / 1    13 x  13 x 512   -&gt;    13 x  13 x1024  1.595 BFLOPs</span><br><span class="line">   81 conv    255  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 255  0.088 BFLOPs</span><br><span class="line">   82 yolo</span><br><span class="line">   83 route  79</span><br><span class="line">   84 conv    256  1 x 1 / 1    13 x  13 x 512   -&gt;    13 x  13 x 256  0.044 BFLOPs</span><br><span class="line">   85 upsample            2x    13 x  13 x 256   -&gt;    26 x  26 x 256</span><br><span class="line">   86 route  85 61</span><br><span class="line">   --------------------------------------------------------------------------------</span><br><span class="line">   87 conv    256  1 x 1 / 1    26 x  26 x 768   -&gt;    26 x  26 x 256  0.266 BFLOPs</span><br><span class="line">   88 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   89 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256  0.177 BFLOPs  Convolutional Set</span><br><span class="line">   90 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   91 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256  0.177 BFLOPs</span><br><span class="line">   --------------------------------------------------------------------------------</span><br><span class="line">   92 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512  1.595 BFLOPs</span><br><span class="line">   93 conv    255  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 255  0.177 BFLOPs</span><br><span class="line">   94 yolo</span><br><span class="line">   95 route  91</span><br><span class="line">   96 conv    128  1 x 1 / 1    26 x  26 x 256   -&gt;    26 x  26 x 128  0.044 BFLOPs</span><br><span class="line">   97 upsample            2x    26 x  26 x 128   -&gt;    52 x  52 x 128</span><br><span class="line">   98 route  97 36</span><br><span class="line">   --------------------------------------------------------------------------------</span><br><span class="line">   99 conv    128  1 x 1 / 1    52 x  52 x 384   -&gt;    52 x  52 x 128  0.266 BFLOPs</span><br><span class="line">  100 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">  101 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128  0.177 BFLOPs  Convolutional Set</span><br><span class="line">  102 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">  103 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128  0.177 BFLOPs</span><br><span class="line">  --------------------------------------------------------------------------------</span><br><span class="line">  104 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256  1.595 BFLOPs</span><br><span class="line">  105 conv    255  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 255  0.353 BFLOPs</span><br><span class="line">  106 yolo</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;YOLO&quot;&gt;&lt;a href=&quot;#YOLO&quot; class=&quot;headerlink&quot; title=&quot;YOLO&quot;&gt;&lt;/a&gt;YOLO&lt;/h1&gt;&lt;h2 id=&quot;1-YOLO-损失函数第二部分&quot;&gt;&lt;a href=&quot;#1-YOLO-损失函数第二部分&quot; class=&quot;headerlink&quot; title=&quot;1. YOLO 损失函数第二部分&quot;&gt;&lt;/a&gt;1. YOLO 损失函数第二部分&lt;/h2&gt;&lt;p&gt;对于width, height的loss, 作者在论文中说明使用square root的原因：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Our error metric should reflect that small deviations in large boxes matter less than in small boxes. To partially address this we predict the square root of the bounding box width and height instead of the width and height directly.&lt;br&gt;经过实际计算演示如下：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title function_&quot;&gt;width_height_loss&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;w, h, error_shift=&lt;span class=&quot;number&quot;&gt;30&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; math.&lt;span class=&quot;built_in&quot;&gt;pow&lt;/span&gt;((math.sqrt(w)-math.sqrt(w-erro_shift)),&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;) + math.&lt;span class=&quot;built_in&quot;&gt;pow&lt;/span&gt;((math.sqrt(h)-math.sqrt(h+erro_shift)),&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(width_height_loss(&lt;span class=&quot;number&quot;&gt;300&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(width_height_loss(&lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;150&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt;&amp;gt; &lt;span class=&quot;number&quot;&gt;1.22700707099&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt;&amp;gt; &lt;span class=&quot;number&quot;&gt;4.03446019009&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;可以发现如此设计后，确实能起到如其所说loss对小的bbox比较敏感，惩罚度较大，而对大bbbox则反之。&lt;br&gt;究其原因，需要画一下此函数的曲线：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;
f(x) = (\sqrt{x} -\sqrt{x-10})^2&lt;/script&gt;&lt;p&gt;从曲线可以直观的看到单调性&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>photograpy</title>
    <link href="http://yoursite.com/2024/06/04/photograpy/"/>
    <id>http://yoursite.com/2024/06/04/photograpy/</id>
    <published>2024-06-04T07:17:38.000Z</published>
    <updated>2025-05-22T05:50:40.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Camera-Raw"><a href="#Camera-Raw" class="headerlink" title="Camera Raw"></a>Camera Raw</h2><p>Basic Panel中<br>对于每一个可调节的滑块：</p><ul><li>双击滑块可回复原始值</li><li>按住shift双击滑块可自动调整<br><a href="https://helpx.adobe.com/cn/camera-raw/using/make-color-tonal-adjustments-camera.html">参考</a></li></ul><blockquote><p>在自动调整色调时，Camera Raw 忽略以前在其它选项卡中进行的任何调整（如在“色调曲线”选项卡中对色调进行的微调）。因此，先应用自动色调调整（如果有）以获取图像最佳设置的初始近似值。如果在拍摄时很细心并有意使用不同的曝光度进行拍摄，您可能不希望应用自动色调调整以放弃所做的工作。另一方面，如果您不喜欢所做的调整，可随时尝试单击“自动”并撤消这些调整。<br>为什么白平衡下面需要设置色调补偿绿色好紫色（tint)</p></blockquote><p><a href="https://photo.stackexchange.com/questions/104920/why-does-white-balance-knob-have-green-and-purple-setting">查阅</a></p><blockquote><p>A daunting task, because humans see using an eye/brain combination that alters our visualization of the world. This mechanism is eye independent. Try this experiment. Procure some transparent color filters, cellophane (candy wrappers work nicely). Filter one eye only with a deep red filter. Keep the filter in place for about 2 minutes. Remove the filter and then peer about quickly looking with one eye, then the other. You will find that the filter eye has radically changed as to its color balance. That eye will see the world with a blue-green tint. Try this again with yellow or blue or green cellophane. Each filter rapidly alters the filtered eye color balance. This adaptive mechanism occurs every minute of every day, to both eyes. You will be witnessing the human ability to adapt and normalize when the ambient light is off-color.<br>With some minor exceptions (special color films) color photography had to wait till the advent of electronic imaging. Now we have “white balance”, a camera mechanism that attempts to mimic our ability to adapt to light source alterations.<br>Photography adopted color “temperature”. Scientist verified that blacksmiths, glazers, potters and other workers (smiths) were able to regulate the temperatures of the materials of their craft visually by color changes as the material is heated. Seems all materials glow with alike outputs as they are heated to incandescence.<br>Black red 426°C —- Dark red 593°C – Cherry red 815°C – Yellow 1093°C – White 1315°+ etc.<br>Now physicists prefer the Celsius scale and they respect an adaptation known as the Absolute Scale. This is the Celsius scale with zero set to -273°C. This is the rock-bottom temperature so starting zero at this value avoids the possibility of negative temperatures. The champion of Absolute scale was William Thomson, 1st Baron Kelvin. In his honor, the Absolute scale was renamed Kelvin scale. Color films and now digital imaging and light sources are typically categorized using the Kelvin scale.<br>Candle 1850K – Standard 60W tungsten lamp 2400K – Studio tungsten bulb 3200K — Daylight 5500K.<br>Images taken under various lighting conditions often yield results that are not faithful reproduction. The traditional countermeasure was to mount a color correction optical filter before the lens. These are shades of blue to reverse reddish ambient light from tungsten sources and salmon (pink-amber) to neutralize the excessive bluish tints of north-sky daylight. Digital settings to correct off color lighting conditions are warming or cooling offsets.</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Camera-Raw&quot;&gt;&lt;a href=&quot;#Camera-Raw&quot; class=&quot;headerlink&quot; title=&quot;Camera Raw&quot;&gt;&lt;/a&gt;Camera Raw&lt;/h2&gt;&lt;p&gt;Basic Panel中&lt;br&gt;对于每一个可调节的滑块：&lt;/p&gt;
&lt;ul&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>tensorflow</title>
    <link href="http://yoursite.com/2024/06/04/tensorflow/"/>
    <id>http://yoursite.com/2024/06/04/tensorflow/</id>
    <published>2024-06-04T07:14:36.000Z</published>
    <updated>2025-05-22T05:50:40.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本元素"><a href="#基本元素" class="headerlink" title="基本元素"></a>基本元素</h2><h3 id="tf-Variable-……"><a href="#tf-Variable-……" class="headerlink" title="tf.Variable(……)"></a>tf.Variable(……)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">A = tf.Variable(<span class="number">3</span>, name=<span class="string">&quot;number&quot;</span>)</span><br><span class="line">B = tf.Variable([<span class="number">1</span>,<span class="number">3</span>], name=<span class="string">&quot;vector&quot;</span>)</span><br><span class="line">C = tf.Variable([[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">3</span>]], name=<span class="string">&quot;matrix&quot;</span>)</span><br><span class="line">D = tf.Variable(tf.zeros([<span class="number">100</span>]), name=<span class="string">&quot;zero&quot;</span>)</span><br><span class="line">E = tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">3</span>], mean=<span class="number">1</span>, stddev=<span class="number">2</span>, dtype=tf.float32))</span><br></pre></td></tr></table></figure><p>我们可以把函数variable()理解为构造函数，构造函数的使用需要初始值，而这个初始值是一个任何形状、类型的Tensor。<br>变量有两个重要的步骤，先后为：</p><ul><li>创建</li><li>初始化</li></ul><p>变量在使用前一定要进行初始化，且变量的初始化必须在模型的其它操作运行之前完成，通常，变量的初始化有三种方式：</p><ul><li>1.初始化全部变量<br><code>init = tf.global_variables_initializer()</code><br>global_variables_initializer()方法是不管全局有多少个变量，全部进行初始化，是最简单也是最常用的一种方式；</li><li>2.初始化变量的子集<br><code>init_subset=tf.variables_initializer([b,c], name=&quot;init_subset&quot;)</code><br>variables_initializer()是初始化变量的子集，相比于全部初始化化的方式更加节约内存</li><li>3.初始化单个变量</li></ul><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nit_var = tf.Variable(tf.zeros([<span class="number">2</span>,<span class="number">5</span>]))</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init_var.initializer)</span><br></pre></td></tr></table></figure><p>Variable()是初始化单个变量，函数的参数便是要初始化的变量内容。</p><h3 id="为什么要使用tf-global-variables-initializer-？"><a href="#为什么要使用tf-global-variables-initializer-？" class="headerlink" title="为什么要使用tf.global_variables_initializer()？"></a>为什么要使用tf.global_variables_initializer()？</h3><p>参考博客<a href="https://blog.csdn.net/qq_37285386/article/details/89054090">【任意门】</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 必须要使用global_variables_initializer的场合</span></span><br><span class="line"><span class="comment"># 含有tf.Variable的环境下，因为tf中建立的变量是没有初始化的，也就是在debug时还不是一个tensor量，而是一个Variable变量类型</span></span><br><span class="line">size_out = <span class="number">10</span></span><br><span class="line">tensor = tf.Variable(tf.random_normal(shape=[size_out]))</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)  <span class="comment"># initialization variables</span></span><br><span class="line">    <span class="built_in">print</span>(sess.run(tensor))</span><br><span class="line"><span class="comment"># 可以不适用初始化的场合</span></span><br><span class="line"><span class="comment"># 不含有tf.Variable、tf.get_Variable的环境下</span></span><br><span class="line"><span class="comment"># 比如只有tf.random_normal或tf.constant等</span></span><br><span class="line">size_out = <span class="number">10</span></span><br><span class="line">tensor = tf.random_normal(shape=[size_out])  <span class="comment"># 这里debug是一个tensor量哦</span></span><br><span class="line"><span class="comment">#init = tf.global_variables_initializer()</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># sess.run(init)  # initialization variables</span></span><br><span class="line">    <span class="built_in">print</span>(sess.run(tensor))</span><br></pre></td></tr></table></figure><p>需要注意的是 tf.placeholder也是tensor，可以这样理解，tf.Variable是需要申请存储（显存/内存）的变量，而tensor:</p><ol><li>计算图上计算的中间结果，比如operation</li><li>常量，比如tf.random_normal, tf.constant</li><li>等待输入的placeholder（不需要初始化，等待feed data)<br>常见的计算系统，无非是操作数，运算符，然后是存储器，如果施加运算符的步骤不再立刻执行，而是最后计算，那么这些中构结果就没必要一开始申请存储，这便是tensor的由来。</li></ol><h3 id="获取graph的名称"><a href="#获取graph的名称" class="headerlink" title="获取graph的名称"></a>获取graph的名称</h3><p>参考<a href="https://stackoverflow.com/questions/36883949/in-tensorflow-get-the-names-of-all-the-tensors-in-a-graph">stackoverflow</a></p><ul><li>To get all nodes:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_nodes = [n <span class="keyword">for</span> n <span class="keyword">in</span> tf.get_default_graph().as_graph_def().node]</span><br><span class="line">These have the <span class="built_in">type</span> tensorflow.core.framework.node_def_pb2.NodeDef</span><br></pre></td></tr></table></figure><ul><li>To get all ops:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_ops = tf.get_default_graph().get_operations()</span><br><span class="line">These have the <span class="built_in">type</span> tensorflow.python.framework.ops.Operation</span><br></pre></td></tr></table></figure><ul><li>To get all variables:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_vars = tf.global_variables()</span><br><span class="line">These have the <span class="built_in">type</span> tensorflow.python.ops.resource_variable_ops.ResourceVariable</span><br></pre></td></tr></table></figure><ul><li>And finally, to answer the question, to get all tensors:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_tensors = [tensor <span class="keyword">for</span> op <span class="keyword">in</span> tf.get_default_graph().get_operations() <span class="keyword">for</span> tensor <span class="keyword">in</span> op.values()]</span><br></pre></td></tr></table></figure><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="tf-reduce-sum的理解"><a href="#tf-reduce-sum的理解" class="headerlink" title="tf.reduce_sum的理解"></a>tf.reduce_sum的理解</h3><p><a href="https://www.jianshu.com/p/30b40b504bae">https://www.jianshu.com/p/30b40b504bae</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.reduce_sum(</span><br><span class="line">    input_tensor, </span><br><span class="line">    axis=None, </span><br><span class="line">    keepdims=None,</span><br><span class="line">    name=None,</span><br><span class="line">    reduction_indices=None, </span><br><span class="line">    keep_dims=None)</span><br></pre></td></tr></table></figure><ul><li>0维，又称0维张量，数字，标量：1</li><li>1维，又称1维张量，数组，vector：[1, 2, 3]</li><li>2维，又称2维张量，矩阵，二维数组：[[1,2], [3,4]]</li><li>3维，又称3维张量，立方（cube），三维数组：[ [[1,2], [3,4]], [[5,6], [7,8]] ]</li><li>n维：你应该get到点了吧~</li></ul><p><strong>再多的维只不过是是把上一个维度当作自己的元素</strong><br><strong>越往里axis就越大，依次加1</strong><br>下面举个多维tensor例子简单说明。下面是个 2 <em>3</em> 4 的tensor。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[[[ 1   2   3   4]</span><br><span class="line">  [ 5   6   7   8]</span><br><span class="line">  [ 9   10 11 12]],</span><br><span class="line"> [[ 13  14 15 16]</span><br><span class="line">  [ 17  18 19 20]</span><br><span class="line">  [ 21  22 23 24]]]</span><br></pre></td></tr></table></figure><p>tf.reduce_sum(tensor, axis=0) axis=0 说明是按第一个维度进行求和。那么求和结果shape是3*4</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[1+13   2+14   3+15 4+16]</span><br><span class="line"> [5+17   6+18   7+19 8+20]</span><br><span class="line"> [9+21 10+22 11+23 12+24]]</span><br></pre></td></tr></table></figure><p>依次类推，如果axis=1，那么求和结果shape是2*4，即：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[ 1 + 5 + 9   2 + 6+10   3 + 7+11   4 + 8+12]</span><br><span class="line"> [13+17+21     14+18+22   15+19+23   16+20+24]]</span><br></pre></td></tr></table></figure><p>如果axis=2，那么求和结果shape是2*3，即：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[1+2+3+4          5+6+7+8          9+10+11+12]</span><br><span class="line"> [13+14+15+16      17+18+19+20      1+22+23+24]]</span><br></pre></td></tr></table></figure><h3 id="tf-stack的理解"><a href="#tf-stack的理解" class="headerlink" title="tf.stack的理解"></a>tf.stack的理解</h3><p><a href="https://stackoverflow.com/questions/50820781/quesion-about-the-axis-of-tf-stack/50821422#50821422">https://stackoverflow.com/questions/50820781/quesion-about-the-axis-of-tf-stack/50821422#50821422</a><br>tf.stack可以理解为先对需要stack的tensor做expand_dims，添加一维，添加的位置即axis，然后在这一axis上做concate</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def tf.stack(tensors, axis=0):</span><br><span class="line">    return tf.concatenate([tf.expand_dims(t, axis=axis) for t in tensors], axis=axis)</span><br></pre></td></tr></table></figure><h3 id="具有先后顺序，synchronize的计算"><a href="#具有先后顺序，synchronize的计算" class="headerlink" title="具有先后顺序，synchronize的计算"></a>具有先后顺序，synchronize的计算</h3><ul><li>tf.GraphKeys.UPDATE_OPS</li><li>tf.control_dependencies</li></ul><p><a href="https://blog.csdn.net/huitailangyz/article/details/85015611">参考资料</a><br><code>tf.GraphKeys.UPDATE_OPS</code> 和 <code>tf.control_dependencies</code> 搭配使用，用来限制一些有先后关系的节点运算<br><code>tf.control_dependencies</code>，该函数保证其<strong>作用域中的操作</strong>必须要在该函数所传递的<strong>参数中的操作</strong>完成后再进行，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一个运算</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a_1 = tf.Variable(<span class="number">1</span>)</span><br><span class="line">b_1 = tf.Variable(<span class="number">2</span>)</span><br><span class="line">update_op = tf.assign(a_1, <span class="number">10</span>)</span><br><span class="line">add = tf.add(a_1, b_1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二个运算</span></span><br><span class="line">a_2 = tf.Variable(<span class="number">1</span>)</span><br><span class="line">b_2 = tf.Variable(<span class="number">2</span>)</span><br><span class="line">update_op = tf.assign(a_2, <span class="number">10</span>)</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies([update_op]):</span><br><span class="line">    add_with_dependencies = tf.add(a_2, b_2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    ans_1, ans_2 = sess.run([add, add_with_dependencies])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Add: &quot;</span>, ans_1)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Add_with_dependency: &quot;</span>, ans_2)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">Add:  <span class="number">3</span></span><br><span class="line">Add_with_dependency:  <span class="number">12</span></span><br></pre></td></tr></table></figure><p>可以看到上面例子中，第一个update_op 对变量做了加一操作，<br><strong>但正常的计算图在计算add时是不会经过update_op操作</strong>，所以没有生效。<br>于tf.GraphKeys.UPDATE_OPS，这是一个tensorflow的计算图中内置的一个集合，其中会保存一些需要在训练操作之前完成的操作，并配合tf.control_dependencies函数使用。<br>至于<code>tf.GraphKeys.UPDATE_OPS</code>的作用，可以在Batch Normalization的例子中理解其作用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, train_mean)</span><br><span class="line">……</span><br><span class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line"><span class="built_in">print</span>(update_ops)</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies(update_ops):</span><br><span class="line">    train_op = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure><p>两个<code>tf.add_to_collection</code>在这里是将需要先计算的Mean和var加入UPDATE_OPS中，这样</p><blockquote><p>如果不在使用时添加tf.control_dependencies函数，即在训练时(training=True)每批次时只会计算当批次的mean和var，并传递给tf.nn.batch_normalization进行归一化，由于mean_update和variance_update在计算图中并不在上述操作的依赖路径上，因为并不会主动完成，也就是说，在训练时mean_update和variance_update并不会被使用到，其值sfsfafsfafafdafa一直是初始值。因此在测试阶段(training=False)使用这两个作为mean和variance并进行归一化操作，这样就会出现错误。而如果使用tf.control_dependencies函数，会在训练阶段每次训练操作执行前被动地去执行mean_update和variance_update，因此moving_mean和moving_variance会被不断更新，在测试时使用该参数也就不会出现错误。</p></blockquote><h3 id="embedding-和-lookupTable-link"><a href="#embedding-和-lookupTable-link" class="headerlink" title="embedding 和 lookupTable [link]"></a>embedding 和 lookupTable [<a href="https://gshtime.github.io/2018/06/01/tensorflow-embedding-lookup-sparse/">link</a>]</h3><p>feature_num : 原始特征数<br>embedding_size: embedding之后的特征数<br>[feature_num, embedding_size] 权重矩阵shape<br>[m, feature_num] 输入矩阵shape，m为样本数<br>[m, embedding_size] 输出矩阵shape，m为样本数</p><p>embedding_lookup不是简单的查表，<a href="https://gshtime.github.io/2018/06/01/tensorflow-embedding-lookup-sparse/">params 对应的向量是可以训练的</a>，训练参数个数应该是 feature_num * embedding_size，即前文表述的embedding层权重矩阵，就是说 lookup 的是一种全连接层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 当输入单个tensor时，partition_strategy不起作用，不做 id（编号） 的切分</span></span><br><span class="line">a = np.arange(<span class="number">20</span>).reshape(<span class="number">5</span>,<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span> (a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前面的编号是我手动加的，意思是不做切分的时候就顺序编号就行</span></span><br><span class="line"><span class="comment"># 0#[[ 0  1  2  3]</span></span><br><span class="line"><span class="comment"># 1# [ 4  5  6  7]</span></span><br><span class="line"><span class="comment"># 2# [ 8  9 10 11]</span></span><br><span class="line"><span class="comment"># 3# [12 13 14 15]</span></span><br><span class="line"><span class="comment"># 4# [16 17 18 19]]</span></span><br><span class="line"></span><br><span class="line">tensor_a = tf.Variable(a)</span><br><span class="line">embedded_tensor = tf.nn.embedding_lookup(params=tensor_a, ids=[<span class="number">0</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    embedded_tensor = sess.run(embedded_tensor)</span><br><span class="line">    <span class="built_in">print</span>(embedded_tensor)</span><br><span class="line"><span class="comment"># 根据 ids 参数做选择</span></span><br><span class="line"><span class="comment">#[[ 0  1  2  3]  选择了 id 0</span></span><br><span class="line"><span class="comment"># [12 13 14 15]  选择了 id 3</span></span><br><span class="line"><span class="comment"># [ 8  9 10 11]  选择了 id 2</span></span><br><span class="line"><span class="comment"># [ 4  5  6  7]] 选择了 id 1</span></span><br></pre></td></tr></table></figure><h3 id="loss-function"><a href="#loss-function" class="headerlink" title="loss function"></a>loss function</h3><p><a href="https://zhuanlan.zhihu.com/p/44216830">https://zhuanlan.zhihu.com/p/44216830</a></p><h4 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h4><p>tf.losses.mean_squared_error<br>tf.losses.absolute_difference<br>tf.losses.huber_loss：Huber loss</p><h4 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h4><p>tf.nn.sigmoid_cross_entropy_with_logits<br>tf.losses.log_loss<br>tf.nn.softmax_cross_entropy_with_logits_v2<br>tf.nn.sparse_softmax_cross_entropy_with_logits<br>tf.nn.weighted_cross_entropy_with_logits<br>tf.losses.hinge_loss</p><h5 id="tf-softmax-cross-entropy-with-logits"><a href="#tf-softmax-cross-entropy-with-logits" class="headerlink" title="tf.softmax_cross_entropy_with_logits"></a>tf.softmax_cross_entropy_with_logits</h5><p>tf.softmax_cross_entropy_with_logits()的计算过程一共分为两步:</p><ul><li>1）将logits转换成概率 <script type="math/tex">l_k = \frac{e^k}{\sum_{i=1}^{n}{e^i}}</script></li><li>2）计算交叉熵损失 <script type="math/tex">-\Sigma y'* log(y)</script></li></ul><p>注意事项：<br>般训练时batch size不会为设为1,所以要使用tf.reduce_mean()来对tf.softmax_cross_entropy_with_logits()的结果取平均,得到关于样本的平均交叉熵损失.</p><h2 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h2><h3 id="tf-Print"><a href="#tf-Print" class="headerlink" title="tf.Print"></a>tf.Print</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">var = tf.concat([var_a, var_b])</span><br><span class="line">var = tf.Print(var, [var_a, var_b], message=&quot;print message in there&quot;, summarized=10000)</span><br></pre></td></tr></table></figure><p>tf.Print 类似identity，挂载到图上，但不影响图结构，所以即使是checkpoint也可以打印计算的中间结果，方便诊断问题。需要注意的是待打印的变量需是图中流过var的上端节点tensor</p><h3 id="tf-cond"><a href="#tf-cond" class="headerlink" title="tf.cond"></a>tf.cond</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.constant(2)</span><br><span class="line">b = tf.constant(3)</span><br><span class="line">x = tf.constant(4)</span><br><span class="line">y = tf.constant(5)</span><br><span class="line">z = tf.multiply(a, b)</span><br><span class="line">result = tf.cond(x &lt; y, lambda: tf.add(x, z), lambda: tf.square(y))</span><br><span class="line">with tf.Session() as session:</span><br><span class="line">    print(result.eval())</span><br></pre></td></tr></table></figure><h2 id="same-和-padding"><a href="#same-和-padding" class="headerlink" title="same 和 padding"></a>same 和 padding</h2><script type="math/tex; mode=display">\left\lceil\frac{n_{i}+p_{i}-k+1}{s}\right\rceil=n_{o}</script><p>$n_i$ 为input_size<br>$n_o$ 为output_size<br>$k$   为 kernel size<br>$s$   为 stride<br>$p_i$ 为 padding size<br><a href="https://www.jianshu.com/p/b9eb4758118d">https://www.jianshu.com/p/b9eb4758118d</a></p><h2 id="Session-run-a-b-c-中变量的顺序"><a href="#Session-run-a-b-c-中变量的顺序" class="headerlink" title="Session.run([a,b,c])中变量的顺序"></a>Session.run([a,b,c])中变量的顺序</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_val, _ = sess.run([loss, optimizer])</span><br></pre></td></tr></table></figure><p>对于上面遇到的问题，可能会产生怀疑，这个Loss到底是back propgation之前的还是之后的？在查看<a href="https://stackoverflow.com/questions/53165418/order-of-sess-runop1-op2-in-tensorflow">stack overflow</a> 上的解答，发现sess.run中的变量求解是不确定的。上面的代码求解的是BP之前的，tensorflow为了保证不重复计算，图中节点已经计算过的会直接取出，若想获取BP之后的Loss, 可通过如下方式：</p><ol><li>再次sess.run([loss])</li><li>定义一个loss_end tensor,</li><li>使用tf.control_dependencies([optimizer])来规定依赖</li></ol><h2 id="Session-和-Graph-的关系"><a href="#Session-和-Graph-的关系" class="headerlink" title="Session 和 Graph 的关系"></a>Session 和 Graph 的关系</h2><p><a href="https://www.easy-tensorflow.com/tf-tutorials/basics/graph-and-session">https://www.easy-tensorflow.com/tf-tutorials/basics/graph-and-session</a><br>网络经过定义然后训练后得的参数保存在session中而非graph中，graph只是网路结构的表述。</p><h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><p><a href="https://zhuanlan.zhihu.com/p/44216830">https://zhuanlan.zhihu.com/p/44216830</a></p><h3 id="1-tf-nn-sigmoid-cross-entropy-with-logits"><a href="#1-tf-nn-sigmoid-cross-entropy-with-logits" class="headerlink" title="1. tf.nn.sigmoid_cross_entropy_with_logits"></a>1. tf.nn.sigmoid_cross_entropy_with_logits</h3><p>先 sigmoid 再求交叉熵,二分类问题首选,使用时，一定不要将预测值（y_pred）进行 sigmoid 处理，因为这个函数已经包含了sigmoid过程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Tensorflow中集成的函数</span><br><span class="line">sigmoids = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_pred)</span><br><span class="line">sigmoids_loss = tf.reduce_mean(sigmoids)</span><br><span class="line"></span><br><span class="line"># 利用Tensorflow基础函数手工实现</span><br><span class="line">y_pred_si = 1.0/(1+tf.exp(-y_pred))</span><br><span class="line">sigmoids = -y_true*tf.log(y_pred_si) - (1-y_true)*tf.log(1-y_pred_si)</span><br><span class="line">sigmoids_loss = tf.reduce_mean(sigmoids)</span><br></pre></td></tr></table></figure><h3 id="2-tf-losses-log-loss"><a href="#2-tf-losses-log-loss" class="headerlink" title="2. tf.losses.log_loss"></a>2. tf.losses.log_loss</h3><p>预测值（y_pred）计算完成后，若已先行进行了 sigmoid 处理，则使用此函数求 loss ，若还没经过 sigmoid 处理，可直接使用 sigmoid_cross_entropy_with_logits。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Tensorflow中集成的函数</span><br><span class="line">logs = tf.losses.log_loss(labels=y, logits=y_pred)</span><br><span class="line">logs_loss = tf.reduce_mean(logs)</span><br><span class="line"></span><br><span class="line"># 利用Tensorflow基础函数手工实现</span><br><span class="line">logs = -y_true*tf.log(y_pred) - (1-y_true)*tf.log(1-y_pred)</span><br><span class="line">logs_loss = tf.reduce_mean(logs)</span><br></pre></td></tr></table></figure><h2 id="模型导出和恢复"><a href="#模型导出和恢复" class="headerlink" title="模型导出和恢复"></a>模型导出和恢复</h2><p><a href="https://www.jianshu.com/p/c3a7f5c47b83">TensorFlow：保存和提取模型</a></p><h3 id="模型恢复"><a href="#模型恢复" class="headerlink" title="模型恢复"></a>模型恢复</h3><h4 id="savedModel"><a href="#savedModel" class="headerlink" title="savedModel"></a>savedModel</h4><p><a href="https://blog.csdn.net/mogoweb/article/details/83054861">如何查看Tensorflow SavedModel格式模型的信息</a><br>signature并非是为了保证模型不被修改的那种电子签名。类似于编程语言中模块的输入输出信息，比如函数名，输入参数类型，输出参数类型等等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.platform <span class="keyword">import</span> gfile</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.core.protobuf <span class="keyword">import</span> saved_model_pb2</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.util <span class="keyword">import</span> compat</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  model_filename =<span class="string">&#x27;./model/saved_model.pb&#x27;</span></span><br><span class="line">  <span class="keyword">with</span> gfile.FastGFile(model_filename, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line"></span><br><span class="line">    data = compat.as_bytes(f.read())</span><br><span class="line">    sm = saved_model_pb2.SavedModel()</span><br><span class="line">    sm.ParseFromString(data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="number">1</span> != <span class="built_in">len</span>(sm.meta_graphs):</span><br><span class="line">      <span class="built_in">print</span>(<span class="string">&#x27;More than one graph found. Not sure which to write&#x27;</span>)</span><br><span class="line">      sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    g_in = tf.import_graph_def(sm.meta_graphs[<span class="number">0</span>].graph_def)</span><br><span class="line">LOGDIR=<span class="string">&#x27;./logdir&#x27;</span></span><br><span class="line">train_writer = tf.summary.FileWriter(LOGDIR)</span><br><span class="line">train_writer.add_graph(sess.graph)</span><br><span class="line">train_writer.flush()</span><br><span class="line">train_writer.close()</span><br></pre></td></tr></table></figure><p>另外可参考stackoverflow的总结<br><a href="https://stackoverflow.com/questions/33759623/tensorflow-how-to-save-restore-a-model">https://stackoverflow.com/questions/33759623/tensorflow-how-to-save-restore-a-model</a></p><h2 id="Tensorflow-主流程"><a href="#Tensorflow-主流程" class="headerlink" title="Tensorflow 主流程"></a>Tensorflow 主流程</h2><h3 id="梯度更新部分"><a href="#梯度更新部分" class="headerlink" title="梯度更新部分"></a>梯度更新部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.control_dependencies(update_ops):</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line"><span class="comment"># 计算梯度，grads_and_vars 是一个list：(gradient, variable)，变量和变量对应的梯度    </span></span><br><span class="line">grads_and_vars = optimizer.compute_gradients(loss)</span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># ...... (此处可以做 梯度修建等操作，然后再对变量更新梯度）</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># 执行对应变量的更新梯度操作</span></span><br><span class="line">train_op = optimizer.apply_gradients(grad_vars, global_step=global_step)</span><br></pre></td></tr></table></figure><h3 id="tf-Summary"><a href="#tf-Summary" class="headerlink" title="tf.Summary"></a>tf.Summary</h3><p><a href="https://zhuanlan.zhihu.com/p/31459527">https://zhuanlan.zhihu.com/p/31459527</a><br><a href="https://www.cnblogs.com/lyc-seu/p/8647792.html">https://www.cnblogs.com/lyc-seu/p/8647792.html</a></p><h2 id="Keras-backend-tensorflow"><a href="#Keras-backend-tensorflow" class="headerlink" title="Keras backend tensorflow"></a>Keras backend tensorflow</h2><p>keras 和 tensorflow-gpu版本兼容列表<br><a href="https://docs.floydhub.com/guides/environments/">https://docs.floydhub.com/guides/environments/</a><br>应对不同tensorlow-gpu好cuda版本的安装<br><code>conda install tensorflow-gpu==1.9.0 cudatoolkit==8.0</code></p><h2 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h2><p>多个model对比train, validation效果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=name1:/path/to/logs/1,name2:/path/to/logs/2</span><br></pre></td></tr></table></figure><p>demo 例子: <a href="https://blog.csdn.net/qiu931110/article/details/80137287">https://blog.csdn.net/qiu931110/article/details/80137287</a><br>讲解：<a href="https://cloud.tencent.com/developer/section/1475708">https://cloud.tencent.com/developer/section/1475708</a></p><h1 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h1><h2 id="分布式-1"><a href="#分布式-1" class="headerlink" title="分布式"></a>分布式</h2><p><a href="https://yq.aliyun.com/articles/603370">参考资料:浅显易懂的分布式TensorFlow入门教程</a></p><h3 id="系统会包含三种类型的节点"><a href="#系统会包含三种类型的节点" class="headerlink" title="系统会包含三种类型的节点"></a>系统会包含三种类型的节点</h3><ul><li><strong>一个或多个参数服务器（ps server)</strong>，用来存放模型</li><li><strong>一个主worker</strong>，用来协调训练操作，负责模型的初始化，为训练步骤计数，保存模型到checkpoints中，从checkpoints中读取模型，向TensorBoard中保存summaries（需要展示的信息）。主worker还要负责分布式计算的容错机制（如果参数服务器或worker服务器崩溃）。</li><li><strong>worker服务器（包括主worker服务器）</strong>，用来执行训练操作，并向参数服务器发送更新操作。(worker服务器在这里是指多个worker节点，集群的意思，见上面结构图）</li></ul><blockquote><p>也就是说最小的集群需要包含一个主worker服务器和一个参数服务器。可以将它扩展为一个主worker服务器，多个参数服务器和多个worker服务器。<br>最好有多个参数服务器，<strong>因为worker服务器和参数服务器之间有大量的I/O通信</strong>。如果只有2个worker服务器，可能1个参数服务器可以扛得住所有的读取和更新请求。但如果你有10个worker而且你的模型非常大，一个参数服务器可能就不够了。</p></blockquote><p><strong>在分布式TensorFlow中，同样的代码会被发送到所有的节点</strong>。虽然你的main.py、train.py等会被同时发送到worker服务器和参数服务器，但<br>每个节点会依据自己的环境变量来执行不同的代码块。</p><h3 id="分布式TensorFlow代码的准备包括三个阶段"><a href="#分布式TensorFlow代码的准备包括三个阶段" class="headerlink" title="分布式TensorFlow代码的准备包括三个阶段"></a>分布式TensorFlow代码的准备包括三个阶段</h3><ol><li>定义tf.trainClusterSpec和tf.train.Server</li><li>将模型赋给参数服务器和worker服务器</li><li>配置和启动tf.train.MonitoredTrainingSession</li></ol><h2 id="PS-and-Worker"><a href="#PS-and-Worker" class="headerlink" title="PS and Worker"></a>PS and Worker</h2><p>参考:<br><a href="https://zhuanlan.zhihu.com/p/35083779">【1】分布式TensorFlow入门教程</a><br><a href="https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md">【2】Distributed TensorFlow</a><br><a href="https://www.oreilly.com/content/distributed-tensorflow/">【3】Distributed TensorFlow</a></p><h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><p>A client is typically a program that builds a TensorFlow graph and constructs a tensorflow::Session to interact with a cluster. Clients are typically written in Python or C++. <strong>A single client process can directly interact with multiple TensorFlow servers</strong> (see “Replicated training” above), <strong>and a single server can serve multiple clients</strong>.<br>server在这里是服务者的角色，无论是ps还是worker都是server,我们可以建立多个server,服务与多个client。比如有个worker server已经建立，A用client建立一个regression任务是使用这个server训练，B用client建立了一个CNN任务也使用了这个server，这不冲突，在资源充足情况下是可以先后使用同一个server的。</p><h3 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h3><p>A job comprises a list of “tasks”, which typically serve a common purpose. For example, a job named ps (for “parameter server”) typically hosts nodes that store and update variables; while a job named worker typically hosts stateless nodes that perform compute-intensive tasks. The tasks in a job typically run on different machines. The set of job roles is flexible: for example, a worker may maintain some state.<br>注意原则上ps和worker两种job功能不同</p><ul><li>ps (parameter server)：hosts nodes that <strong>store</strong> and <strong>update</strong> variables;</li><li>worker：hosts <strong>stateless</strong> nodes that perform <strong>compute-intensive tasks</strong>.<br>虽然规则上这样各司其职，但实际上并不一定需要严格这样执行，job的角色是灵活的，比如，worker也可以维护一些状态（state)<h3 id="Master-service"><a href="#Master-service" class="headerlink" title="Master service"></a>Master service</h3>An RPC service that provides remote access to a set of distributed devices, and <strong>acts as a session target.</strong> The master service implements the tensorflow::Session interface, and is responsible for coordinating work across one or more “worker services”. <strong>All TensorFlow servers implement the master service.</strong><br>具体理解参照下面的例子：</li></ul><p>在【1】的例子中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># example.py</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">tf.app.flags.DEFINE_string(&quot;ps_hosts&quot;, &quot;localhost:2222&quot;, &quot;ps hosts&quot;)</span><br><span class="line">tf.app.flags.DEFINE_string(&quot;worker_hosts&quot;, &quot;localhost:2223,localhost:2224&quot;, &quot;worker hosts&quot;)</span><br><span class="line">tf.app.flags.DEFINE_string(&quot;job_name&quot;, &quot;worker&quot;, &quot;&#x27;ps&#x27; or&#x27;worker&#x27;&quot;)</span><br><span class="line">tf.app.flags.DEFINE_integer(&quot;task_index&quot;, 0, &quot;Index of task within the job&quot;)</span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line">def main(_):</span><br><span class="line">    ps_hosts = FLAGS.ps_hosts.split(&quot;,&quot;)</span><br><span class="line">    worker_hosts = FLAGS.worker_hosts.split(&quot;,&quot;)</span><br><span class="line">    # create cluster</span><br><span class="line">    cluster = tf.train.ClusterSpec(&#123;&quot;ps&quot;: ps_hosts, &quot;worker&quot;: worker_hosts&#125;)</span><br><span class="line">    # create the server</span><br><span class="line">    server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)</span><br><span class="line">    server.join()</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure><p>exmple.py用来建立执行不同功能的server，执行上面的example.py来生成不同的<strong>server</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python example.py --job_name=ps --task_index=0</span><br><span class="line">python example.py --job_name=worker --task_index=0</span><br><span class="line">python example.py --job_name=worker --task_index=1</span><br></pre></td></tr></table></figure><p>以work-0为例子，打印日志如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2020-03-20 15:50:24.761196: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job ps -&gt; &#123;0 -&gt; localhost:2222&#125;</span><br><span class="line">2020-03-20 15:50:24.761240: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -&gt; &#123;0 -&gt; localhost:2223, 1 -&gt; localhost:2224&#125;</span><br><span class="line">2020-03-20 15:50:24.762191: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:2223</span><br></pre></td></tr></table></figure><p>日志里显示了当前server的grpc地址，以及server所知道的其他集群信息，这是理所应当，如果我们需要协调分布式任务，必然需要知道其他服务的信息，这样才可以通信协调工作。<br>到目前为止，server已经建立，也就意味着资源已经建立，而接下来我们就可以通过client使用这些资源来完成分布式任务了。<br>我们创建一个client来执行一个计算图，并且采用/job:worker/task:0这个server所对应的<strong>master</strong>，即grpc://localhost:2223来创建Session，如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#client.py</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    with tf.device(&quot;/job:ps/task:0&quot;):</span><br><span class="line">        x = tf.Variable(tf.ones([2, 2]))</span><br><span class="line">        y = tf.Variable(tf.ones([2, 2]))</span><br><span class="line"></span><br><span class="line">    with tf.device(&quot;/job:worker/task:0&quot;):</span><br><span class="line">        z = tf.matmul(x, y) + x</span><br><span class="line"></span><br><span class="line">    with tf.device(&quot;/job:worker/task:1&quot;):</span><br><span class="line">        z = tf.matmul(z, x) + x</span><br><span class="line"></span><br><span class="line">    with tf.Session(&quot;grpc://localhost:2223&quot;) as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        val = sess.run(z)</span><br><span class="line">        print(val)</span><br></pre></td></tr></table></figure><p>其实这个client就是一个进程，但是其在计算时需要依靠cluster中的device来执行部分计算子图。这时候各个server的日志中，只有2223的日志发生了变化，多了一行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">2020-03-20 15:55:50.796022: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session b7f2e9eb1f8c5548 with config:</span><br></pre></td></tr></table></figure><h2 id="Between-graph-replication"><a href="#Between-graph-replication" class="headerlink" title="Between-graph replication"></a>Between-graph replication</h2><p>在Between-graph replication中，各个worker都包含一个client，它们构建相同的计算图，然后把参数放在ps上，TensorFlow提供了一个专门的函数tf.train.replica_device_setter来方便Graph构建，先看代码【1】：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># cluster包含两个ps 和三个 worker</span><br><span class="line">cluster_spec = &#123;</span><br><span class="line">    &quot;ps&quot;: [&quot;ps0:2222&quot;, &quot;ps1:2222&quot;],</span><br><span class="line">    &quot;worker&quot;: [&quot;worker0:2222&quot;, &quot;worker1:2222&quot;, &quot;worker2:2222&quot;]&#125;</span><br><span class="line">cluster = tf.train.ClusterSpec(cluster_spec)</span><br><span class="line">with tf.device(tf.train.replica_device_setter(</span><br><span class="line">                worker_device=&quot;/job:worker/task:%d&quot; % FLAGS.task_index,</span><br><span class="line">               cluster=cluster)):</span><br><span class="line">  # Build your graph</span><br><span class="line">  v1 = tf.Variable(...)  # assigned to /job:ps/task:0</span><br><span class="line">  v2 = tf.Variable(...)  # assigned to /job:ps/task:1</span><br><span class="line">  v3 = tf.Variable(...)  # assigned to /job:ps/task:0</span><br><span class="line">  # Run compute</span><br></pre></td></tr></table></figure><p>使用<strong>tf.train.replica_device_setter</strong>可以自动把Graph中的Variables放到ps上，而同时将Graph的计算部分放置在当前worker上，省去了很多麻烦。由于ps往往不止一个，这个函数在为各个Variable分配ps时默认采用简单的round-robin方式，就是按次序将参数挨个放到各个ps上，但这个方式可能不能使ps负载均衡，如果需要更加合理，可以采用tf.contrib.training.GreedyLoadBalancingStrategy策略。<br>采用Between-graph replication方式的另外一个问题，由于各个worker都独立拥有自己的client，但是对于一些公共操作比如模型参数初始化与checkpoint文件保存等，如果每个client都独立进行这些操作，显然是对资源的浪费。为了解决这个问题，一般会指定一个worker为chief worker，它将作为各个worker的管家，协调它们之间的训练，并且完成模型初始化和模型保存和恢复等公共操作。在TensorFlow中，可以使用tf.train.MonitoredTrainingSession创建client的Session，并且其可以指定哪个worker是chief worker。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;基本元素&quot;&gt;&lt;a href=&quot;#基本元素&quot; class=&quot;headerlink&quot; title=&quot;基本元素&quot;&gt;&lt;/a&gt;基本元素&lt;/h2&gt;&lt;h3 id=&quot;tf-Variable-……&quot;&gt;&lt;a href=&quot;#tf-Variable-……&quot; class=&quot;headerlink&quot; title=&quot;tf.Variable(……)&quot;&gt;&lt;/a&gt;tf.Variable(……)&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; tensorflow &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;A = tf.Variable(&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, name=&lt;span class=&quot;string&quot;&gt;&amp;quot;number&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;B = tf.Variable([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;], name=&lt;span class=&quot;string&quot;&gt;&amp;quot;vector&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;C = tf.Variable([[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;],[&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;]], name=&lt;span class=&quot;string&quot;&gt;&amp;quot;matrix&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;D = tf.Variable(tf.zeros([&lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;]), name=&lt;span class=&quot;string&quot;&gt;&amp;quot;zero&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;E = tf.Variable(tf.random_normal([&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;], mean=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, stddev=&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, dtype=tf.float32))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们可以把函数variable()理解为构造函数，构造函数的使用需要初始值，而这个初始值是一个任何形状、类型的Tensor。&lt;br&gt;变量有两个重要的步骤，先后为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建&lt;/li&gt;
&lt;li&gt;初始化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;变量在使用前一定要进行初始化，且变量的初始化必须在模型的其它操作运行之前完成，通常，变量的初始化有三种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1.初始化全部变量&lt;br&gt;&lt;code&gt;init = tf.global_variables_initializer()&lt;/code&gt;&lt;br&gt;global_variables_initializer()方法是不管全局有多少个变量，全部进行初始化，是最简单也是最常用的一种方式；&lt;/li&gt;
&lt;li&gt;2.初始化变量的子集&lt;br&gt;&lt;code&gt;init_subset=tf.variables_initializer([b,c], name=&amp;quot;init_subset&amp;quot;)&lt;/code&gt;&lt;br&gt;variables_initializer()是初始化变量的子集，相比于全部初始化化的方式更加节约内存&lt;/li&gt;
&lt;li&gt;3.初始化单个变量&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>recommendation_system</title>
    <link href="http://yoursite.com/2024/06/04/recommendation-system/"/>
    <id>http://yoursite.com/2024/06/04/recommendation-system/</id>
    <published>2024-06-04T07:13:36.000Z</published>
    <updated>2025-05-22T05:50:40.080Z</updated>
    
    <content type="html"><![CDATA[<p>使用Embedding策略在各种任务场景中提取用户信息的paper<br>《Modeling User Activities on the Web using Paragraph Vector》<br>:用户在浏览网页的时候会留下来一系列的行为，比方说网页浏览，搜索问题，点击广告等，设用户$i$留下的 $T$个行为表示为$(a<em>{i,1},a</em>{i,2}….,a_{i,Ti})$<br> )。我们希望根据所有的用户行为数据，生成表征每一个用户的向量，使具有相同行为序列的用户被映射到相似的向量空间之中。我们希望根据所有的用户行为数据，生成表征每一个用户的向量，使具有相同行为序列的用户被映射到相似的向量空间之中。<br>该论文借鉴了skip-gram 的思想</p><h2 id="Deep-amp-Cross-Network-for-Ad-Click-Predictions"><a href="#Deep-amp-Cross-Network-for-Ad-Click-Predictions" class="headerlink" title="Deep &amp; Cross Network for Ad Click Predictions"></a>Deep &amp; Cross Network for Ad Click Predictions</h2><p><a href="https://blog.csdn.net/Dby_freedom/article/details/86502623">https://blog.csdn.net/Dby_freedom/article/details/86502623</a><br><a href="https://blog.csdn.net/qq_40778406/article/details/105009989">https://blog.csdn.net/qq_40778406/article/details/105009989</a><br><a href="https://www.cnblogs.com/LuckPsyduck/p/11995230.html">https://www.cnblogs.com/LuckPsyduck/p/11995230.html</a><br><a href="https://zhuanlan.zhihu.com/p/96010464">https://zhuanlan.zhihu.com/p/96010464</a></p><span id="more"></span><h2 id="RankNet"><a href="#RankNet" class="headerlink" title="RankNet"></a>RankNet</h2><p><a href="https://www.cnblogs.com/kemaswill/p/kemaswill.html">https://www.cnblogs.com/kemaswill/p/kemaswill.html</a></p><script type="math/tex; mode=display">C_{i j}=-\bar{P}_{i j} o_{i j}+\log \left(1+e^{o_{i j}}\right)</script><p> 2019-09-06 15:37:39<br>vin word2vec # word2vec</p><p>标签（空格分隔）： word2vec</p><hr><p>![word2word][1]<br>对于上图，以前直觉对于skip-gram模型，有这样一个疑问<br>比如：<br>词汇表有V个，所以我们的输入是V-dimension的向量，对于句子：<br>“what are you doing now”<br>对于skip-gram方式：<br>输入 x 是 you 的one-hot向量，<br>输出 y 是 V 维度向量，这个向量可以直接把what, are, doing, now四个词的index位置点亮唯1，然后计算损失函数，这样的方式不是更好吗？</p><p>某天回看word2vec模型结构图突然明白，这是不合理的，因为context是有“序”的信息的，如果类似bag-of-words的方式处理，所达到的效果<strong>只关注word是否出现，而丢掉了序的信息</strong>。<br>所以正确的网络结构应该是这样的：<br>![skip-gram][2]</p><p>  [2]: <a href="https://pic1.zhimg.com/80/v2-ca81e19caa378cee6d4ba6d867f4fc7c_hd.jpg">https://pic1.zhimg.com/80/v2-ca81e19caa378cee6d4ba6d867f4fc7c_hd.jpg</a> 2019-09-12 10:25:43</p><h2 id="CTR"><a href="#CTR" class="headerlink" title="CTR"></a>CTR</h2><h3 id="Deep-Interest-Network"><a href="#Deep-Interest-Network" class="headerlink" title="Deep Interest Network"></a>Deep Interest Network</h3><p>《Deep Interest Network for Click-Through Rate Prediction》<br><a href="https://mp.weixin.qq.com/s/V6tjQzfzsekXuoXhbXbKSQ">【传送门】</a></p><p><strong>总结</strong>：</p><ol><li><p>用户有多个兴趣爱好，访问了多个 good_id，shop_id。为了降低纬度并使得商品店铺间的算术运算有意义，我们先对其进行 Embedding 嵌入。那么我们如何对用户多种多样的兴趣建模那？使用 Pooling 对 Embedding Vector 求和或者求平均。同时这也解决了不同用户输入长度不同的问题，得到了一个固定长度的向量。这个向量就是用户表示，是用户兴趣的代表。</p></li><li><p>但是，直接求 sum 或 average 损失了很多信息。所以稍加改进，针对不同的 behavior id 赋予不同的权重，这个权重是由当前 behavior id 和候选广告共同决定的。这就是 Attention 机制，实现了 Local Activation。</p></li><li><p>DIN 使用 <strong>activation unit</strong> 来捕获 <strong>local activation</strong> 的特征，使用 <strong>weighted sum pooling</strong> 来捕获 <strong>diversity</strong> 结构。</p></li><li><p>在模型学习优化上，DIN 提出了 Dice 激活函数、自适应正则 ，显著的提升了模型性能与收敛速度。</p></li></ol><p>参考资料</p><ol><li><p>Deep Interest Network for Click-Through Rate Prediction</p></li><li><p>Learning piece-wise linear models from large scale data for ad click prediction</p></li><li><p><a href="https://www.leiphone.com/news/201707/t0AT4sIgyWS2QWVU.html">https://www.leiphone.com/news/201707/t0AT4sIgyWS2QWVU.html</a></p></li><li><p><a href="https://www.leiphone.com/news/201706/pDfOAoMYp8mqNKEC.html">https://www.leiphone.com/news/201706/pDfOAoMYp8mqNKEC.html</a></p></li><li><p>盖坤的分享视频 <a href="http://www.itdks.com/dakalive/detail/3166">http://www.itdks.com/dakalive/detail/3166</a></p></li></ol><h2 id="BPR"><a href="#BPR" class="headerlink" title="BPR"></a>BPR</h2><script type="math/tex; mode=display">\begin{aligned}\text { BPR-OPT } &:=\ln p\left(\Theta \mid>_{u}\right) \\&=\ln p\left(>_{u} \mid \Theta\right) p(\Theta) \\&=\ln \prod_{(u, i, j) \in D_{S}} \sigma\left(\hat{x}_{u i j}\right) p(\Theta) \\&=\sum_{(u, i, j) \in D_{S}} \ln \sigma\left(\hat{x}_{u i j}\right)+\ln p(\Theta) \\&=\sum_{(u, i, j) \in D_{S}} \ln \sigma\left(\hat{x}_{u i j}\right)-\lambda_{\Theta}\|\Theta\|^{2}\end{aligned}</script><p>Here $\hat{x}_{u i j}(\Theta)$ is an arbitrary real-valued function of<br>the model parameter vector $\Theta$ which captures the special relationship between user $u$, item $i$ and item $j$.</p><p>Here,$&gt;u$  is the desired but latent preference structure<br>for user u. All users are presumed to act independently<br>of each other.</p><p><a href="https://cloud.tencent.com/developer/article/1164759">https://cloud.tencent.com/developer/article/1164759</a><br>排序推荐算法大体上可以分为三类，第一类排序算法类别是点对方法(Pointwise Approach)，这类算法将排序问题被转化为分类、回归之类的问题，并使用现有分类、回归等方法进行实现。第二类排序算法是成对方法(Pairwise Approach)，在序列方法中，排序被转化为对序列分类或对序列回归。所谓的pair就是成对的排序，比如(a,b)一组表明a比b排的靠前。第三类排序算法是列表方法(Listwise Approach)，它采用更加直接的方法对排序问题进行了处理。它在学习和预测过程中都将排序列表作为一个样本。排序的组结构被保持<br>我们构造的训练数据是<u,i,j>的三元组，i可以根据刚才生成的用户评分字典得到，j可以利用负采样的思想，认为用户没有看过的电影都是负样本：</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>1.BPR是基于矩阵分解的一种排序算法，它不是做全局的评分优化，而是针对每一个用户自己的商品喜好分贝做排序优化。<br>2.它是一种<strong>pairwise</strong>的排序算法，对于每一个三元组<u,i,j>，模型希望能够使用户u对物品i和j的差异更明显。<br>3.同时，引入了<strong>贝叶斯先验</strong>，假设参数服从正态分布，在转换后变为了L2正则，减小了模型的过拟合</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;使用Embedding策略在各种任务场景中提取用户信息的paper&lt;br&gt;《Modeling User Activities on the Web using Paragraph Vector》&lt;br&gt;:用户在浏览网页的时候会留下来一系列的行为，比方说网页浏览，搜索问题，点击广告等，设用户$i$留下的 $T$个行为表示为$(a&lt;em&gt;{i,1},a&lt;/em&gt;{i,2}….,a_{i,Ti})$&lt;br&gt; )。我们希望根据所有的用户行为数据，生成表征每一个用户的向量，使具有相同行为序列的用户被映射到相似的向量空间之中。我们希望根据所有的用户行为数据，生成表征每一个用户的向量，使具有相同行为序列的用户被映射到相似的向量空间之中。&lt;br&gt;该论文借鉴了skip-gram 的思想&lt;/p&gt;
&lt;h2 id=&quot;Deep-amp-Cross-Network-for-Ad-Click-Predictions&quot;&gt;&lt;a href=&quot;#Deep-amp-Cross-Network-for-Ad-Click-Predictions&quot; class=&quot;headerlink&quot; title=&quot;Deep &amp;amp; Cross Network for Ad Click Predictions&quot;&gt;&lt;/a&gt;Deep &amp;amp; Cross Network for Ad Click Predictions&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/Dby_freedom/article/details/86502623&quot;&gt;https://blog.csdn.net/Dby_freedom/article/details/86502623&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/qq_40778406/article/details/105009989&quot;&gt;https://blog.csdn.net/qq_40778406/article/details/105009989&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.cnblogs.com/LuckPsyduck/p/11995230.html&quot;&gt;https://www.cnblogs.com/LuckPsyduck/p/11995230.html&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/96010464&quot;&gt;https://zhuanlan.zhihu.com/p/96010464&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>hive</title>
    <link href="http://yoursite.com/2024/06/04/hive/"/>
    <id>http://yoursite.com/2024/06/04/hive/</id>
    <published>2024-06-04T07:11:19.000Z</published>
    <updated>2025-05-22T05:50:40.064Z</updated>
    
    <content type="html"><![CDATA[<h2 id="查看表的信息"><a href="#查看表的信息" class="headerlink" title="查看表的信息"></a>查看表的信息</h2><p>可以看到表的 location, tableType等<br>根据Table Type值可以知道表是内部表还是外部表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">describe extended tablename</span><br><span class="line">desc formatted tablename;</span><br></pre></td></tr></table></figure><p>查看表分区</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;show partitions <span class="variable">$&#123;table_name&#125;</span></span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="Hive-输出日志分析"><a href="#Hive-输出日志分析" class="headerlink" title="Hive 输出日志分析"></a>Hive 输出日志分析</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">Partition xxx&#123;dt=2019-11-12&#125; stats: [numFiles=6, numRows=15677698, totalSize=1281943134, rawDataSize=1266265436]</span><br><span class="line">……</span><br></pre></td></tr></table></figure><p>numRows 是本次hive执行生成的数据量，这里要注意，实际查看这个数字时遇到一个现象：<br>hql-1:   insert overwrite 3 line on partition (dt = ‘2019-11-11’)<br>hql-2:   insert into 2 line on partition (dt = ‘2019-11-11’)<br>在执行hql-2的时候，日志最后显示的numRows=5, 原本的理解时这里应该是2，从我角度理解来看这应该是指hive会重新整理数据，整理的数据包括上一次已经插入表中的3条数据，所以最后产生的数据是5。</p><h2 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h2><h3 id="create"><a href="#create" class="headerlink" title="create"></a>create</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> $&#123;prod_stat&#125;;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;prod_stat&#125;</span><br><span class="line">(</span><br><span class="line">    sku        string,</span><br><span class="line">    cnt        string</span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (dt string)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> orc</span><br><span class="line">LOCATION <span class="string">&#x27;$tbl_hdfs&#x27;</span></span><br><span class="line">TBLPROPERTIES (&quot;orc.compress&quot;<span class="operator">=</span>&quot;SNAPPY&quot;);</span><br></pre></td></tr></table></figure><p>创建双字段分区表：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">create table <span class="keyword">if</span> <span class="keyword">not</span> exists $&#123;overlap_table_name&#125;</span><br><span class="line">(</span><br><span class="line">    expo_uv string,</span><br><span class="line">    clk_pv string,</span><br><span class="line">)</span><br><span class="line">partitioned by (dt string, contain_in_skus boolean)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">location <span class="string">&#x27;hdfs://ns1013/user/recsys/recpro/tmpr.db/xxx&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#插入数据</span></span><br><span class="line"></span><br><span class="line">insert overwrite table $&#123;overlap_table_name&#125; partition(dt=<span class="string">&#x27;$&#123;dt&#125;&#x27;</span>)</span><br><span class="line">select ....</span><br></pre></td></tr></table></figure><h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">truncate</span> <span class="keyword">table</span> table_name;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> table_name <span class="keyword">drop</span> <span class="keyword">partition</span> (partition_name<span class="operator">=</span><span class="string">&#x27;yyyy-mm-dd&#x27;</span>)</span><br></pre></td></tr></table></figure><h4 id="除hive内部表，不会删除数据的方法探索"><a href="#除hive内部表，不会删除数据的方法探索" class="headerlink" title="除hive内部表，不会删除数据的方法探索"></a>除hive内部表，不会删除数据的方法探索</h4><p><a href="https://blog.csdn.net/qomoman/article/details/50516560">https://blog.csdn.net/qomoman/article/details/50516560</a><br>亲测第一种方法可行</p><h5 id="方法一：将内部表改成外部表"><a href="#方法一：将内部表改成外部表" class="headerlink" title="方法一：将内部表改成外部表"></a>方法一：将内部表改成外部表</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alter table table_name set TBLPROPERTIES(&#x27;EXTERNAL&#x27;=&#x27;TRUE&#x27;);//内部表转外部表</span><br><span class="line">drop table table_name</span><br></pre></td></tr></table></figure><h5 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h5><ol><li>将表的名字改掉<br><code>alter table table_name rename to table_name_temp</code></li><li>将表的数据所存放的目录改掉<br><code>hadoop   fs -mv  /user/hive/warehouse/table_name_temp /user/hive/warehouse/table_name</code></li><li><code>drop table table_name</code></li></ol><h4 id="删除分区"><a href="#删除分区" class="headerlink" title="删除分区"></a>删除分区</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table tmpr.table drop partition(dt&gt;=&#x27;2021-01-05&#x27;, dt&lt;=&#x27;2021-03-08&#x27;)</span><br></pre></td></tr></table></figure><h3 id="内部表和外部表区别"><a href="#内部表和外部表区别" class="headerlink" title="内部表和外部表区别"></a>内部表和外部表区别</h3><p>1 删除内表时，内表数据会一并删除；<br>2 删除外表时，外表数据依旧存在。</p><h3 id="like"><a href="#like" class="headerlink" title="like"></a>like</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hql=<span class="string">&quot;drop table <span class="variable">$&#123;hp_few_sku&#125;</span>;</span></span><br><span class="line"><span class="string">create table <span class="variable">$&#123;hp_few_sku&#125;</span></span></span><br><span class="line"><span class="string">like <span class="variable">$&#123;hp_table&#125;</span></span></span><br><span class="line"><span class="string">location &#x27;<span class="variable">$&#123;location&#125;</span>&#x27;</span></span><br><span class="line"><span class="string">;</span></span><br></pre></td></tr></table></figure><h3 id="alter"><a href="#alter" class="headerlink" title="alter"></a>alter</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> name RENAME <span class="keyword">TO</span> new_name</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> name <span class="keyword">ADD</span> COLUMNS (col_spec[, col_spec ...])</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> name <span class="keyword">DROP</span> [<span class="keyword">COLUMN</span>] column_name</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> name CHANGE column_name new_name new_type</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> name REPLACE COLUMNS (col_spec[, col_spec ...])</span><br></pre></td></tr></table></figure><h3 id="创建表可以包含的关键字"><a href="#创建表可以包含的关键字" class="headerlink" title="创建表可以包含的关键字"></a>创建表可以包含的关键字</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name</span><br><span class="line">   [(col_name data_type [COMMENT col_comment], ...)]:指定表的名称和表的具体列信息。</span><br><span class="line">   [COMMENT table_comment] :表的描述信息。</span><br><span class="line">   [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]:表的分区信息。</span><br><span class="line">   [CLUSTERED BY (col_name, col_name, ...) </span><br><span class="line">   [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]:表的桶信息。</span><br><span class="line">   [ROW FORMAT row_format] :表的数据分割信息，格式化信息。</span><br><span class="line">   [STORED AS file_format] :表数据的存储序列化信息。</span><br><span class="line">   [LOCATION hdfs_path] :数据存储的文件夹地址信息。</span><br></pre></td></tr></table></figure><h2 id="Insert"><a href="#Insert" class="headerlink" title="Insert"></a>Insert</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">INSERT OVERWRITE [ LOCAL ] DIRECTORY directory_path</span><br><span class="line">    [ ROW FORMAT row_format ] [ STORED AS file_format ]</span><br><span class="line">    &#123; VALUES ( &#123; value | NULL &#125; [ , ... ] ) [ , ( ... ) ] | query &#125;</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory1 </span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span> </span><br><span class="line">select_statement1;</span><br></pre></td></tr></table></figure><h3 id="生成数据常用config"><a href="#生成数据常用config" class="headerlink" title="生成数据常用config"></a>生成数据常用config</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">set mapred.max.split.size=524288000;</span><br><span class="line">set mapred.min.split.size=524288000;</span><br><span class="line">set mapred.min.split.size.per.node=524288000;</span><br><span class="line">set mapred.min.split.size.per.rack=524288000;</span><br><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br><span class="line">set hive.merge.mapfiles = true;</span><br><span class="line">set hive.merge.mapredfiles = true;</span><br><span class="line">set hive.merge.size.per.task = 256000000;</span><br><span class="line">set hive.merge.smallfiles.avgsize = 104857600;</span><br></pre></td></tr></table></figure><h2 id="从本地导入数据到表中"><a href="#从本地导入数据到表中" class="headerlink" title="从本地导入数据到表中"></a>从本地导入数据到表中</h2><p>load data inpath ‘filepath’ into table tablename<br>这里的filepath是hdfs路径，而非本地文本文件路径，所以最好将文本文件上传至hdfs目录, 然后再导入<a href="https://blog.csdn.net/xiongbingcool/article/details/82982099">【参考】</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put &#x27;local_file_path&#x27; &#x27;hdfs://……/user/local/user.login_log&#x27;</span><br></pre></td></tr></table></figure><p>导入本地数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [LOCAL] INPATH &#x27;filepath&#x27; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]</span><br></pre></td></tr></table></figure><p>这里需要注意的是如果使用的时：当使用hdf路径时不加local,即：<code>load data inpath hdfs://xxxx/data/</code>，并且在导入数据后会<strong>源地址数据会被删除</strong><br>example</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data inpath &#x27;hdfs://ns1007/user/recsys/recpro/yuanwenwu3/tmpr.feedback_bad_1200_in_15&#x27; overwrite into table tmpr.feedback_bad_1200_in_15 partition(dt=&#x27;2019-09-03&#x27;);</span><br></pre></td></tr></table></figure><h2 id="简略流程"><a href="#简略流程" class="headerlink" title="简略流程"></a>简略流程</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># step-1 创建临时表</span><br><span class="line">create table if not exists zx_user.temp_ly_sentitive_phone(phone STRING)</span><br><span class="line">row format delimited</span><br><span class="line">fields terminated by &#x27;,&#x27;</span><br><span class="line">stored as textfile;</span><br><span class="line"># step-2 将本地数据导入临时表</span><br><span class="line">LOAD DATA local INPATH &#x27;/home/zx_user/fmd5_0916_1021/sentitive_phone.csv&#x27; INTO TABLE zx_user.temp_ly_sentitive_phone</span><br><span class="line"># step-3 验证</span><br><span class="line">select * from zx_user.temp_ly_sentitive_phone_200917 limit 1;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="查询SQL语句"><a href="#查询SQL语句" class="headerlink" title="查询SQL语句"></a>查询SQL语句</h2><h3 id="按照排序截取指定位置的数据"><a href="#按照排序截取指定位置的数据" class="headerlink" title="按照排序截取指定位置的数据"></a>按照排序截取指定位置的数据</h3><p>场景：按照某一字段排序，然后选择第排序1000位置的数据</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> </span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span> name,</span><br><span class="line">    cnt,</span><br><span class="line">    <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> cnt <span class="keyword">desc</span>) <span class="keyword">as</span> rank </span><br><span class="line">    <span class="keyword">from</span> tmpr.yuan_test</span><br><span class="line">) a </span><br><span class="line"><span class="keyword">where</span> a.rank <span class="operator">=</span> <span class="number">3</span>;</span><br></pre></td></tr></table></figure><h2 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put /home/user/train.tar.gz <span class="string">&#x27;hdfs://ns1013/user/.../train&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get <span class="string">&#x27;hdfs://ns1013/user/.../train&#x27;</span> /home/user/train.tar.gz</span><br></pre></td></tr></table></figure><h2 id="hadoop-查看文件大小"><a href="#hadoop-查看文件大小" class="headerlink" title="hadoop 查看文件大小"></a>hadoop 查看文件大小</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">du</span> -s -h hdfs://ns1013/0530/train/data/</span><br><span class="line"><span class="comment"># -h humanity</span></span><br></pre></td></tr></table></figure><h2 id="hadoop-更改组权限"><a href="#hadoop-更改组权限" class="headerlink" title="hadoop 更改组权限"></a>hadoop 更改组权限</h2><p>hadoop fs -chgrp -R user1</p><h2 id="LEFT-JOIN-后面接AND和接WHERE的区别"><a href="#LEFT-JOIN-后面接AND和接WHERE的区别" class="headerlink" title="LEFT JOIN 后面接AND和接WHERE的区别"></a>LEFT JOIN 后面接AND和接WHERE的区别</h2><p>参考博客<a href="https://blog.csdn.net/henrrywan/article/details/90207961">例子</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[nd1:21000] default&gt; select * from test_user;</span><br><span class="line">+----+------+-----+---------+</span><br><span class="line">| id | name | age | classid | </span><br><span class="line">+----+------+-----+---------+</span><br><span class="line">| 1  | 张三 | 20  | 1       |</span><br><span class="line">| 2  | 李四 | 21  | 1       |</span><br><span class="line">| 3  | 王五 | 22  | 2       | </span><br><span class="line">| 4  | Lucy | 18  | 3       |</span><br><span class="line">| 5  | Jack | 18  | 3       |</span><br><span class="line">| 6  | Tom  | 18  | 3       |</span><br><span class="line">+----+------+-----+---------+</span><br><span class="line"></span><br><span class="line">[nd1:21000] default&gt; select * from test_class;</span><br><span class="line">+----+----------+</span><br><span class="line">| id | classname|</span><br><span class="line">+----+----------+</span><br><span class="line">| 1  | class101 |</span><br><span class="line">| 2  | class102 |</span><br><span class="line">| 3  | class103 |</span><br><span class="line">| 4  | class104 |</span><br><span class="line">+----+----------+</span><br></pre></td></tr></table></figure><h3 id="带ON和AND的SQL查询"><a href="#带ON和AND的SQL查询" class="headerlink" title="带ON和AND的SQL查询"></a>带ON和AND的SQL查询</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">select t1.id,t1.name,t2.classname from test_user t1</span><br><span class="line">left join test_class t2 </span><br><span class="line">on t1.classid=t2.id and t1.id=1</span><br><span class="line"></span><br><span class="line">+----+------+----------+</span><br><span class="line">| id | name | classname|</span><br><span class="line">+----+------+----------+</span><br><span class="line">| 1  | 张三 | class101 | </span><br><span class="line">| 2  | 李四 | NULL     | </span><br><span class="line">| 3  | 王五 | NULL     | </span><br><span class="line">| 4  | Lucy | NULL     |</span><br><span class="line">| 5  | Jack | NULL     | </span><br><span class="line">| 6  | Tom  | NULL     | </span><br><span class="line">+----+------+----------+</span><br><span class="line"></span><br><span class="line">--这里我们把on后面的查询条件放在括号里面，结果一致。</span><br><span class="line">select t1.id,t1.name,t2.classname from test_user t1</span><br><span class="line">left join test_class  t2 </span><br><span class="line">on (t1.classid = t2.id and t1.id = 1)</span><br></pre></td></tr></table></figure><p>对于left join，<strong>on条件是在生成临时表时使用的条件(参照上面的博客，这里用来过滤t2表的数据，而t1的数据全部显示，也就是说关联上了就显示t2数据，关联不上就显示NULL)</strong>，它不管on中的条件是否为真，都会返回左边表中的记录，on后面的只作为关联条件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">select t1.id,t1.name,t2.classname from test_user t1</span><br><span class="line">left join test_class t2</span><br><span class="line">on t1.classid=t2.id</span><br><span class="line">where t1.id=1</span><br><span class="line"></span><br><span class="line">+----+------+----------+</span><br><span class="line">| id | name | classname| </span><br><span class="line">+----+------+----------+</span><br><span class="line">| 1  | 张三 | class101 |</span><br><span class="line">+----+------+----------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>where条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉</strong><br>其实比较好的写法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select u.id, u.name, c.classname from (select * from test_user where id = 1) u left join test_class c on u.classid=c.id;</span><br></pre></td></tr></table></figure><p>尽量使用left join-on-where标准写法<strong>，on只出现连接字段</strong>，过滤条件放在where里面。</p><p>对于inner join 则没有这个顾虑，在join的过程正过滤掉数据有利于提高效率<br>主要结论如下：</p><ul><li>LEFT JOIN 后面如果只接ON查询，会显示所有左表的数据，右表中的数据是否显示取决于后面的查询条件</li><li>LEFT JOIN 后面接WHERE查询，会根据WHERE条件先对数据进行过滤</li><li>LEFT JOIN 后面条件查询，条件一定不要恒为真，否则会出现笛卡尔积</li><li>LEFT JOIN 后面条件查询，条件一定不要恒为假，否则查询结果中右表数据始终为NULL</li><li>RIGHT JOIN 和LEFT JOIN 特性相同，INNER JOIN没这个特殊性，不管条件是放在ON中，还是放在WHERE中，返回的结果集是相同的</li></ul><h2 id="Rack-amp-Node-amp-cluster"><a href="#Rack-amp-Node-amp-cluster" class="headerlink" title="Rack &amp; Node &amp; cluster"></a>Rack &amp; Node &amp; cluster</h2><p>参考<a href="https://www.quora.com/What-is-the-rack-in-a-Hadoop-cluster-How-does-it-work">回答</a></p><p>一个node就是一台电脑，一堆nodes的存储空间被称作rack。通常一个rack是30-40个有实际物理存储空间的nodes组成的，且这些nodes位置比较近，且连接于同一个network switch(交换机)。基于这个结构可知：同一rack中的任意两个nodes之间通信的带宽大于不同ranck中的nodes。一个Hadoop Cluster就是racks的集合。</p><blockquote><p>Whenever any data is stored in hdfs ,it is replicated (default 3) in which two copies are in same rack and one outside the rack. So that if whole rack goes down then also data can be retrived.</p></blockquote><p>(上面这一点即Data protection against rack failure）</p><h3 id="Rack-Awareness"><a href="#Rack-Awareness" class="headerlink" title="Rack Awareness"></a>Rack Awareness</h3><p>In a large cluster of Hadoop, in order to improve the network traffic while reading/writing HDFS file, <strong>namenode chooses the datanode which is closer to the same rack or nearby rack to Read/Write request</strong>. Namenode achieves rack information by maintaining the rack id’s of each datanode. This concept that chooses closer datanodes based on the rack information is called <strong>Rack Awareness</strong> in Hadoop.</p><h3 id="node"><a href="#node" class="headerlink" title="node"></a>node</h3><p>A node in hadoop simply means a computer that can be used for processing and storing. There are two types of nodes in hadoop Name node and Data node. It is called as a node as all these computers are interconnected.</p><h3 id="NameNode-and-DataNode"><a href="#NameNode-and-DataNode" class="headerlink" title="NameNode and DataNode"></a><a href="https://www.quora.com/What-is-the-difference-between-Namenode-+-Datanode-Jobtracker-+-Tasktracker-Combiners-Shufflers-and-Mappers+Reducers-in-their-technical-functionality-and-physically-ie-whether-they-are-on-the-same-machine-in-a-cluster-while-running-a-job">NameNode and DataNode</a></h3><p>Technical Sense: NameNode stores MetaData(No of Blocks, On Which Rack which DataNode the data is stored and other details) about the data being stored in DataNodes whereas the DataNode stores the actual Data.</p><p>Physical Sense: In a multinode cluster NameNode and DataNodes are usually on different machines. There is only one NameNode in a cluster and many DataNodes; Thats why we call NameNode as a single point of failure. Although There is a Secondary NameNode (SNN) that can exist on different machine which doesn’t actually act as a NameNode but stores the image of primary NameNode at certain checkpoint and is used as backup to restore NameNode.</p><h3 id="JobTracker-And-TaskTracker"><a href="#JobTracker-And-TaskTracker" class="headerlink" title="JobTracker And TaskTracker"></a>JobTracker And TaskTracker</h3><p>Technical Sense: JobTracker is a master which creates and runs the job. <strong>JobTracker which can run on the NameNode allocates the job to TaskTrackers which run on DataNodes</strong>; TaskTrackers run the tasks and report the status of task to JobTracker.</p><p>Physical Sense: The JobTracker runs on MasterNode aka NameNode whereas TaskTrackers run on DataNodes.</p><h2 id="hive中控制map-reduce数量方法"><a href="#hive中控制map-reduce数量方法" class="headerlink" title="hive中控制map reduce数量方法"></a><a href="https://blog.csdn.net/zhong_han_jun/article/details/50814246">hive中控制map reduce数量方法</a></h2><ul><li>map:</li></ul><p>set mapred.max.split.size=256000000; — 决定每个map处理的最大的文件大小，单位为B<br>set mapred.min.split.size.per.node=1; — 节点中可以处理的最小的文件大小<br>set mapred.min.split.size.per.rack=1; — 机架中可以处理的最小的文件大小</p><p>如果mapred.max.split.size = 240x1024x1024=240M</p><ol><li>假设有两个文件大小分别为(256M,280M)被分配到节点A，那么会启动两个map，剩余的文件大小为10MB和35MB因为每个大小都不足241MB会先做保留</li><li>根据参数set mapred.min.split.size.per.node看剩余的大小情况并进行合并,如果值为1，表示a中每个剩余文件都会自己起一个map，这里会起两个，如果设置为大于45<em>1024</em>1024则会合并成一个块，并产生一个map<br>如果mapred.min.split.size.per.node为10<em>1024</em>1024，那么在这个节点上一共会有4个map，处理的大小为(245MB,245MB,10MB,10MB，10MB，10MB)，余下9MB<br>如果mapred.min.split.size.per.node为45<em>1024</em>1024，那么会有三个map，处理的大小为(245MB,245MB,45MB)<br>实际中mapred.min.split.size.per.node无法准确地设置成45<em>1024</em>1024，会有剩余并保留带下一步进行判断处理</li><li>对2中余出来的文件与其它节点余出来的文件根据mapred.min.split.size.per.rack大小进行判断是否合并，对再次余出来的文件独自产生一个map处理</li></ol><ul><li>reduce:<br>方法1 set mapred.reduce.tasks=10; — 设置reduce的数量<br>方法2 set hive.exec.reducers.bytes.per.reducer=1073741824 — 每个reduce处理的数据量,默认1GB</li></ul><p>其他更细的优化参考下面两个连接未完待续<br><a href="https://www.cnblogs.com/xd502djj/p/3799432.html">资料1</a><br><a href="https://www.cnblogs.com/swordfall/p/11037539.html">资料2</a> 2019-09-04 18:09:24</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;查看表的信息&quot;&gt;&lt;a href=&quot;#查看表的信息&quot; class=&quot;headerlink&quot; title=&quot;查看表的信息&quot;&gt;&lt;/a&gt;查看表的信息&lt;/h2&gt;&lt;p&gt;可以看到表的 location, tableType等&lt;br&gt;根据Table Type值可以知道表是内部表还是外部表&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;describe extended tablename&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;desc formatted tablename;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;查看表分区&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt;&amp;gt;show partitions &lt;span class=&quot;variable&quot;&gt;$&amp;#123;table_name&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>data_process</title>
    <link href="http://yoursite.com/2024/06/04/data-process/"/>
    <id>http://yoursite.com/2024/06/04/data-process/</id>
    <published>2024-06-04T06:52:38.000Z</published>
    <updated>2025-05-22T05:50:40.064Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Byte-KB-MB的笔记"><a href="#Byte-KB-MB的笔记" class="headerlink" title="Byte, KB, MB的笔记"></a>Byte, KB, MB的笔记</h1><p><a href="http://myrepono.com/faq/4">http://myrepono.com/faq/4</a></p><blockquote><p>A byte is a sequence of 8 bits (enough to represent one alphanumeric character) processed as a single unit of information. A single letter or character would use one byte of memory (8 bits), two characters would use two bytes (16 bits).</p></blockquote><p>1024 bytes = 1 KB<br>1024 KB = 1 MB<br>1024 MB = 1 GB<br>1024 GB = 1 TB<br>1024 TB = 1 PB<br>KB = KilobyteM<br>B = MegabyteG<br>B = GigabyteT<br>B = TerabyteP<br>B = Petabyte</p><h2 id="dataframe-估算内存"><a href="#dataframe-估算内存" class="headerlink" title="dataframe 估算内存"></a>dataframe 估算内存</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">memory_usage</span>(<span class="params">df</span>):</span><br><span class="line">    types = df.dtypes</span><br><span class="line">    s = df.memory_usage(deep=<span class="literal">True</span>)</span><br><span class="line">    s = s/<span class="number">1024</span>**<span class="number">2</span></span><br><span class="line">    total_mem = s.<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">for</span> column <span class="keyword">in</span> df.columns:</span><br><span class="line">        <span class="keyword">if</span> s[column] &lt; <span class="number">0.01</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; = &#123;&#125; KB,  &#123;&#125;&quot;</span>.<span class="built_in">format</span>(column, s[column] * <span class="number">1024</span>, types[column]))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; = &#123;:1.2f&#125; MB,  &#123;&#125;&quot;</span>.<span class="built_in">format</span>(column, s[column], types[column]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;totoal memory: &#123;:.2f&#125; MB&quot;</span>.<span class="built_in">format</span>(total_mem))</span><br><span class="line"></span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="读文件"><a href="#读文件" class="headerlink" title="读文件"></a>读文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(live_data_path, names=[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;index_image&#x27;</span>, <span class="string">&#x27;view_num&#x27;</span>, <span class="string">&#x27;dt&#x27;</span>], dtype=&#123;<span class="string">&#x27;id&#x27;</span>:<span class="built_in">str</span>, <span class="string">&#x27;index_image&#x27;</span>:<span class="built_in">str</span>, <span class="string">&#x27;view_num&#x27;</span>:<span class="built_in">str</span>, <span class="string">&#x27;dt&#x27;</span>:<span class="built_in">str</span>&#125;, parse_dates=[<span class="string">&#x27;dt&#x27;</span>], index_col=[<span class="string">&#x27;id&#x27;</span>])</span><br></pre></td></tr></table></figure><h2 id="dataframe-列数据格式format"><a href="#dataframe-列数据格式format" class="headerlink" title="dataframe 列数据格式format"></a>dataframe 列数据格式format</h2><p>1.读文件时<br>frame = pandas.DataFrame({..some data..},dtype=[str,int,int])</p><p>2.读文件后<br>frame[‘some column’] = frame[‘some column’].astype(float)</p><p>3.遇到错误（NULL不能转换时）<br>df[‘count’] = df[‘count’].apply(pd.to_numeric, errors=’coerce’).fillna(0.0)</p><h2 id="pandas-取行，列的方式"><a href="#pandas-取行，列的方式" class="headerlink" title="pandas 取行，列的方式"></a>pandas 取行，列的方式</h2><p>pandas 有两种索引：</p><ol><li>name（index,column名称)</li><li>int (整数，列或行的数组位置）</li></ol><ul><li>df[…]: 用索引取</li><li>ix: int 和 name 混用，现在已经deprecated</li><li>loc: name</li><li>iloc: int</li></ul><p>参看<a href="https://www.cnblogs.com/nxf-rabbit75/p/10105271.html">《pandas取dataframe特定行/列》</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"> </span><br><span class="line">df=DataFrame(np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>,<span class="number">4</span>)),index=[<span class="string">&#x27;one&#x27;</span>,<span class="string">&#x27;two&#x27;</span>,<span class="string">&#x27;thr&#x27;</span>],columns=<span class="built_in">list</span>(<span class="string">&#x27;abcd&#x27;</span>))</span><br><span class="line"> </span><br><span class="line">df[<span class="string">&#x27;a&#x27;</span>]<span class="comment">#取a列</span></span><br><span class="line">df[[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>]]<span class="comment">#取a、b列</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#ix可以用数字索引，也可以用index和column索引</span></span><br><span class="line">df.ix[<span class="number">0</span>]<span class="comment">#取第0行</span></span><br><span class="line">df.ix[<span class="number">0</span>:<span class="number">1</span>]<span class="comment">#取第0行</span></span><br><span class="line">df.ix[<span class="string">&#x27;one&#x27;</span>:<span class="string">&#x27;two&#x27;</span>]<span class="comment">#取one、two行</span></span><br><span class="line">df.ix[<span class="number">0</span>:<span class="number">2</span>,<span class="number">0</span>]<span class="comment">#取第0、1行，第0列</span></span><br><span class="line">df.ix[<span class="number">0</span>:<span class="number">1</span>,<span class="string">&#x27;a&#x27;</span>]<span class="comment">#取第0行，a列</span></span><br><span class="line">df.ix[<span class="number">0</span>:<span class="number">2</span>,<span class="string">&#x27;a&#x27;</span>:<span class="string">&#x27;c&#x27;</span>]<span class="comment">#取第0、1行，abc列</span></span><br><span class="line">df.ix[<span class="string">&#x27;one&#x27;</span>:<span class="string">&#x27;two&#x27;</span>,<span class="string">&#x27;a&#x27;</span>:<span class="string">&#x27;c&#x27;</span>]<span class="comment">#取one、two行，abc列</span></span><br><span class="line">df.ix[<span class="number">0</span>:<span class="number">2</span>,<span class="number">0</span>:<span class="number">1</span>]<span class="comment">#取第0、1行，第0列</span></span><br><span class="line">df.ix[<span class="number">0</span>:<span class="number">2</span>,<span class="number">0</span>:<span class="number">2</span>]<span class="comment">#取第0、1行，第0、1列</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#loc只能通过index和columns来取，不能用数字</span></span><br><span class="line">df.loc[<span class="string">&#x27;one&#x27;</span>,<span class="string">&#x27;a&#x27;</span>]<span class="comment">#one行，a列</span></span><br><span class="line">df.loc[<span class="string">&#x27;one&#x27;</span>:<span class="string">&#x27;two&#x27;</span>,<span class="string">&#x27;a&#x27;</span>]<span class="comment">#one到two行，a列</span></span><br><span class="line">df.loc[<span class="string">&#x27;one&#x27;</span>:<span class="string">&#x27;two&#x27;</span>,<span class="string">&#x27;a&#x27;</span>:<span class="string">&#x27;c&#x27;</span>]<span class="comment">#one到two行，a到c列</span></span><br><span class="line">df.loc[<span class="string">&#x27;one&#x27;</span>:<span class="string">&#x27;two&#x27;</span>,[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;c&#x27;</span>]]<span class="comment">#one到two行，ac列</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#iloc只能用数字索引，不能用索引名</span></span><br><span class="line">df.iloc[<span class="number">0</span>:<span class="number">2</span>]<span class="comment">#前2行</span></span><br><span class="line">df.iloc[<span class="number">0</span>]<span class="comment">#第0行</span></span><br><span class="line">df.iloc[<span class="number">0</span>:<span class="number">2</span>,<span class="number">0</span>:<span class="number">2</span>]<span class="comment">#0、1行，0、1列</span></span><br><span class="line">df.iloc[[<span class="number">0</span>,<span class="number">2</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]<span class="comment">#第0、2行，1、2、3列</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#iat取某个单值,只能数字索引</span></span><br><span class="line">df.iat[<span class="number">1</span>,<span class="number">1</span>]<span class="comment">#第1行，1列</span></span><br><span class="line"><span class="comment">#at取某个单值,只能index和columns索引</span></span><br><span class="line">df.at[<span class="string">&#x27;one&#x27;</span>,<span class="string">&#x27;a&#x27;</span>]<span class="comment">#one行，a列</span></span><br></pre></td></tr></table></figure><h2 id="按行条件判断处理"><a href="#按行条件判断处理" class="headerlink" title="按行条件判断处理"></a>按行条件判断处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>: [<span class="number">50</span>, <span class="number">50</span>], </span><br><span class="line">                   <span class="string">&#x27;B&#x27;</span> : [<span class="number">150</span>, <span class="number">30</span>],</span><br><span class="line">                   <span class="string">&#x27;C&#x27;</span>: [<span class="number">11</span>, <span class="number">40</span>]&#125;)    </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">adjust_min</span>(<span class="params">row</span>):</span><br><span class="line">    res = <span class="built_in">min</span>(row[<span class="string">&#x27;A&#x27;</span>], row[<span class="string">&#x27;B&#x27;</span>], row[<span class="string">&#x27;C&#x27;</span>])</span><br><span class="line">    <span class="keyword">if</span> res == row[<span class="string">&#x27;A&#x27;</span>]:</span><br><span class="line">        row[<span class="string">&#x27;min&#x27;</span>] = <span class="string">&#x27;A&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> res == row[<span class="string">&#x27;B&#x27;</span>]:</span><br><span class="line">        row[<span class="string">&#x27;min&#x27;</span>] = <span class="string">&#x27;B&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        row[<span class="string">&#x27;min&#x27;</span>] = <span class="string">&#x27;C&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> row[<span class="string">&#x27;min&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df[<span class="string">&#x27;Min&#x27;</span>] = df.apply(adjust_min, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="group-by"><a href="#group-by" class="headerlink" title="group by"></a>group by</h2><h3 id="count-sort"><a href="#count-sort" class="headerlink" title="count sort"></a>count sort</h3><p><a href="https://stackoverflow.com/questions/40454030/count-and-sort-with-pandas">https://stackoverflow.com/questions/40454030/count-and-sort-with-pandas</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;STNAME&#x27;</span>:<span class="built_in">list</span>(<span class="string">&#x27;abscscbcdbcsscae&#x27;</span>),</span><br><span class="line">                   <span class="string">&#x27;CTYNAME&#x27;</span>:[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">5</span>]&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (df)</span><br><span class="line">    CTYNAME STNAME</span><br><span class="line"><span class="number">0</span>         <span class="number">4</span>      a</span><br><span class="line"><span class="number">1</span>         <span class="number">5</span>      b</span><br><span class="line"><span class="number">2</span>         <span class="number">6</span>      s</span><br><span class="line"><span class="number">3</span>         <span class="number">5</span>      c</span><br><span class="line"><span class="number">4</span>         <span class="number">6</span>      s</span><br><span class="line"><span class="number">5</span>         <span class="number">2</span>      c</span><br><span class="line"><span class="number">6</span>         <span class="number">3</span>      b</span><br><span class="line"><span class="number">7</span>         <span class="number">4</span>      c</span><br><span class="line"><span class="number">8</span>         <span class="number">5</span>      d</span><br><span class="line"><span class="number">9</span>         <span class="number">6</span>      b</span><br><span class="line"><span class="number">10</span>        <span class="number">4</span>      c</span><br><span class="line"><span class="number">11</span>        <span class="number">5</span>      s</span><br><span class="line"><span class="number">12</span>        <span class="number">4</span>      s</span><br><span class="line"><span class="number">13</span>        <span class="number">3</span>      c</span><br><span class="line"><span class="number">14</span>        <span class="number">6</span>      a</span><br><span class="line"><span class="number">15</span>        <span class="number">5</span>      e</span><br><span class="line"></span><br><span class="line">df = df[[<span class="string">&#x27;STNAME&#x27;</span>,<span class="string">&#x27;CTYNAME&#x27;</span>]].groupby([<span class="string">&#x27;STNAME&#x27;</span>])[<span class="string">&#x27;CTYNAME&#x27;</span>] \</span><br><span class="line">                             .count() \</span><br><span class="line">                             .reset_index(name=<span class="string">&#x27;count&#x27;</span>) \</span><br><span class="line">                             .sort_values([<span class="string">&#x27;count&#x27;</span>], ascending=<span class="literal">False</span>) \</span><br><span class="line">                             .head(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (df)</span><br><span class="line">  STNAME  count</span><br><span class="line"><span class="number">2</span>      c      <span class="number">5</span></span><br><span class="line"><span class="number">5</span>      s      <span class="number">4</span></span><br><span class="line"><span class="number">1</span>      b      <span class="number">3</span></span><br><span class="line"><span class="number">0</span>      a      <span class="number">2</span></span><br><span class="line"><span class="number">3</span>      d      <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="groupby-后保留列"><a href="#groupby-后保留列" class="headerlink" title="groupby 后保留列"></a>groupby 后保留列</h3><p><a href="https://stackoverflow.com/questions/19202093/how-to-select-columns-from-groupby-object-in-pandas/26668184">https://stackoverflow.com/questions/19202093/how-to-select-columns-from-groupby-object-in-pandas/26668184</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;a&#x27;</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">                   <span class="string">&#x27;b&#x27;</span>: [<span class="number">4.0</span>, <span class="number">5.5</span>, <span class="number">6.0</span>],</span><br><span class="line">                   <span class="string">&#x27;c&#x27;</span>: [<span class="number">7L</span>, <span class="number">8L</span>, <span class="number">9L</span>],</span><br><span class="line">                   <span class="string">&#x27;name&#x27;</span>: [<span class="string">&#x27;hello&#x27;</span>, <span class="string">&#x27;hello&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>]&#125;)</span><br><span class="line">df.groupby([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;name&#x27;</span>]).median()</span><br><span class="line"><span class="comment"># 会得到结果如下</span></span><br><span class="line">            b    c</span><br><span class="line">a name            </span><br><span class="line"><span class="number">1</span> hello  <span class="number">4.75</span>  <span class="number">7.5</span></span><br><span class="line"><span class="number">3</span> foo    <span class="number">6.00</span>  <span class="number">9.0</span></span><br></pre></td></tr></table></figure><p>通过groupby后可能groupBy的字段无法通过df[‘name’]访问，因为已经变成了index<br>如果保证其能访问，可以在groupby里设置参数<br>groupby(…, <strong>as_index=False</strong>)</p><h2 id="pandas-读取-excel文件"><a href="#pandas-读取-excel文件" class="headerlink" title="pandas 读取 excel文件"></a>pandas 读取 excel文件</h2><p>需要安装xlrd<br><a href="https://www.cnblogs.com/yfacesclub/p/11232736.html">https://www.cnblogs.com/yfacesclub/p/11232736.html</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pd.read_excel(path, sheet_name=<span class="number">0</span>, header=<span class="number">0</span>, names=<span class="literal">None</span>, index_col=<span class="literal">None</span>, </span><br><span class="line">              usecols=<span class="literal">None</span>, squeeze=<span class="literal">False</span>,dtype=<span class="literal">None</span>, engine=<span class="literal">None</span>, </span><br><span class="line">              converters=<span class="literal">None</span>, true_values=<span class="literal">None</span>, false_values=<span class="literal">None</span>, </span><br><span class="line">              skiprows=<span class="literal">None</span>, nrows=<span class="literal">None</span>, na_values=<span class="literal">None</span>, parse_dates=<span class="literal">False</span>, </span><br><span class="line">              date_parser=<span class="literal">None</span>, thousands=<span class="literal">None</span>, comment=<span class="literal">None</span>, skipfooter=<span class="number">0</span>, </span><br><span class="line">              convert_float=<span class="literal">True</span>, **kwds)</span><br></pre></td></tr></table></figure><h2 id="pandas-print格式调整"><a href="#pandas-print格式调整" class="headerlink" title="pandas print格式调整"></a>pandas print格式调整</h2><p><a href="https://blog.csdn.net/weekdawn/article/details/81389865">https://blog.csdn.net/weekdawn/article/details/81389865</a><br><a href="https://www.cnblogs.com/yoyo1216/p/12367713.html">https://www.cnblogs.com/yoyo1216/p/12367713.html</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#pd.options.display.max_colwidth = 100</span></span><br><span class="line"><span class="comment">#显示所有列</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment">#显示所有行</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_rows&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment">#设置value的显示长度为100，默认为50</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;max_colwidth&#x27;</span>,<span class="number">200</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;expand_frame_repr&#x27;</span>, <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="map-filter"><a href="#map-filter" class="headerlink" title="map, filter"></a>map, filter</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">train_logs = glob.glob(<span class="string">&#x27;/data/vinyuan/bpr-models/MSNClick/sgd-unified_event_data_0715_0807*/train.log&#x27;</span>)</span><br><span class="line">train_logs= <span class="built_in">sorted</span>(train_logs, key=<span class="keyword">lambda</span> x: os.path.getmtime(x), reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">text=<span class="string">&#x27;WeightedSample&#x27;</span></span><br><span class="line"></span><br><span class="line">fix_params = [<span class="string">&#x27;UserNegCross=0.2&#x27;</span>, <span class="string">&#x27;PosL2=0.1&#x27;</span>, <span class="string">&#x27;NegL2=0.15&#x27;</span>]</span><br><span class="line">fix_params_str = <span class="string">&quot;\\n&quot;</span>.join(fix_params)+<span class="string">&#x27;\\n&#x27;</span> <span class="keyword">if</span> <span class="built_in">len</span>(fix_params) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&quot;&quot;</span></span><br><span class="line">pattern=re.<span class="built_in">compile</span>(<span class="string">r&quot;.*&#123;&#125;-(\d+\.?\d*)&quot;</span>.<span class="built_in">format</span>(text))</span><br><span class="line">train_logs = train_logs[:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">filter_by_fix_param</span>(<span class="params">x</span>):</span><br><span class="line">    value, model_name = x</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> fix_params:</span><br><span class="line">        <span class="keyword">if</span> param <span class="keyword">not</span> <span class="keyword">in</span> model_name:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>, model_name</span><br><span class="line">    <span class="keyword">return</span> value, model_name</span><br><span class="line">            </span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">x</span>):</span><br><span class="line">    res = pattern.<span class="keyword">match</span>(x)</span><br><span class="line">    model_name = x.split(<span class="string">&#x27;/&#x27;</span>)[<span class="number">5</span>]</span><br><span class="line">    <span class="keyword">if</span> res <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> (-<span class="number">1</span>, model_name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        value = <span class="built_in">float</span>(res.group(<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">if</span> value &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="number">0</span>, model_name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (value, model_name)</span><br><span class="line">        </span><br><span class="line">train_logs = <span class="built_in">map</span>(fun, train_logs)</span><br><span class="line">train_logs = <span class="built_in">filter</span>(filter_by_fix_param, train_logs)</span><br><span class="line">train_logs = <span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &gt; <span class="number">0</span>, train_logs)</span><br><span class="line">train_logs = <span class="built_in">sorted</span>(train_logs, key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>], reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h2 id="co1-co2-co3-gt-new-col"><a href="#co1-co2-co3-gt-new-col" class="headerlink" title="(co1, co2, co3 -&gt; new_col)"></a>(co1, co2, co3 -&gt; new_col)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cal_diff</span>(<span class="params">row</span>):</span><br><span class="line">    diff = <span class="built_in">set</span>(row[<span class="string">&#x27;a&#x27;</span>]) - <span class="built_in">set</span>(row[<span class="string">&#x27;b&#x27;</span>])</span><br><span class="line">    diff = <span class="built_in">list</span>(diff)</span><br><span class="line">    <span class="keyword">return</span> diff</span><br><span class="line">df[<span class="string">&#x27;c&#x27;</span>] = df.apply(<span class="keyword">lambda</span> row: cal_diff(row), axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><h2 id="按行和列填值"><a href="#按行和列填值" class="headerlink" title="按行和列填值"></a>按行和列填值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = np.zeros([<span class="number">5</span>,<span class="number">3</span>])</span><br><span class="line">a[[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>]] = <span class="number">1</span></span><br><span class="line">a</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">array([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure><h2 id="从数值范围创建递增数组"><a href="#从数值范围创建递增数组" class="headerlink" title="从数值范围创建递增数组"></a>从数值范围创建递增数组</h2><ol><li>numpy.arange(start, stop, step, dtype)</li><li>np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)</li><li>numpy.logspace</li></ol><h2 id="DataFrame-统计空值"><a href="#DataFrame-统计空值" class="headerlink" title="DataFrame 统计空值"></a>DataFrame 统计空值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data1 = &#123;<span class="string">&#x27;itemId&#x27;</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], <span class="string">&#x27;other&#x27;</span>:[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>]&#125;</span><br><span class="line">data2 = &#123;<span class="string">&#x27;itemId&#x27;</span>:[<span class="number">2</span>,<span class="number">3</span>], <span class="string">&#x27;label&#x27;</span>:[<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;C&#x27;</span>]&#125;</span><br><span class="line">df_data1 = pd.DataFrame(data1)</span><br><span class="line">df_data2 = pd.DataFrame(data2)</span><br><span class="line">df_merge = pd.merge(df_data1, df_data2, on=[<span class="string">&#x27;itemId&#x27;</span>], how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(df_data1)</span><br><span class="line"><span class="built_in">print</span>(df_data2)</span><br><span class="line"><span class="built_in">print</span>(df_merge)</span><br><span class="line">a = df_tmp.where(df_merge[<span class="string">&#x27;label&#x27;</span>].isnull())[<span class="string">&#x27;itemId&#x27;</span>].count()</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Byte-KB-MB的笔记&quot;&gt;&lt;a href=&quot;#Byte-KB-MB的笔记&quot; class=&quot;headerlink&quot; title=&quot;Byte, KB, MB的笔记&quot;&gt;&lt;/a&gt;Byte, KB, MB的笔记&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;http://myrepono.com/faq/4&quot;&gt;http://myrepono.com/faq/4&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A byte is a sequence of 8 bits (enough to represent one alphanumeric character) processed as a single unit of information. A single letter or character would use one byte of memory (8 bits), two characters would use two bytes (16 bits).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1024 bytes = 1 KB&lt;br&gt;1024 KB = 1 MB&lt;br&gt;1024 MB = 1 GB&lt;br&gt;1024 GB = 1 TB&lt;br&gt;1024 TB = 1 PB&lt;br&gt;KB = KilobyteM&lt;br&gt;B = MegabyteG&lt;br&gt;B = GigabyteT&lt;br&gt;B = TerabyteP&lt;br&gt;B = Petabyte&lt;/p&gt;
&lt;h2 id=&quot;dataframe-估算内存&quot;&gt;&lt;a href=&quot;#dataframe-估算内存&quot; class=&quot;headerlink&quot; title=&quot;dataframe 估算内存&quot;&gt;&lt;/a&gt;dataframe 估算内存&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title function_&quot;&gt;memory_usage&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;df&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    types = df.dtypes&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    s = df.memory_usage(deep=&lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    s = s/&lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt;**&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    total_mem = s.&lt;span class=&quot;built_in&quot;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; column &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; df.columns:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; s[column] &amp;lt; &lt;span class=&quot;number&quot;&gt;0.01&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&amp;quot;&amp;#123;&amp;#125; = &amp;#123;&amp;#125; KB,  &amp;#123;&amp;#125;&amp;quot;&lt;/span&gt;.&lt;span class=&quot;built_in&quot;&gt;format&lt;/span&gt;(column, s[column] * &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt;, types[column]))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&amp;quot;&amp;#123;&amp;#125; = &amp;#123;:1.2f&amp;#125; MB,  &amp;#123;&amp;#125;&amp;quot;&lt;/span&gt;.&lt;span class=&quot;built_in&quot;&gt;format&lt;/span&gt;(column, s[column], types[column]))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&amp;quot;totoal memory: &amp;#123;:.2f&amp;#125; MB&amp;quot;&lt;/span&gt;.&lt;span class=&quot;built_in&quot;&gt;format&lt;/span&gt;(total_mem))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>spark</title>
    <link href="http://yoursite.com/2024/06/04/spark/"/>
    <id>http://yoursite.com/2024/06/04/spark/</id>
    <published>2024-06-04T06:51:08.000Z</published>
    <updated>2025-05-22T05:50:40.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="pyspark-API"><a href="#pyspark-API" class="headerlink" title="pyspark API"></a>pyspark API</h2><p><a href="https://spark.apache.org/docs/2.2.1/api/python/search.html?q=dataframe.write">https://spark.apache.org/docs/2.2.1/api/python/search.html?q=dataframe.write</a></p><h2 id="简明教程"><a href="#简明教程" class="headerlink" title="简明教程"></a>简明教程</h2><p><a href="https://sparkbyexamples.com/pyspark/pyspark-orderby-and-sort-explained/">https://sparkbyexamples.com/pyspark/pyspark-orderby-and-sort-explained/</a><br><a href="http://www.learnbymarketing.com/1100/pyspark-joins-by-example/">http://www.learnbymarketing.com/1100/pyspark-joins-by-example/</a></p><span id="more"></span><h2 id="Spark调优"><a href="#Spark调优" class="headerlink" title="Spark调优"></a>Spark调优</h2><p><a href="https://tech.meituan.com/2016/04/29/spark-tuning-basic.html">https://tech.meituan.com/2016/04/29/spark-tuning-basic.html</a><br>资源参数调优<br>了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，我们同时也给出了一个调优的参考值。</p><ul><li>num-executors<br>参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。<br>参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。</li><li>executor-memory<br>参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。<br>参数调优建议：每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。</li><li>executor-cores<br>参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。<br>参数调优建议：Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。</li><li>driver-memory<br>参数说明：该参数用于设置Driver进程的内存。<br>参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。</li><li>spark.default.parallelism<br>参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。<br>参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。</li><li>spark.storage.memoryFraction<br>参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。<br>参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</li><li>spark.shuffle.memoryFraction<br>参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。<br>参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。<br>资源参数的调优，没有一个固定的值，需要同学们根据自己的实际情况（包括Spark作业中的shuffle操作数量、RDD持久化操作数量以及spark web ui中显示的作业gc情况），同时参考本篇文章中给出的原理以及调优建议，合理地设置上述参数。</li></ul><p>资源参数参考示例<br>以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/<span class="built_in">bin</span>/spark-submit \</span><br><span class="line">  --master yarn-cluster \</span><br><span class="line">  --num-executors <span class="number">100</span> \</span><br><span class="line">  --executor-memory 6G \</span><br><span class="line">  --executor-cores <span class="number">4</span> \</span><br><span class="line">  --driver-memory 1G \</span><br><span class="line">  --conf spark.default.parallelism=<span class="number">1000</span> \</span><br><span class="line">  --conf spark.storage.memoryFraction=<span class="number">0.5</span> \</span><br><span class="line">  --conf spark.shuffle.memoryFraction=<span class="number">0.3</span> \</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="spark-本地执行"><a href="#spark-本地执行" class="headerlink" title="spark 本地执行"></a>spark 本地执行</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 本机4个CPU核心上执行</span></span><br><span class="line">./<span class="built_in">bin</span>/pyspark --master local[<span class="number">4</span>]</span><br><span class="line"><span class="comment"># 本机所有CPU核心上执行</span></span><br><span class="line">./<span class="built_in">bin</span>/pyspark --master local[*]</span><br><span class="line"><span class="comment"># 查看当前的运行模式</span></span><br><span class="line"> sc.master</span><br><span class="line"><span class="comment"># 读取本地文件（路径前用file:///)</span></span><br><span class="line">textFile=sc.textFile(<span class="string">&quot;file:///usr/local/spark/README.md&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="spark-tutorial"><a href="#spark-tutorial" class="headerlink" title="spark tutorial"></a><a href="https://www.tutorialspoint.com/pyspark/pyspark_sparkcontext.htm">spark tutorial</a></h1><p>spark-shell 不用创建sparkContext，默认已经启用了一个，如果再次生成会提示：”ValueError: Cannot run multiple SparkContexts at once”.</p><h1 id="SparkSession和SparkContext的关系"><a href="#SparkSession和SparkContext的关系" class="headerlink" title="SparkSession和SparkContext的关系"></a>SparkSession和SparkContext的关系</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">└── SparkSession</span><br><span class="line">    └── SparkContext</span><br><span class="line">        ├── RDD1</span><br><span class="line">        ├── RDD2</span><br><span class="line">        └── RDD3</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>SparkSession是Spark 2.0引入的新概念。SparkSession为用户提供了统一的切入点，来让用户学习spark的各项功能。<br>在spark的早期版本中，SparkContext是spark的主要切入点，由于RDD是主要的API，我们通过SparkContext来创建和操作RDD。对于每个其他的API，我们需要使用不同的context：</p><ul><li>Streaming使用StreamingContext</li><li>sql使用SqlContext</li><li>hive使用HiveContext</li></ul><p>但是随着DataSet和DataFrame的API逐渐成为标准的API，就需要为他们建立接入点。所以在spark2.0中，引入SparkSession作为DataSet和DataFrame API的切入点。<br>SparkSession封装了SparkContext和SQLContext。为了向后兼容，SQLContext和HiveContext也被保存下来。<br>在大多数情况下，我们不需要显式初始化SparkContext; 而尽量通过SparkSession来访问它。<br><a href="https://www.jianshu.com/p/4705988b0c84">https://www.jianshu.com/p/4705988b0c84</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Creating a SparkSession in Python</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">spark = SparkSession.builder.master(<span class="string">&quot;local&quot;</span>).appName(<span class="string">&quot;Word Count&quot;</span>)\</span><br><span class="line">    .config(<span class="string">&quot;spark.some.config.option&quot;</span>, <span class="string">&quot;some-value&quot;</span>)\</span><br><span class="line">    .getOrCreate()</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 上面的spark时SparkSession对象，使用type可以验证</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(spark)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pyspark.sql.session.SparkSession</span><br></pre></td></tr></table></figure><h1 id="Spark-Cluster-Components"><a href="#Spark-Cluster-Components" class="headerlink" title="Spark Cluster Components"></a><a href="https://spark.apache.org/docs/latest/cluster-overview.html">Spark Cluster Components</a></h1><p><img src="https://spark.apache.org/docs/latest/img/cluster-overview.png" alt="spark cluster components"></p><p>Spark applications run as independent sets of processes on a cluster, coordinated by the SparkContext object in your main program (called the <strong>driver program</strong>).</p><blockquote><p>driver program是协调集群进程的hub，所以当driver不在集群里时（client模式），网络带宽延迟会很影响通信与状态更新。</p></blockquote><ol><li>Specifically, to run on a cluster, the SparkContext can <strong>connect</strong> to several types of <strong>cluster managers</strong> (either Spark’s own standalone cluster manager, Mesos or YARN), which allocate resources across applications.</li><li>Once connected, Spark <strong>acquires executors</strong> on nodes in the cluster, which are <strong>processes</strong> that run computations and store data for your application.</li><li>Next, it <strong>sends your application code</strong> (defined by JAR or Python files passed to SparkContext) <strong>to the executors</strong>.</li><li>Finally, SparkContext <strong>sends tasks</strong> to the executors to run.</li></ol><h1 id="Spark-Config"><a href="#Spark-Config" class="headerlink" title="Spark Config"></a>Spark Config</h1><h2 id="spark-sql-shuffle-partitions"><a href="#spark-sql-shuffle-partitions" class="headerlink" title="spark.sql.shuffle.partitions"></a>spark.sql.shuffle.partitions</h2><p><a href="http://blog.madhukaraphatak.com/dynamic-spark-shuffle-partitions/">http://blog.madhukaraphatak.com/dynamic-spark-shuffle-partitions/</a></p><h1 id="Spark-Submit"><a href="#Spark-Submit" class="headerlink" title="Spark Submit"></a>Spark Submit</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/bin/spark-submit \</span><br><span class="line">--class &lt;main-class&gt; \  # 程序入口，如果是java则是类，java</span><br><span class="line">--master &lt;master-url&gt; \</span><br><span class="line">--deploy-mode &lt;deploy-mode&gt; \ #分为cluster和client两种</span><br><span class="line">--conf &lt;conf-param&gt; \  #一些配置参数</span><br><span class="line">... # other options</span><br><span class="line">&lt;application-jar&gt; \  # 可以是jar或python文件的路径，如果是url则需要所有node可见</span><br><span class="line">[application-arguments] \ 参数</span><br></pre></td></tr></table></figure><p><strong>注意</strong>：当提交spark 任务时，如果jar包有多个，用逗号隔开，<strong>逗号前后不能有空格!,有逗号会导致后续参数解析错误，可能提交的scalar程序提示class notFound!</strong><br>具体的例子参见<a href="https://spark.apache.org/docs/latest/submitting-applications.html#submitting-applications">《Submitting Applications》</a></p><p>python的例子：<br>对于 main.py 依赖的 util.py, module1.py, module2.py，需要先压缩成一个 .zip 文件，再通过 spark-submit 的 —py—files 选项上传到 yarn，mail.py 才能 import 这些子模块。<a href="https://www.jianshu.com/p/92be93cfbb97">命令如下</a>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">spark-submit</span> </span><br><span class="line">--master=yarn \</span><br><span class="line">--deploy-mode=cluster \</span><br><span class="line">--jars elasticsearch-hadoop-5.3.1.jar \</span><br><span class="line">--py-files deps.zip \</span><br><span class="line">main.py</span><br></pre></td></tr></table></figure><h2 id="deploy-mode"><a href="#deploy-mode" class="headerlink" title="deploy-mode"></a>deploy-mode</h2><p>具体参考<a href="https://blog.csdn.net/qq_39131779/article/details/83539608">《standalone mode》</a><br>总结起来就一句话：<strong>culster/client的主要区别就是driver是否在cluster里</strong></p><h3 id="cluster-集群模式"><a href="#cluster-集群模式" class="headerlink" title="cluster 集群模式"></a>cluster 集群模式</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/bin/spark-submit \</span><br><span class="line">--master  spark://node01:7077 \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">../lib/spark-examples-1.6.0-hadoop2.6.0.jar </span><br><span class="line">100</span><br></pre></td></tr></table></figure><ol><li>client模式提交任务后，会在客户端启动Driver进程。</li><li>Driver会向Master申请启动Application启动的资源。</li><li>资源申请成功，Driver端将task发送到worker端执行。</li><li>worker将task执行结果返回到Driver端。(由代码设置)</li></ol><p>总结：client模式适用于测试调试程序。<strong>Driver进程是在客户端启动的</strong>，这里的客户端就是指提交应用程序的当前节点。<strong>在Driver端可以看到task执行的情况。生产环境下不能使用client模式</strong>，是因为：假设要提交100个application到集群运行，Driver每次都会在client端启动，那么就会导致客户端100次网卡流量暴增的问题。（因为要监控task的运行情况，会占用很多端口，如上图的结果图）客户端网卡通信，都被task监控信息占用。<br>集群模式如果是用来本地文件，需要添加—files参数<br>例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">此处代码使用了本地文件<span class="string">&#x27;stat.conf&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果直接使用 deploy-mode=cluster会报错找不到stat.conf</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">所以需要在submit时添加 <span class="string">&quot;--files <span class="variable">$con_file</span>&quot;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">start_day=<span class="string">&#x27;2020-10-01&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">end_day=<span class="string">&#x27;2020-10-02&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">conf_file=<span class="string">&#x27;./stat.conf&#x27;</span></span></span><br><span class="line"></span><br><span class="line">spark-submit --class com.jd.rec.FeatStat\</span><br><span class="line">   --num-executors 500 \</span><br><span class="line">   --executor-memory 45g \</span><br><span class="line">   --driver-memory 10g \</span><br><span class="line">   --executor-cores 6 \</span><br><span class="line">   --master yarn \</span><br><span class="line">   --deploy-mode cluster \</span><br><span class="line">   --conf spark.sql.catalogImplementation=hive \</span><br><span class="line">   --conf spark.sql.shuffle.partitions=10000 \</span><br><span class="line">   --conf spark.shuffle.consolidateFiles=true\</span><br><span class="line">   --jars protobuf-java-3.5.1.jar,proto-1.10.0.jar \</span><br><span class="line">   --conf spark.executor.userClassPathFirst=true \</span><br><span class="line">   --files $conf_file \ # 注意此处</span><br><span class="line">   tfrecord-hadoop-trans-11.0.0.jar $conffile $start_day $end_day</span><br></pre></td></tr></table></figure><h3 id="client"><a href="#client" class="headerlink" title="client"></a>client</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/bin/spark-submit \</span><br><span class="line">--master spark://node01:7077 \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">../lib/spark-examples-1.6.0-hadoop2.6.0.jar  </span><br><span class="line">100</span><br></pre></td></tr></table></figure><ol><li>客户端使用命令spark-submit —deploy-mode cluster 后会启动spark-submit进程</li><li>此进程为Driver向Master申请资源，Driver进程默认需要1G内存和1Core，</li><li>Master会<strong>随机选择一台</strong>worker节点来启动Driver进程（这样通信会较近，利于信息、状态收集）</li><li><strong>Driver启动成功后，spark-submit关闭</strong>，然后Driver向Master申请资源</li><li>Master接收到请求后，会在资源充足的worker节点上启动Executor进程</li><li>Driver分发Task到Executor中执行</li></ol><p>总结：这种模式会将单节点的网卡流量激增问题分散到集群中。在客户端看不到task执行情况和结果，要去<strong>webui</strong>中看。cluster模式适用于生产环境，Master模式先启动Driver，再启动Application</p><p><strong>spark shell 模式是以client提交的</strong>(第一种)，所以不能加入—deploy-mode cluster的(第二种) <strong>client方式用于测试环境，用于方便查看结果</strong>，因为 spark shell 模式以client方式提交，所以 spark shell 模式不支持—deploy-mode cluster提</p><h1 id="RDD-and-DataFrame"><a href="#RDD-and-DataFrame" class="headerlink" title="RDD and DataFrame"></a>RDD and DataFrame</h1><h2 id="Transform函数"><a href="#Transform函数" class="headerlink" title="Transform函数"></a>Transform函数</h2><h3 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df = spark.sql(&quot;select id_feat from table where dt = &#x27;2020-10-01&#x27;&quot;)</span><br><span class="line">df_split = split(df[&#x27;id_feat&#x27;], &#x27;\t&#x27;)</span><br><span class="line">attrs = [&#x27;item_c3&#x27;,&#x27;item_br&#x27;,&#x27;item_c2&#x27;,&#x27;item_sh&#x27;,&#x27;item_pw&#x27;,&#x27;item_sku&#x27;]</span><br><span class="line">#print(&quot;列名：&quot;, attrs)</span><br><span class="line">for index, value in enumerate(attrs):</span><br><span class="line">    df = df.withColumn(value, df_split.getItem(index))</span><br><span class="line">rdd = df.rdd.flatMap(lambda x: fun(x)).reduceByKey(lambda x, y: x+y)</span><br><span class="line">rdd = rdd.map(lambda x: &quot;&#123;0&#125;,&#123;1&#125;,&#123;2&#125;&quot;.format(x[0][0], x[0][1], x[1]))</span><br></pre></td></tr></table></figure><h2 id="DataFrame-速查表"><a href="#DataFrame-速查表" class="headerlink" title="DataFrame 速查表"></a>DataFrame 速查表</h2><p><a href="https://sparkbyexamples.com/pyspark/pyspark-structtype-and-structfield/">https://sparkbyexamples.com/pyspark/pyspark-structtype-and-structfield/</a><br><a href="https://www.cnblogs.com/liaowuhen1314/p/12792202.html">https://www.cnblogs.com/liaowuhen1314/p/12792202.html</a></p><h2 id="DataFrame-Split-列生成新column"><a href="#DataFrame-Split-列生成新column" class="headerlink" title="DataFrame Split 列生成新column"></a>DataFrame Split 列生成新column</h2><p><a href="https://sparkbyexamples.com/spark/spark-split-dataframe-column-into-multiple-columns/">https://sparkbyexamples.com/spark/spark-split-dataframe-column-into-multiple-columns/</a></p><p>[split 教程][2]</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df = spark.sql(&quot;select * from xxx where dt = &#x27;2020-10-20&#x27;&quot;)</span><br><span class="line">df[]</span><br><span class="line">df_split = split(df[&#x27;id_feat&#x27;], &#x27;\t&#x27;)</span><br><span class="line">attrs = [&#x27;item_c3&#x27;,&#x27;item_br&#x27;,&#x27;item_c2&#x27;]</span><br><span class="line">for index, value in enumerate(attrs):</span><br><span class="line">    df = df.withColumn(value, df_split.getItem(index))</span><br><span class="line">print(df.select(&#x27;item_br&#x27;).take(3))</span><br></pre></td></tr></table></figure><h2 id="DataFrame-筛选"><a href="#DataFrame-筛选" class="headerlink" title="DataFrame 筛选"></a>DataFrame 筛选</h2><p><a href="https://blog.csdn.net/sinat_26917383/article/details/80500349">https://blog.csdn.net/sinat_26917383/article/details/80500349</a></p><h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><p>例子</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a_rdd = sc.parallelize([(&#x27;a&#x27;, 13132), (&#x27;b&#x27;, 121212),(&#x27;c&#x27;,56577)])</span><br><span class="line">b_rdd = sc.parallelize([(&#x27;a&#x27;, 23232), (&#x27;b&#x27;,333333)])</span><br><span class="line">columns = [&#x27;sku&#x27;, &#x27;feat&#x27;]</span><br><span class="line">df_a = a_rdd.toDF(columns)</span><br><span class="line">df_b = b_rdd.toDF(columns)</span><br><span class="line"></span><br><span class="line">df_a.join(df_b, df_a.sku==df_b.sku, &#x27;left&#x27;).where(df_b.sku.isNull()).select(df_a.sku, df_b.feat).show()</span><br></pre></td></tr></table></figure><h3 id="Where"><a href="#Where" class="headerlink" title="Where"></a>Where</h3><p><a href="https://stackoverflow.com/questions/35870760/filtering-a-pyspark-dataframe-with-sql-like-in-clause">https://stackoverflow.com/questions/35870760/filtering-a-pyspark-dataframe-with-sql-like-in-clause</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">df = sc.parallelize([(1, &quot;foo&quot;), (2, &quot;x&quot;), (3, &quot;bar&quot;)]).toDF((&quot;k&quot;, &quot;v&quot;))</span><br><span class="line">df.registerTempTable(&quot;df&quot;)</span><br><span class="line">sqlContext.sql(&quot;SELECT * FROM df WHERE v IN &#123;0&#125;&quot;.format((&quot;foo&quot;, &quot;bar&quot;))).count()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">from pyspark.sql.functions import col</span><br><span class="line">df.where(col(&quot;v&quot;).isin(&#123;&quot;foo&quot;, &quot;bar&quot;&#125;)).count()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">from pyspark.sql.functions import col</span><br><span class="line">df.where(col(&quot;v&quot;).isin([&quot;foo&quot;, &quot;bar&quot;])).count()</span><br><span class="line"></span><br><span class="line"># example-2</span><br><span class="line">df = df.where((df[&#x27;dt&#x27;] &gt;= &#x27;2020-09-14&#x27;) &amp; (df[&#x27;dt&#x27;] &lt;= &#x27;2020-10-05&#x27;)).groupby(&#x27;dt&#x27;).count()</span><br></pre></td></tr></table></figure><h2 id="DataFrame-统计"><a href="#DataFrame-统计" class="headerlink" title="DataFrame 统计"></a>DataFrame 统计</h2><h3 id="GroupBy"><a href="#GroupBy" class="headerlink" title="GroupBy"></a>GroupBy</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.where((df[&#x27;dt&#x27;] &gt;= &#x27;2020-09-14&#x27;) &amp; (df[&#x27;dt&#x27;] &lt;= &#x27;2020-10-05&#x27;)).groupby(&#x27;dt&#x27;).count()</span><br></pre></td></tr></table></figure><h2 id="DataFrame-转-rdd"><a href="#DataFrame-转-rdd" class="headerlink" title="DataFrame 转 rdd"></a>DataFrame 转 rdd</h2><p><a href="https://blog.csdn.net/helloxiaozhe/article/details/89414735">参考资料</a><br>DataFrame的表相关操作不能处理一些问题，例如需要对一些数据利用指定的函数进行计算时，就需要将DataFrame转换为RDD。DataFrame可以直接利用df.rdd获取对应的RDD对象，此RDD对象的每个元素使用Row对象来表示，<strong>每列值会成为Row对象的一个域=&gt;值映射</strong>。例如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; lists = [[&#x27;a&#x27;, 1], [&#x27;b&#x27;, 2]]</span><br><span class="line">&gt;&gt;&gt; list_dataframe = sqlContext.createDataFrame(lists,[&#x27;col1&#x27;,&#x27;col2&#x27;])</span><br><span class="line">&gt;&gt;&gt; list_dataframe.show()</span><br><span class="line">+----+----+                                                                     </span><br><span class="line">|col1|col2|</span><br><span class="line">+----+----+</span><br><span class="line">|   a|   1|</span><br><span class="line">|   b|   2|</span><br><span class="line">+----+----+</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; rdd=list_dataframe.rdd</span><br><span class="line">&gt;&gt;&gt; rdd.collect()</span><br><span class="line">[Row(col1=u&#x27;a&#x27;, col2=1), Row(col1=u&#x27;b&#x27;, col2=2)] </span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; rdd.map(lambda x: [x[0], x[1:]]).collect()</span><br><span class="line">[[u&#x27;a&#x27;, (1,)], [u&#x27;b&#x27;, (2,)]]</span><br><span class="line">&gt;&gt;&gt; rdd.map(lambda x: [x[0], x[1]]).collect()</span><br><span class="line">[[u&#x27;a&#x27;, 1], [u&#x27;b&#x27;, 2]]</span><br></pre></td></tr></table></figure><h2 id="DataFrame写Hive表"><a href="#DataFrame写Hive表" class="headerlink" title="DataFrame写Hive表"></a>DataFrame写Hive表</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2. 处理数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;/user/recsys/recpro/xxx.csv&#x27;</span>)</span><br><span class="line">df = spark.sql(<span class="string">&quot;select * from tmpr.live_person_attributes_yuanwenwu3&quot;</span>)</span><br><span class="line"><span class="comment"># 3. 写hive表</span></span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">hiveContext = HiveContext(sc)</span><br><span class="line">data_to_hive_df = hiveContext.createDataFrame(df)</span><br><span class="line">data_to_hive_df.partitionBy(<span class="string">&#x27;dt&#x27;</span>).write.<span class="built_in">format</span>(<span class="string">&quot;parquet&quot;</span>).mode(<span class="string">&quot;overwrite&quot;</span>).saveAsTable(<span class="string">&quot;tmpr.output_table&quot;</span>) </span><br></pre></td></tr></table></figure><h2 id="rdd-转-dataframe"><a href="#rdd-转-dataframe" class="headerlink" title="rdd 转 dataframe"></a>rdd 转 dataframe</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = sqlContext.createDataFrame(data, schema=None, samplingRatio=None, verifySchema=True)</span><br></pre></td></tr></table></figure><p>schema：DataFrame各列类型信息，在提前知道RDD所有类型信息时设定。例如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schema = StructType([StructField(&#x27;col1&#x27;, StringType()), StructField(&#x27;col2&#x27;, IntegerType())])</span><br></pre></td></tr></table></figure><h2 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h2><p><a href="https://zhuanlan.zhihu.com/p/105893298">参考资料1</a><br><a href="https://www.jianshu.com/p/d1f6678db183">参考资料2</a></p><h3 id="读文件"><a href="#读文件" class="headerlink" title="读文件"></a>读文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = spark.read.csv(filepath, sep=&#x27;,&#x27;, header=True, inferSchema=True)</span><br></pre></td></tr></table></figure><h3 id="rdd写文件"><a href="#rdd写文件" class="headerlink" title="rdd写文件"></a>rdd写文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">## 单独一个文件</span><br><span class="line">data.repartition(1).write.csv(writepath,mode=&quot;overwrite&quot;)</span><br><span class="line">data.coalesce(1).write.csv(writepath,mode=&quot;overwrite&quot;)</span><br><span class="line">## 写成特殊格式，去掉括号</span><br><span class="line">data.map(lambda (k,v): &quot;&#123;0&#125; &#123;1&#125;&quot;.format(k,v)).coalesce(1).write.csv(writepath,mode=&quot;overwrite&quot;)</span><br><span class="line">## 分块儿文件</span><br><span class="line">data.repartition(1000).write.csv(writepath,mode=&quot;overwrite&quot;)</span><br><span class="line">data.coalesce(1000).write.csv(writepath,mode=&quot;overwrite&quot;)</span><br></pre></td></tr></table></figure><p>通常rdd直接write到文件，内容会是如下形式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;cat rdd_res.txt</span><br><span class="line">……</span><br><span class="line">(k1,v1)</span><br><span class="line">(k2,v2)</span><br><span class="line">……</span><br></pre></td></tr></table></figure><p>rdd想<strong>没有括号</strong>输出到文本文件可以使用如下方式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data.map(lambda (k,v): &quot;&#123;0&#125; &#123;1&#125;&quot;.format(k,v)).coalesce(1).write.csv(&#x27;path&#x27;)</span><br><span class="line">#或者转成DataFrame在写</span><br><span class="line">rdd.toDF().write.csv(&quot;path&quot;)</span><br></pre></td></tr></table></figure><h3 id="DataFrame写文件"><a href="#DataFrame写文件" class="headerlink" title="DataFrame写文件"></a>DataFrame写文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># dataframe 写csv文件</span><br><span class="line">df.write.format(&quot;csv&quot;).option(&quot;header&quot;, &quot;false&quot;).mode(&quot;overwrite&quot;).save(&quot;hdfs://user/xxx/data.csv&quot;)</span><br><span class="line">hadoop fs -getmerge &quot;hdfs://user/xxx/data.csv&quot; &quot;./data.csv&quot;</span><br></pre></td></tr></table></figure><p><strong>option</strong> 支持参数<br>path: csv文件的路径。支持通配符;<br>header: csv文件的header。默认值是false;<br>delimiter: 分隔符。默认值是’,’;<br>quote: 引号。默认值是””;<br>mode: 解析的模式。支持的选项有：</p><h2 id="dataframe-添加一列"><a href="#dataframe-添加一列" class="headerlink" title="dataframe 添加一列"></a>dataframe 添加一列</h2><p>如果数据很多，想分块处理，以打到如下目的：</p><h3 id="添加-id-选择区间"><a href="#添加-id-选择区间" class="headerlink" title="添加 id 选择区间"></a>添加 id 选择区间</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">sku_img_df = spark.sql(sql)</span><br><span class="line">def flat(l):</span><br><span class="line">    sku_img = l[0]</span><br><span class="line">    index = l[1]</span><br><span class="line">    return (sku_img[0], sku_img[1], index)</span><br><span class="line">## 添加 &#x27;id&#x27; 生成新的dataframe</span><br><span class="line">rdd = sku_img_df.rdd.zipWithIndex()</span><br><span class="line">schema = sku_img_df.schema.add(StructField(&quot;id&quot;, LongType()))</span><br><span class="line">rdd = rdd.map(lambda x: flat(x))</span><br><span class="line">sku_img_df = spark.createDataFrame(rdd, schema)</span><br><span class="line">## 分区间处理dataframe中的行</span><br><span class="line">batch_size = 30000000</span><br><span class="line">start_index = 0</span><br><span class="line">while start_index &lt; total_count:</span><br><span class="line">    if start_index + batch_size &lt; total_count:</span><br><span class="line">        batch_data_num = batch_size</span><br><span class="line">    else:</span><br><span class="line">        batch_data_num = total_count - start_index</span><br><span class="line">    extract_batch(sku_img_df, start_index, batch_data_num)</span><br><span class="line">    start_index = start_index + batch_size</span><br></pre></td></tr></table></figure><h2 id="读取TXT文件"><a href="#读取TXT文件" class="headerlink" title="读取TXT文件"></a>读取TXT文件</h2><ul><li>spark.sparkContext.textFile(file_path)<br>读取到的是<strong>RDD</strong> (pyspark.rdd.RDD)，每一个元素直接是字符串</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; rdd = spark.sparkContext.textFile(file_path)</span><br><span class="line">&gt;&gt; rdd.take(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">[<span class="string">u&#x27;first line&#x27;</span>,</span><br><span class="line"> <span class="string">u&#x27;second line&#x27;</span>,</span><br><span class="line"> <span class="string">u&#x27;third line&#x27;</span>]</span><br></pre></td></tr></table></figure><ul><li>spark.read.text(file_path)<br>读取到的是<strong>DataFrame</strong> (pyspark.sql.dataframe.DataFrame)，每一个元素是 Row (pyspark.sql.types.Row)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; df = spark.read.text(file_path)</span><br><span class="line">&gt;&gt; rdd = df.rdd</span><br><span class="line">&gt;&gt; rdd.take(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">[Row(value=<span class="string">u&#x27;first line&#x27;</span>),</span><br><span class="line"> Row(value=<span class="string">u&#x27;second line&#x27;</span>),</span><br><span class="line"> Row(value=<span class="string">u&#x27;third line&#x27;</span>)]</span><br></pre></td></tr></table></figure><p>所以这里如果直接rdd.map(lambda line: line.split(“ “)) 会报错，因为操作的元素是Row，Row对象没有split方法。</p><h2 id="DataFrame-写入hive表"><a href="#DataFrame-写入hive表" class="headerlink" title="DataFrame 写入hive表"></a>DataFrame 写入hive表</h2><h3 id="一般步骤"><a href="#一般步骤" class="headerlink" title="一般步骤"></a>一般步骤</h3><p>参考：<a href="https://blog.csdn.net/a2639491403/article/details/80044121">https://blog.csdn.net/a2639491403/article/details/80044121</a></p><h4 id="1-创建数据集的spark-DattaFrame"><a href="#1-创建数据集的spark-DattaFrame" class="headerlink" title="1.创建数据集的spark DattaFrame"></a>1.创建数据集的spark DattaFrame</h4><p><code>df_tmp = spark.createDataFrame(RDD,schema)</code><br>这里schema是由StructFied函数定义的</p><h4 id="2-将数据集的DataFrames格式映射到零时表"><a href="#2-将数据集的DataFrames格式映射到零时表" class="headerlink" title="2.将数据集的DataFrames格式映射到零时表"></a>2.将数据集的DataFrames格式映射到零时表</h4><pre><code class="lang-df_tmp.createOrReplaceTempView(&#39;tempTable&#39;)```">#### 3.用spark sql语句将零时表的数据导入hive的tmp_table表中```sqlContext.sql(&#39;insert overwrite table des_table select *from tempTable&#39;)</code></pre><h3 id="写入分区表"><a href="#写入分区表" class="headerlink" title="写入分区表"></a>写入分区表</h3><p>参考：<a href="https://xinancsd.github.io/Python/pyspark_save_hive_table.html">https://xinancsd.github.io/Python/pyspark_save_hive_table.html</a></p><h4 id="df-write-saveAsTable-方法"><a href="#df-write-saveAsTable-方法" class="headerlink" title="df.write.saveAsTable() 方法"></a>df.write.saveAsTable() 方法</h4><p>需要注意的是hive表名<strong>是不明感大小写</strong>的，经历过如下现象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df = spark.sql(<span class="string">&quot;select tmpr.abc&quot;</span>)</span><br><span class="line">df.write.option(<span class="string">&quot;delimiter&quot;</span>, <span class="string">&#x27;\t&#x27;</span>).saveAsTable(<span class="string">&#x27;tmpr.ABC&#x27;</span>, <span class="built_in">format</span>=<span class="string">&#x27;hive&#x27;</span>, mode=<span class="string">&#x27;append&#x27;</span>, partitionBy=<span class="string">&#x27;dt&#x27;</span>)</span><br><span class="line">会写到原地址，因为如果原地址是：hdfs://xxxx/tmpr.db/abc，在使用新表tmpr.ABC时会从新创建地址，恰好是这一地址，所以数据又写回原地址了</span><br><span class="line"></span><br><span class="line">`mode=’overwrite’ `模式时，会创建新的表，若表名已存在则会被删除，整个表被重写。而 `mode=’append’` 模式会在直接在原有数据增加新数据，这一模式可以写入已存在的表。</span><br><span class="line">当使用overwrite时，saveAsTable 会自动创建hive表，partitionBy指定分区字段，默认存储为 parquet 文件格式。对于从文件生成的DataFrame，字段类型也是自动转换的，有时会转换成不符合要求的类型</span><br><span class="line"><span class="comment">##### format:</span></span><br></pre></td></tr></table></figure><p>hive （hive默认格式，数据文件纯文本无压缩存储）<br>parquet （spark默认采用格式）<br>orc<br>json<br>csv<br>text（若用saveAsTable只能保存只有一个列的df）<br>jdbc<br>libsvm</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.write.saveAsTable(save_table, mode=<span class="string">&#x27;append&#x27;</span>, partitionBy=[<span class="string">&#x27;pt_day&#x27;</span>])</span><br><span class="line">需要自定义字段类型的，可以在创建DataFrame时指定类型：</span><br></pre></td></tr></table></figure><p>from pyspark.sql.types import StringType, StructType, BooleanType, StructField</p><p>schema = StructType([<br>    StructField(“vin”, StringType(), True),<br>    StructField(“cust_id”, StringType(), True),<br>    StructField(“is_maintain”, BooleanType(), True),<br>    StructField(“is_wash”, BooleanType(), True),<br>    StructField(“pt_day”, StringType(), True),<br>  ]<br>)</p><p>data = pd.read_csv(‘/path/to/data.csv’, header=0)<br>df = spark.createDataFrame(data, schema=schema)</p><h1 id="写入hive表时就是指定的数据类型了"><a href="#写入hive表时就是指定的数据类型了" class="headerlink" title="写入hive表时就是指定的数据类型了"></a>写入hive表时就是指定的数据类型了</h1><p>df.write.saveAsTable(save_table, mode=’append’, partitionBy=[‘pt_day’]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#### option(&quot;delimiter&quot;, &#x27;\t&#x27;)</span></span><br><span class="line">写入hive表需要指定分割符时可使用如上方式</span><br><span class="line"></span><br><span class="line"><span class="comment">#### df.partitionBy(&#x27;dt&#x27;)和df.saveAsTable(partitionBy=[&#x27;dt&#x27;])的区别</span></span><br><span class="line">https://blog.csdn.net/qq_33536353/article/details/<span class="number">106165924</span></span><br><span class="line">对于两种写回分区表的方法：</span><br><span class="line">第一种：这种会清理hdfs路径，生成新的dt，**以为着重名旧分区会被删除，切记**</span><br></pre></td></tr></table></figure><p>df.write.mode(“overwrite”).format(“orc”).partitionBy(“dt”).saveAsTable(“aicloud.cust_features”)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">第二种：这种只会重写覆盖的分区，其他旧分区不会被删除</span><br><span class="line"></span><br><span class="line">df.write.saveAsTable(<span class="string">&quot;aicloud.cust_features&quot;</span>, <span class="built_in">format</span>=<span class="string">&quot;orc&quot;</span>, mode=<span class="string">&quot;overwrite&quot;</span>, partitionBy=<span class="string">&quot;dt&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h2><h3 id="Scala匿名函数不可用return"><a href="#Scala匿名函数不可用return" class="headerlink" title="Scala匿名函数不可用return"></a>Scala匿名函数不可用return</h3><p>Scala - return in anonymous function<br><a href="https://www.jianshu.com/p/2053634328d3">https://www.jianshu.com/p/2053634328d3</a></p><p>  [2]: <a href="https://sparkbyexamples.com/pyspark/pyspark-split-dataframe-column-into-multiple-columns/">https://sparkbyexamples.com/pyspark/pyspark-split-dataframe-column-into-multiple-columns/</a> 2019-12-25 14:26:31<br>vin Javascript &amp; JQuery # Javascript &amp; JQuery</p><p>标签（空格分隔）： javascript</p><hr><h2 id="JQuery选择器"><a href="#JQuery选择器" class="headerlink" title="JQuery选择器"></a>JQuery选择器</h2><p><a href="https://blog.csdn.net/qq_38225558/article/details/83780618">https://blog.csdn.net/qq_38225558/article/details/83780618</a></p><h2 id="chrome-脚本编辑器"><a href="#chrome-脚本编辑器" class="headerlink" title="chrome 脚本编辑器"></a>chrome 脚本编辑器</h2><p><a href="https://www.jianshu.com/p/87adbf88e2e3">https://www.jianshu.com/p/87adbf88e2e3</a><br><a href="https://www.cnblogs.com/liun1994/p/7265828.html">https://www.cnblogs.com/liun1994/p/7265828.html</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;pyspark-API&quot;&gt;&lt;a href=&quot;#pyspark-API&quot; class=&quot;headerlink&quot; title=&quot;pyspark API&quot;&gt;&lt;/a&gt;pyspark API&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://spark.apache.org/docs/2.2.1/api/python/search.html?q=dataframe.write&quot;&gt;https://spark.apache.org/docs/2.2.1/api/python/search.html?q=dataframe.write&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;简明教程&quot;&gt;&lt;a href=&quot;#简明教程&quot; class=&quot;headerlink&quot; title=&quot;简明教程&quot;&gt;&lt;/a&gt;简明教程&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://sparkbyexamples.com/pyspark/pyspark-orderby-and-sort-explained/&quot;&gt;https://sparkbyexamples.com/pyspark/pyspark-orderby-and-sort-explained/&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.learnbymarketing.com/1100/pyspark-joins-by-example/&quot;&gt;http://www.learnbymarketing.com/1100/pyspark-joins-by-example/&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>conda</title>
    <link href="http://yoursite.com/2024/02/29/conda/"/>
    <id>http://yoursite.com/2024/02/29/conda/</id>
    <published>2024-02-29T11:12:02.000Z</published>
    <updated>2025-05-22T05:50:40.064Z</updated>
    
    <content type="html"><![CDATA[<p>conda 是 Anaconda 的工具箱，它是 pip 和 vitualenv 的组合，也就是说他可以像pip来管理包，也可以像vitualenv来切换环境</p><h4 id="installation"><a href="#installation" class="headerlink" title="installation"></a>installation</h4><p><a href="https://www.digitalocean.com/community/tutorials/how-to-install-anaconda-on-ubuntu-18-04-quickstart">https://www.digitalocean.com/community/tutorials/how-to-install-anaconda-on-ubuntu-18-04-quickstart</a></p><h4 id="在conda中使用pip"><a href="#在conda中使用pip" class="headerlink" title="在conda中使用pip"></a>在conda中使用pip</h4><p>注意：当在conda的虚拟环境中使用Pip安装包时，需要使用<code>pip -V</code>查看Pip所使用的路径，如果conda没有安装Pip，会使用系统默认的pip命令，这种结果使得pip安装的包被安装到了系统库位置，从而在当前虚拟环境中的python下无法使用或找不到。<br>一般conda的虚拟环境中自带pip，如果你是用pip3安装，可能使用的是系统的pip，这一点要注意</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(face_detector) ➜  ~ pip -V</span><br><span class="line">pip 9.0.1 from /opt/anaconda3/envs/face_detector/lib/python3.5/site-packages (python 3.5)</span><br><span class="line">(face_detector) ➜  ~ pip3 -V</span><br><span class="line">pip 20.0.2 from /usr/local/lib/python3.7/site-packages/pip (python 3.7)</span><br></pre></td></tr></table></figure><p>的开发环境会被默认安装在你conda目录下的envs文件目录下。可以指定一个其他的路径；去通过 conda create -h了解更<br>果我们没有指定安装python的版本，conda会安装我们最初安装conda时所装的那个版本的python。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列举当前所有环境</span></span><br><span class="line">conda info</span><br><span class="line">conda env <span class="built_in">list</span></span><br><span class="line"><span class="comment"># 创建环境</span></span><br><span class="line">conda create --name new_env_name python=<span class="number">2.7</span><span class="number">.9</span></span><br><span class="line">conda create -n new_env_name python=<span class="number">2.7</span><span class="number">.9</span></span><br><span class="line"><span class="comment"># 克隆环境 (例如当前环境是base, 需要克隆一个copy_base，地址在~/path)</span></span><br><span class="line">conda create -n copy_base --clone ~/path</span><br><span class="line"><span class="comment"># 激活环境</span></span><br><span class="line">source activate snowflakes  <span class="comment">#linux</span></span><br><span class="line">activate new_env_name <span class="comment">#windows</span></span><br><span class="line"><span class="comment"># 释放环境</span></span><br><span class="line">source deactivate <span class="comment">#linux</span></span><br><span class="line">deactivate <span class="comment">#windows</span></span><br><span class="line"><span class="comment"># 移除环境</span></span><br><span class="line">conda remove --name new_env_name --<span class="built_in">all</span></span><br><span class="line">conda remove -n new_env_name --<span class="built_in">all</span></span><br><span class="line"><span class="comment"># 保存环境\分享环境</span></span><br><span class="line">conda env export &gt; environment.yml</span><br><span class="line"><span class="comment"># 恢复环境</span></span><br><span class="line">conda env create -f environment.yml</span><br><span class="line"><span class="comment"># 查看当前环境所有package</span></span><br><span class="line">conda <span class="built_in">list</span></span><br><span class="line"><span class="comment"># 为指定环境安装某个包</span></span><br><span class="line">conda install -n env_name package_name</span><br><span class="line"><span class="comment"># 查找包有哪些版本</span></span><br><span class="line">conda search tensorflow-gpu </span><br><span class="line"><span class="comment"># 将conda放入PATH</span></span><br><span class="line"><span class="built_in">eval</span> <span class="string">&quot;$(/home/yuanwenwu/anaconda3/bin/conda shell.YOUR_SHELL_NAME hook)&quot;</span></span><br></pre></td></tr></table></figure><ul><li>在python2.7环境中启动notebook 使kernel变为python3、python2共存</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入python2虚拟环境，执行下面语句，然后启动jupyter notebook即可</span></span><br><span class="line">python -m ipykernel install --user</span><br></pre></td></tr></table></figure><ul><li>问题1：python能找到的包，jupyter notebook找不到</li></ul><p>是因为python执行路径不一致。<br>定位这个问题可以通过sys包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="built_in">print</span>(sys.executable)</span><br></pre></td></tr></table></figure><p>往往这个问题是只安装了python，但要使用ipython或jupyter notebook，由于虚拟环境没有，会去主系统找可用版本呢，从而导致启动路径不一致，解决方式是在虚拟环境conda install需要的包（ ipython or jupyter notebook )<br>参考：<a href="https://blog.csdn.net/sunxinyu/article/details/78801534">https://blog.csdn.net/sunxinyu/article/details/78801534</a></p><h4 id="conda-更换源"><a href="#conda-更换源" class="headerlink" title="conda 更换源"></a>conda 更换源</h4><h4 id="conda-安装指定version包"><a href="#conda-安装指定version包" class="headerlink" title="conda 安装指定version包"></a>conda 安装指定version包</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda search tensorflow</span><br><span class="line">conda install tensorflow-gpu==<span class="number">2.0</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;conda 是 Anaconda 的工具箱，它是 pip 和 vitualenv 的组合，也就是说他可以像pip来管理包，也可以像vitualenv来切换环境&lt;/p&gt;
&lt;h4 id=&quot;installation&quot;&gt;&lt;a href=&quot;#installation&quot; class=&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>matplotlib</title>
    <link href="http://yoursite.com/2024/02/29/matplotlib/"/>
    <id>http://yoursite.com/2024/02/29/matplotlib/</id>
    <published>2024-02-29T11:10:11.000Z</published>
    <updated>2025-05-22T05:50:40.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h2><h3 id="pyplot"><a href="#pyplot" class="headerlink" title="pyplot"></a>pyplot</h3><p>&emsp;pyplot负责绘制图像，修饰图像figure。此处应强调的是，其保持matlab的风格，总是跟踪当前figure,绘制函数直接指向当前axes.<br>&emsp;figure()函数负责创建一个图像，默认不用调用此函数，并且一个subplot(111)也会默认被创建如果不手动指定axes的话。figure(i)创建标号为i的figure</p><span id="more"></span><h3 id="结构知识"><a href="#结构知识" class="headerlink" title="结构知识"></a>结构知识</h3><p><a href="https://zhuanlan.zhihu.com/p/93423829">plt, axes, figure之间的关系</a></p><p>![此处输入图片的描述][1]<br>![此处输入图片的描述][2]</p><h3 id="绘制子图"><a href="#绘制子图" class="headerlink" title="绘制子图"></a>绘制子图</h3><p><a href="https://blog.csdn.net/You_are_my_dream/article/details/53439518">https://blog.csdn.net/You_are_my_dream/article/details/53439518</a><br>dataFrame绘制在子图上<br><a href="https://blog.csdn.net/htuhxf/article/details/82986440?spm=1001.2014.3001.5502">https://blog.csdn.net/htuhxf/article/details/82986440?spm=1001.2014.3001.5502</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">fig.suptitle(<span class="string">&quot;whole title&quot;</span>)</span><br><span class="line"><span class="comment"># 等价于：</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">fig.suptitle(<span class="string">&quot;whole title&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>使用subplots (<strong>Template</strong> !!!)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># data</span></span><br><span class="line">curve_list = []</span><br><span class="line">x = np.arange(<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">curve_list.append((x, x))</span><br><span class="line">curve_list.append((x, -x))</span><br><span class="line">curve_list.append((x, x**<span class="number">2</span>))</span><br><span class="line">curve_list.append((x, np.log(x)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># sub window nums</span></span><br><span class="line">n = <span class="built_in">len</span>(curve_list)</span><br><span class="line">column_num = <span class="number">2</span></span><br><span class="line">row_num = <span class="built_in">int</span>(np.ceil(n/column_num))</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct figure and pre split</span></span><br><span class="line">fig, axes = plt.subplots(row_num, column_num, figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">fig.suptitle(<span class="string">&quot;curve show&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw sub plot on figure</span></span><br><span class="line">index = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> axes:</span><br><span class="line">    <span class="keyword">for</span> ax <span class="keyword">in</span> row:</span><br><span class="line">        x, y = curve_list[index]</span><br><span class="line">        ax.set_title(<span class="string">&quot;curve_&#123;&#125;&quot;</span>.<span class="built_in">format</span>(index))</span><br><span class="line">        <span class="comment"># plot 时设置 label, 颜色, 线宽度等</span></span><br><span class="line">        ax.plot(x, y, <span class="string">&#x27;C&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(index), label=<span class="string">&#x27;curve&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(index), linewidth=<span class="number">2</span>)</span><br><span class="line">        ax.grid(color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, linewidth=<span class="number">1</span>,alpha=<span class="number">0.3</span>)</span><br><span class="line">        index += <span class="number">1</span> </span><br><span class="line">        <span class="comment"># ax 显示label, 可设置显示位置</span></span><br><span class="line">        ax.legend(loc=<span class="string">&#x27;lower right&#x27;</span>, fontsize=<span class="number">10</span>)   </span><br></pre></td></tr></table></figure><ul><li>subplots和DataFrame结合<br><a href="https://blog.csdn.net/htuhxf/article/details/82986440?spm=1001.2014.3001.5502">https://blog.csdn.net/htuhxf/article/details/82986440?spm=1001.2014.3001.5502</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">data = pd.Series(np.random.rand(<span class="number">16</span>), index=<span class="built_in">list</span>(<span class="string">&#x27;abcdefghijklmnop&#x27;</span>))</span><br><span class="line">data.plot.bar(ax=axes[<span class="number">1</span>,<span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">data.plot.barh(ax=axes[<span class="number">0</span>,<span class="number">1</span>], color=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><ul><li>使用add_subplot</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">x = np.arange(<span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="comment"># first you have to make the figure</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line"><span class="comment"># now you have to create each subplot individually</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">221</span>)</span><br><span class="line">ax1.plot(x, x)</span><br><span class="line">ax2 = fig.add_subplot(<span class="number">222</span>)</span><br><span class="line">ax2.plot(x, -x)</span><br><span class="line">ax3 = fig.add_subplot(<span class="number">223</span>)</span><br><span class="line">ax3.plot(x, x ** <span class="number">2</span>)</span><br><span class="line">ax4 = fig.add_subplot(<span class="number">224</span>)</span><br><span class="line">ax4.plot(x, np.log(x))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>多个子图的模板</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">figure = plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">cols, rows = <span class="number">3</span>, <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, cols * rows + <span class="number">1</span>):</span><br><span class="line">    sample_idx = torch.randint(<span class="built_in">len</span>(training_data), size=(<span class="number">1</span>,)).item()</span><br><span class="line">    img, label = training_data[sample_idx]</span><br><span class="line">    figure.add_subplot(rows, cols, i)</span><br><span class="line">    plt.title(labels_map[label])</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.imshow(img.squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>code [link][3]<br>![此处输入图片的描述][4]</p><ul><li>使用subplot</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment">#coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="comment"># first you have to make the figure</span></span><br><span class="line">fig = plt.figure(<span class="number">1</span>) </span><br><span class="line"><span class="comment"># now you have to create each subplot individually</span></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.plot(x, x)</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.plot(x, -x)</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(x, x ** <span class="number">2</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.plot(x, np.log(x))</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line"><span class="comment"># ax1 = plt.subplot(221)</span></span><br><span class="line"><span class="comment"># ax1.plot(x, x)</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="定制legend"><a href="#定制legend" class="headerlink" title="定制legend"></a>定制legend</h3><p>场景，例如在绘制曲线的是后想绘制每个曲线的极值点，同事legend是”曲线名+极值点value”这种需求，可以使用custom legend<br>普通plt.plot(x,y)会返回绘制的曲线，是Line2D object, 获取这些objects后，使用ax.legend(lines, legends, loc=’lower right’)可以定制legend<br>例如</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># simple example</span></span><br><span class="line">lines = plt.plot(data)</span><br><span class="line">plt.legend(lines, [<span class="string">&#x27;line1&#x27;</span>,<span class="string">&#x27;line2&#x27;</span>,<span class="string">&#x27;lin3&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># another simple example</span></span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> randn</span><br><span class="line">z = randn(<span class="number">10</span>)</span><br><span class="line">red_dot, = plt.plot(z, <span class="string">&quot;ro&quot;</span>, markersize=<span class="number">15</span>)</span><br><span class="line"><span class="comment"># Put a white cross over some of the data.</span></span><br><span class="line">white_cross, = plt.plot(z[:<span class="number">5</span>], <span class="string">&quot;w+&quot;</span>, markeredgewidth=<span class="number">3</span>, markersize=<span class="number">15</span>)</span><br><span class="line">plt.legend([red_dot, (red_dot, white_cross)], [<span class="string">&quot;Attr A&quot;</span>, <span class="string">&quot;Attr A+B&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># practice example</span></span><br><span class="line"><span class="comment"># 注意dataframe.plot不返回Line2D对象，如果需要曲线对象，需要使用dataframe.plot.line(), 最好还是使用原始的ax.plot()分column绘制，这样好控制一些</span></span><br><span class="line">lines = []</span><br><span class="line">legends = []</span><br><span class="line"><span class="keyword">for</span> idx, metric_type <span class="keyword">in</span> <span class="built_in">enumerate</span>(metrics_type_column):</span><br><span class="line">    data = df[metric_type]</span><br><span class="line">    x, y = data.idxmax(), data.<span class="built_in">max</span>()</span><br><span class="line">    line = ax.plot(data, c=<span class="string">&#x27;C%d&#x27;</span>%(idx))</span><br><span class="line">    lines.extend(line)</span><br><span class="line">    ax.scatter(x, y, c=<span class="string">&#x27;C%d&#x27;</span>%(idx), alpha=<span class="number">0.5</span>)</span><br><span class="line">    legends.append(<span class="string">&quot;%s max=%.4f&quot;</span>%(metric_type.replace(<span class="string">&quot;bf_&quot;</span>, <span class="string">&quot;&quot;</span>), y))</span><br><span class="line">ax.legend(lines, legends, loc=<span class="string">&#x27;lower right&#x27;</span>)</span><br></pre></td></tr></table></figure><h4 id="Legend-for-Size-of-Points"><a href="#Legend-for-Size-of-Points" class="headerlink" title="Legend for Size of Points"></a>Legend for Size of Points</h4><p><a href="https://jakevdp.github.io/PythonDataScienceHandbook/04.06-customizing-legends.html">https://jakevdp.github.io/PythonDataScienceHandbook/04.06-customizing-legends.html</a></p><h3 id="绘制gauss曲线"><a href="#绘制gauss曲线" class="headerlink" title="绘制gauss曲线"></a>绘制gauss曲线</h3><p><a href="http://emredjan.github.io/blog/2017/07/19/plotting-distributions/">http://emredjan.github.io/blog/2017/07/19/plotting-distributions/</a></p><h3 id="绘制activation-函数曲线"><a href="#绘制activation-函数曲线" class="headerlink" title="绘制activation 函数曲线"></a>绘制activation 函数曲线</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.widgets <span class="keyword">import</span> Cursor</span><br><span class="line"><span class="comment"># data</span></span><br><span class="line">x = np.arange(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">0.1</span>)</span><br><span class="line">y1 = np.log(np.exp(x)+ <span class="number">1</span>) </span><br><span class="line">y2 = np.maximum(<span class="number">0</span>, x)</span><br><span class="line"><span class="comment"># draw</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">fig.suptitle(<span class="string">&quot;activation function&quot;</span>)</span><br><span class="line">axes = fig.add_subplot()</span><br><span class="line">axes.plot(x, y1, color=<span class="string">&#x27;C0&#x27;</span>, label=<span class="string">&#x27;softplus&#x27;</span>)</span><br><span class="line">axes.plot(x, y2, color=<span class="string">&#x27;C1&#x27;</span>, label=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment">#axes.set_ylim((-1,3))</span></span><br><span class="line"><span class="comment">#ax.grid()</span></span><br><span class="line"><span class="comment">#axes.set_yticks(np.arange(-1, max(y+1), 1))</span></span><br><span class="line"><span class="comment">#axes.set_xticks(np.arange(-3, max(x+1), 1))</span></span><br><span class="line"><span class="comment"># 注意set_yticks会造成图空出一部分，函数说明也很明显：If necessary, the view limits of the Axis are expanded so that all given ticks are visible.</span></span><br><span class="line">axes.axis([-<span class="number">3</span>,<span class="number">3</span>,-<span class="number">1</span>,<span class="number">3</span>])</span><br><span class="line"><span class="comment"># axis 函数则直接会截取到指定区间，不会空余出margin</span></span><br><span class="line">axes.grid(linestyle=<span class="string">&#x27;--&#x27;</span>, linewidth=<span class="number">1</span>,alpha=<span class="number">0.3</span>)</span><br><span class="line">axes.axvline(x=<span class="number">0</span>, linewidth=<span class="number">1</span>, color=<span class="string">&#x27;black&#x27;</span>,alpha=<span class="number">0.6</span>)</span><br><span class="line">axes.axhline(y=<span class="number">0</span>, linewidth=<span class="number">1</span>,  color=<span class="string">&#x27;black&#x27;</span>,alpha=<span class="number">0.6</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;matplotlib&quot;&gt;&lt;a href=&quot;#matplotlib&quot; class=&quot;headerlink&quot; title=&quot;matplotlib&quot;&gt;&lt;/a&gt;matplotlib&lt;/h2&gt;&lt;h3 id=&quot;pyplot&quot;&gt;&lt;a href=&quot;#pyplot&quot; class=&quot;headerlink&quot; title=&quot;pyplot&quot;&gt;&lt;/a&gt;pyplot&lt;/h3&gt;&lt;p&gt;&amp;emsp;pyplot负责绘制图像，修饰图像figure。此处应强调的是，其保持matlab的风格，总是跟踪当前figure,绘制函数直接指向当前axes.&lt;br&gt;&amp;emsp;figure()函数负责创建一个图像，默认不用调用此函数，并且一个subplot(111)也会默认被创建如果不手动指定axes的话。figure(i)创建标号为i的figure&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>linux</title>
    <link href="http://yoursite.com/2024/02/29/linux/"/>
    <id>http://yoursite.com/2024/02/29/linux/</id>
    <published>2024-02-29T09:57:34.000Z</published>
    <updated>2025-05-22T05:50:40.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建数组(注意不需要逗号，以空格分隔)</span></span><br><span class="line">array=(1 2 3 4)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">获取所有元素</span></span><br><span class="line">echo $&#123;array[@]&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">获取第一个元素</span></span><br><span class="line">echo $&#123;array[0]&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">获取数组元素个数</span></span><br><span class="line">echo $&#123;#array[@]&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果某个元素是字符串，还可以通过指定下标的方式获得该元素的长度，如下所示：</span></span><br><span class="line">echo $&#123;#array[2]&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">因为字符串获取长度如下</span></span><br><span class="line">str=&quot;hello world&quot;</span><br><span class="line">echo $&#123;#str&#125;</span><br></pre></td></tr></table></figure><span id="more"></span><h3 id="将command结果存入数组-不受空格影响"><a href="#将command结果存入数组-不受空格影响" class="headerlink" title="将command结果存入数组(不受空格影响)"></a>将command结果存入数组(不受空格影响)</h3><p><a href="https://stackoverflow.com/questions/11426529/reading-output-of-a-command-into-an-array-in-bash">https://stackoverflow.com/questions/11426529/reading-output-of-a-command-into-an-array-in-bash</a><br>The other answers will break if output of command contains spaces (which is rather frequent) or glob characters like *, ?, […].</p><p>To get the output of a command in an array, with one line per element, there are essentially 3 ways:</p><h3 id="1-With-Bash≥4-use-mapfile—it’s-the-most-efficient"><a href="#1-With-Bash≥4-use-mapfile—it’s-the-most-efficient" class="headerlink" title="1. With Bash≥4 use mapfile—it’s the most efficient"></a>1. With Bash≥4 use mapfile—it’s the most efficient</h3><p>mapfile使用方式：<a href="https://wangchujiang.com/linux-command/c/mapfile.html">https://wangchujiang.com/linux-command/c/mapfile.html</a><br>箭头紧贴括号是将内部命令转换为临时文件，参照<a href="https://tldp.org/LDP/abs/html/process-sub.html">https://tldp.org/LDP/abs/html/process-sub.html</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mapfile -t my_array &lt; &lt;( my_command )</span><br></pre></td></tr></table></figure><h3 id="2-Otherwise-a-loop-reading-the-output-slower-but-safe"><a href="#2-Otherwise-a-loop-reading-the-output-slower-but-safe" class="headerlink" title="2. Otherwise, a loop reading the output (slower, but safe)"></a>2. Otherwise, a loop reading the output (slower, but safe)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">my_array=()</span><br><span class="line">while IFS= read -r line; do</span><br><span class="line">    my_array+=( &quot;$line&quot; )</span><br><span class="line">done &lt; &lt;( my_command )</span><br></pre></td></tr></table></figure><h3 id="3-As-suggested-by-Charles-Duffy-in-the-comments-thanks-the-following-might-perform-better-than-the-loop-method-in-number-2"><a href="#3-As-suggested-by-Charles-Duffy-in-the-comments-thanks-the-following-might-perform-better-than-the-loop-method-in-number-2" class="headerlink" title="3. As suggested by Charles Duffy in the comments (thanks!), the following might perform better than the loop method in number 2"></a>3. As suggested by Charles Duffy in the comments (thanks!), the following might perform better than the loop method in number 2</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IFS=$&#x27;\n&#x27; read -r -d &#x27;&#x27; -a my_array &lt; &lt;( my_command &amp;&amp; printf &#x27;\0&#x27; )</span><br></pre></td></tr></table></figure><p>查看IFS值</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;$IFS&quot; | od -b</span><br><span class="line">0000000 040 011 012 012</span><br><span class="line">0000004</span><br></pre></td></tr></table></figure><h3 id="set命令"><a href="#set命令" class="headerlink" title="set命令"></a>set命令</h3><p><a href="http://www.ruanyifeng.com/blog/2017/11/bash-set.html">http://www.ruanyifeng.com/blog/2017/11/bash-set.html</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">set -eu</span><br><span class="line">set -o pipefail</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">folder=&quot;MSNClick&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">IFS=$<span class="string">&#x27;\n&#x27;</span> <span class="built_in">read</span> -r -d <span class="string">&#x27;&#x27;</span> -a array &lt; &lt;( <span class="built_in">du</span> -d 1 <span class="variable">$folder</span>/* | <span class="built_in">sort</span> -n -t 1 -r &amp;&amp; <span class="built_in">printf</span> <span class="string">&#x27;\0&#x27;</span> )</span></span><br><span class="line">mapfile -t array &lt; &lt;( du -d 1 $folder/* | sort -n -t 1 -r )</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">echo</span> -n <span class="string">&quot;<span class="variable">$IFS</span>&quot;</span> | <span class="built_in">od</span> -b</span></span><br><span class="line"></span><br><span class="line">function fun()&#123;</span><br><span class="line">    local IFS=$&#x27; &#x27;</span><br><span class="line"></span><br><span class="line">    #echo -n &quot;$IFS&quot; | od -b</span><br><span class="line"></span><br><span class="line">    for line in $&#123;array[@]&#125;;do</span><br><span class="line">        size=`echo $line |cut -f 1`</span><br><span class="line">        model_dir=`echo $line |cut -f 2`</span><br><span class="line">        debug_case_dir=&quot;$model_dir/debug_case&quot;</span><br><span class="line">        if [[ $size -gt 100000 ]];then</span><br><span class="line">            echo &quot;$model_dir, size=$(($size / 1024))M&quot;</span><br><span class="line">            if [ -d $debug_case_dir ]; then</span><br><span class="line">                echo &quot;rm $model_dir/*.bin&quot;</span><br><span class="line">                rm $model_dir/*.bin</span><br><span class="line">            else</span><br><span class="line">                echo &quot;rm $model_dir/*.tsv&quot;</span><br><span class="line">                rm $model_dir/*.tsv</span><br><span class="line">                echo &quot;rm $model_dir/*.bin&quot;</span><br><span class="line">                rm $model_dir/*.bin</span><br><span class="line">            fi</span><br><span class="line">        fi</span><br><span class="line">    done</span><br><span class="line"></span><br><span class="line">    return 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fun</span><br></pre></td></tr></table></figure><h2 id="参数判空"><a href="#参数判空" class="headerlink" title="参数判空"></a>参数判空</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if [ ! -n &quot;$end_dt&quot; ];then</span><br><span class="line">    echo &quot;end_dt is None&quot;</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h2 id="参数数量校验"><a href="#参数数量校验" class="headerlink" title="参数数量校验"></a>参数数量校验</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">param_len=$#</span><br><span class="line">if [ $param_len != 3 ];then</span><br><span class="line">    echo &quot;train need 3 parameters, now $param_len&quot;</span><br><span class="line">    exit 1;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h2 id="循环日期"><a href="#循环日期" class="headerlink" title="循环日期"></a>循环日期</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">t_end=`date -d &quot;$end_dt&quot; +%s`</span><br><span class="line">cur_dt=$start_dt</span><br><span class="line">while true</span><br><span class="line">do</span><br><span class="line">  t_cur=`date -d &quot;$cur_dt&quot; +%s`</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">当开始时间小于结束时间时，直接结束脚本</span></span><br><span class="line">  if [ $t_cur -gt $t_end ]; then</span><br><span class="line">    break</span><br><span class="line">  fi</span><br><span class="line">  echo -e &quot;\n&quot;</span><br><span class="line">  echo &quot;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; $cur_dt &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;</span><br><span class="line"></span><br><span class="line">  sh run.sh $cur_dt</span><br><span class="line">  check_result &quot;backtrace from rank $cur_dt&quot;</span><br><span class="line">  cur_dt=`date --date &quot;$cur_dt 1 day&quot; +%Y-%m-%d`</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="分割文件"><a href="#分割文件" class="headerlink" title="分割文件"></a>分割文件</h2><h3 id="Split文件"><a href="#Split文件" class="headerlink" title="Split文件"></a>Split文件</h3><p><a href="https://www.cnblogs.com/OliverQin/p/10240222.html">https://www.cnblogs.com/OliverQin/p/10240222.html</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># file contains 5000 lines</span><br><span class="line">split -l 1000 tmp.log -d -a 2 tmp_part_</span><br><span class="line"># will result like below</span><br><span class="line">tmp_part_00</span><br><span class="line">tmp_part_01</span><br><span class="line">...</span><br><span class="line">tmp_part_04</span><br></pre></td></tr></table></figure><h3 id="Merg文件"><a href="#Merg文件" class="headerlink" title="Merg文件"></a>Merg文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat part_dir/tmp_part_* &gt;&gt; tmp.log</span><br></pre></td></tr></table></figure><h2 id="统计用户存储占用情况-sort"><a href="#统计用户存储占用情况-sort" class="headerlink" title="统计用户存储占用情况(sort)"></a>统计用户存储占用情况(sort)</h2><p>du -sh ./* | sort -rh<br>find ./data -size +200M | xargs ls -lSh</p><h2 id="字符处理"><a href="#字符处理" class="headerlink" title="字符处理"></a>字符处理</h2><h3 id="统计字符串单词个数"><a href="#统计字符串单词个数" class="headerlink" title="统计字符串单词个数"></a>统计字符串单词个数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方法1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;one two three four five&#x27;</span> | <span class="built_in">wc</span> -w</span><br><span class="line"><span class="comment"># 方法2</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;one two three four five&#x27;</span> | awk <span class="string">&#x27;&#123;print NF&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 方法3 </span></span><br><span class="line">s=<span class="string">&#x27;one two three four five&#x27;</span> </span><br><span class="line"><span class="built_in">set</span> <span class="variable">$&#123;s&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$#</span></span><br><span class="line"><span class="comment"># 方法4 通过数组方式获取</span></span><br><span class="line">=<span class="string">&#x27;one two three four five&#x27;</span> </span><br><span class="line">a=(<span class="variable">$s</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;#a[@]&#125;</span></span><br><span class="line"><span class="comment"># 方法5</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;one two three four five&#x27;</span> | <span class="built_in">tr</span> <span class="string">&#x27; &#x27;</span> <span class="string">&#x27;\n&#x27;</span> | <span class="built_in">wc</span> -l</span><br></pre></td></tr></table></figure><h3 id="提取数字"><a href="#提取数字" class="headerlink" title="提取数字"></a>提取数字</h3><p>如果某一行如下<br>file.txt</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line"> &#123;space&#125;&#123;space&#125;&#123;\t&#125;numRows&#123;space&#125;&#123;\t&#125;122321</span><br><span class="line">……</span><br></pre></td></tr></table></figure><p>上述文件里有某一行需要提取numRows，但此行有空格，制表符,如果想提取数字保存变量，可以使用tr命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">numRows=`cat file.txt | grep &quot;numRows&quot; | tr -cd [0-9]`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">tr</span> 命令</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">tr</span> -<span class="built_in">cd</span> [<span class="string">&#x27;字符集合&#x27;</span>]</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  -d：delete；-c：complement；-<span class="built_in">cd</span>：删除后边的参数以外的</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  ps: complement意味着补集</span></span><br></pre></td></tr></table></figure><h3 id="打印信息"><a href="#打印信息" class="headerlink" title="打印信息"></a>打印信息</h3><p>echo -e 可以输出’\t</p><h4 id="打印一条线"><a href="#打印一条线" class="headerlink" title="打印一条线"></a>打印一条线</h4><p><a href="https://blog.csdn.net/u013670453/article/details/113462422">https://blog.csdn.net/u013670453/article/details/113462422</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">printf &#x27;#%.0s&#x27; &#123;1..100&#125;</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">printf &#x27;%100s\n&#x27; | tr &#x27; &#x27; =</span><br></pre></td></tr></table></figure><h3 id="选定某几行"><a href="#选定某几行" class="headerlink" title="选定某几行"></a>选定某几行</h3><p><a href="http://www.cnblogs.com/xianghang123/archive/2011/08/03/2125977.html">参考资料</a><br>【一】从第3000行开始，显示1000行。即显示3000~3999行<br><code>cat filename | tail -n +3000 | head -n 1000</code><br>【二】显示1000行到3000行<br><code>cat filename| head -n 3000 | tail -n +1000</code><br>*注意两种方法的顺序<br>分解：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tail -n 1000：显示最后1000行</span><br><span class="line">tail -n +1000：从1000行开始显示，显示1000行以后的</span><br><span class="line">head -n 1000：显示前面1000行</span><br></pre></td></tr></table></figure><p>【三】用sed命令<br> <code>sed -n &#39;5,10p&#39; filename</code><br> 这样你就可以只查看文件的第5行到第10行。<br> 如果不加n, 会将5,10行打印一遍，同时打印全部文件；加n是取消default print的执行<br> -n, —quiet, —silent: suppress automatic printing of pattern space</p><h3 id="linux-sort-uniq-cut-wc命令详解"><a href="#linux-sort-uniq-cut-wc命令详解" class="headerlink" title="linux sort,uniq,cut,wc命令详解"></a>linux sort,uniq,cut,wc命令详解</h3><p><a href="https://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858385.html">https://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858385.html</a>)</p><h4 id="cut"><a href="#cut" class="headerlink" title="cut"></a>cut</h4><p><a href="https://www.cnblogs.com/f-ck-need-u/p/7521357.html">https://www.cnblogs.com/f-ck-need-u/p/7521357.html</a></p><h4 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h4><p><a href="https://www.cnblogs.com/ding2016/p/9668425.html">https://www.cnblogs.com/ding2016/p/9668425.html</a><br>sort可以对行进行排序，包括按数字，以及按照split后某一列排序等<br>常见一种情况，例如目录有如下文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">logs/</span><br><span class="line">├── 202005_0_detect.log</span><br><span class="line">├── 202005_10_detect.log</span><br><span class="line">├── 202005_11_detect.log</span><br><span class="line">├── 202005_1_detect.log</span><br><span class="line">├── 202005_2_detect.log</span><br><span class="line">├── 202005_3_detect.log</span><br><span class="line">├── 202005_4_detect.log</span><br><span class="line">├── 202005_5_detect.log</span><br><span class="line">├── 202005_6_detect.log</span><br><span class="line">├── 202005_7_detect.log</span><br><span class="line">├── 202005_8_detect.log</span><br><span class="line">└── 202005_9_detect.log</span><br></pre></td></tr></table></figure><p>想按照数字排序，如果直接使用ls会以字母序排序，得到的结果会如上所示，因为ls将数字按照字符串排序，先排第一位再排第二位，类似基数排序的思想。<br>如果想按照数字顺序就需要sort命令了，sort命令如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sort --help</span><br><span class="line">-n # sort by num 按数字排序</span><br><span class="line">-k # split后选则第k列作为排序依据</span><br><span class="line">-t # terminate 指定分隔符</span><br><span class="line">……</span><br></pre></td></tr></table></figure><p>形成的命令如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ls logs/*.log | sort -n -k 2 -t _</span><br><span class="line"></span><br><span class="line"># another example</span><br><span class="line"># 按照第四列，以数字方式排列，分割方式是Tab键， 取某一区间结果</span><br><span class="line">sort -k 4 -n -t$&#x27;\t&#x27; -r userIdMap.tsv | sed -n &#x27;30000, 30500p&#x27; &gt; userIdMapSort.tsv</span><br></pre></td></tr></table></figure><h5 id="处理tab键分隔符"><a href="#处理tab键分隔符" class="headerlink" title="处理tab键分隔符"></a>处理tab键分隔符</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sort -n -k 4 -r -t$&#x27;\t&#x27; userIdMap.tsv</span><br></pre></td></tr></table></figure><h5 id="sort-排列日期字符串"><a href="#sort-排列日期字符串" class="headerlink" title="sort 排列日期字符串"></a>sort 排列日期字符串</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#例如文件内容 data.txt：</span><br><span class="line">2020-11-14_2020-12-01/train/2020-11-30_2020-12-01</span><br><span class="line">2020-12-01_2020-12-20/train/2020-12-01_2020-12-02</span><br><span class="line">2020-12-01_2020-12-20/train/2020-12-02_2020-12-03</span><br><span class="line">2020-12-01_2020-12-20/train/2020-12-03_2020-12-04</span><br><span class="line">2020-12-01_2020-12-20/train/2020-12-04_2020-12-05</span><br><span class="line">2020-12-01_2020-12-20/train/2020-12-05_2020-12-06</span><br><span class="line">2020-12-01_2020-12-20/train/2020-12-06_2020-12-07</span><br><span class="line"></span><br><span class="line">sort -n -k 2 -k 3 -k 4 -k 5 -k 7 -k 8 -t &#x27;-&#x27; data.txt </span><br></pre></td></tr></table></figure><h5 id="sort-MAC-OS换行符不起作用"><a href="#sort-MAC-OS换行符不起作用" class="headerlink" title="sort MAC OS换行符不起作用"></a>sort MAC OS换行符不起作用</h5><p>原因就是Max OS X上的sed是BSD的版本，Linux上的是Gnu的版本，导致的不一致<br>可以brew install gnu-sed和替换调用sed与gsed。<br>如果不想在“ g”之前加上sed，可以brew install gnu-sed —with-default-names</p><h5 id="sort-处理负数"><a href="#sort-处理负数" class="headerlink" title="sort 处理负数"></a>sort 处理负数</h5><p>sort -g 注意使用了-g就要去掉-n两者是冲突的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sort -g ……</span><br><span class="line"># or --general-numeric-sort</span><br><span class="line"># or --sort=general-numeric</span><br></pre></td></tr></table></figure><h3 id="xarg"><a href="#xarg" class="headerlink" title="xarg"></a>xarg</h3><p><a href="http://www.ruanyifeng.com/blog/2019/08/xargs-tutorial.html">http://www.ruanyifeng.com/blog/2019/08/xargs-tutorial.html</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep /bin/bash | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs -n 1 kill -9</span><br><span class="line"># -n参数指定每次将多少项，作为命令行参数。</span><br><span class="line">$ echo &#123;0..9&#125; | xargs -n 2 echo</span><br><span class="line">0 1</span><br><span class="line">2 3</span><br><span class="line">4 5</span><br><span class="line">6 7</span><br><span class="line">8 9</span><br></pre></td></tr></table></figure><h4 id="从一系列日志文件中提取相同一行内容"><a href="#从一系列日志文件中提取相同一行内容" class="headerlink" title="从一系列日志文件中提取相同一行内容"></a>从一系列日志文件中提取相同一行内容</h4><p>例如，从多个spark日志中提取tracking URL</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -t logs/extract_*.log | head -10 | xargs -L 1 grep &quot;tracking URL&quot; -m 1</span><br></pre></td></tr></table></figure><p>几个知识点：</p><ul><li>xargs 的形式是：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xargs [-options] [command]</span><br></pre></td></tr></table></figure><ul><li>xargs -L n : 如果输入是多行，需要以<strong>几行</strong>作为参数：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; cat tmp.txt</span><br><span class="line">img-1.jpeg</span><br><span class="line">img-1-backup.jpeg</span><br><span class="line">img-2.jpeg</span><br><span class="line">img-2-backup.jpeg</span><br><span class="line"></span><br><span class="line">cat tmp.txt | xargs -L 2 cp</span><br><span class="line"># 上面命令实现：cp img-d img-d-backup的功能</span><br></pre></td></tr></table></figure><p>意味着xargs后面需要接command，如果直接接管道会出错</p><ul><li>grep 取第一个匹配结果: grrep ‘xxx’ -m 1</li></ul><h3 id="查找文件名"><a href="#查找文件名" class="headerlink" title="查找文件名"></a>查找文件名</h3><h4 id="Find"><a href="#Find" class="headerlink" title="Find"></a>Find</h4><p>find &lt;指定目录&gt; &lt;指定条件&gt; &lt;指定动作&gt;</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">find . -name &#x27;my*&#x27;</span><br><span class="line">find . -name &#x27;my*&#x27; -ls</span><br><span class="line">find . -type f -mmin -10 #搜索当前目录中，所有过去10分钟中更新过的普通文件。如果不加-type f参数，则搜索普通文件+特殊文件+目录</span><br><span class="line">find ./ -name &#x27;*.csv&#x27; -maxdepth 1 #至查找当前目录，不递归</span><br></pre></td></tr></table></figure><h4 id="locate"><a href="#locate" class="headerlink" title="locate"></a>locate</h4><h3 id="检索关键字"><a href="#检索关键字" class="headerlink" title="检索关键字"></a>检索关键字</h3><p>指定文件类型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grep -rn --include=&#x27;*.后缀名&#x27; &quot;检索词&quot;</span><br><span class="line">例如：</span><br><span class="line">grep -rn --include=&#x27;*.sh&#x27; &quot;kill command&quot;</span><br></pre></td></tr></table></figure><h3 id="比较两个文件夹内容"><a href="#比较两个文件夹内容" class="headerlink" title="比较两个文件夹内容"></a>比较两个文件夹内容</h3><p><a href="https://www.tecmint.com/compare-find-difference-between-two-directories-in-linux/">https://www.tecmint.com/compare-find-difference-between-two-directories-in-linux/</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ diff [OPTION]… FILES</span><br><span class="line">$ diff options dir1 dir2 </span><br><span class="line"></span><br><span class="line"># 非递归，只对比当前文件内容</span><br><span class="line">$ diff -q directory-1/ directory-2/</span><br><span class="line"></span><br><span class="line"># 递归对比</span><br><span class="line">$ diff -qr directory-1/ directory-2/ </span><br><span class="line"></span><br><span class="line"># 比较两文件指定段落内容</span><br><span class="line">vimdiff &lt;(sed -n &#x27;7088,7122p&#x27; /user/vinyuan/a.txt) &lt;(sed -n &#x27;9022,9043p&#x27; /user/vinyuan/b.txt)</span><br></pre></td></tr></table></figure><h3 id="文件名称替换"><a href="#文件名称替换" class="headerlink" title="文件名称替换"></a>文件名称替换</h3><p><a href="https://www.cnblogs.com/xiaomai333/p/9760304.html">https://www.cnblogs.com/xiaomai333/p/9760304.html</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; var=person.jpg</span><br><span class="line"><span class="comment">#想替换成person_large.jpg</span></span><br><span class="line">&gt;&gt; var=<span class="variable">$&#123;var%.*&#125;</span>_large.<span class="variable">$&#123;var##*.&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$var</span></span><br><span class="line">&gt;&gt; person_large.jpg</span><br><span class="line"><span class="comment"># $&#123;var##*.&#125;</span></span><br><span class="line"><span class="comment"># $&#123;var#*.&#125;</span></span><br><span class="line"><span class="comment"># $&#123;var%.*&#125;</span></span><br><span class="line"><span class="comment"># $&#123;var%%.*&#125;</span></span><br></pre></td></tr></table></figure><p>其实<code>$&#123;&#125;</code>并不是专门为提取文件名或目录名的，它的使用是变量的提取和替换等等操作，它可以提取非常多的内容，并不一定是上面五个例子中的’/‘或’.’。也就是说，上面的使用方法只是它使用的一个特例。<br><strong>记忆方式：</strong><br>查看键盘布局，<code>#</code>在<script type="math/tex">`的左边，`%`在`</script>的右边</p><h3 id="字符串删除指定部分"><a href="#字符串删除指定部分" class="headerlink" title="字符串删除指定部分"></a>字符串删除指定部分</h3><p>[Substring Removal][1]<br>两种方式都是删除<strong>匹配到的字符串</strong>，对于符号右边的通配符匹配，只要匹配到，<strong>则删除匹配到的部分，留下其他部分</strong></p><h4 id="1-”-“号的使用"><a href="#1-”-“号的使用" class="headerlink" title="1.”#“号的使用"></a>1.”#“号的使用</h4><p><code>$&#123;string#substring&#125;</code><br>Deletes shortest match of <code>$substring</code> from front of <code>$string</code>.<br><code>$&#123;string##substring&#125;</code><br>Deletes longest match of <code>$substring</code> from front of <code>$string</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">stringZ=abcABC123ABCabc</span><br><span class="line">#       |----|          shortest</span><br><span class="line">#       |----------|    longest</span><br><span class="line">echo $&#123;stringZ#a*C&#125;      # 123ABCabc</span><br><span class="line"># Strip out shortest match between &#x27;a&#x27; and &#x27;C&#x27;.</span><br><span class="line"></span><br><span class="line">echo $&#123;stringZ##a*C&#125;     # abc</span><br><span class="line"># Strip out longest match between &#x27;a&#x27; and &#x27;C&#x27;.</span><br><span class="line"></span><br><span class="line"># You can parameterize the substrings.</span><br><span class="line">X=&#x27;a*C&#x27;</span><br><span class="line">echo $&#123;stringZ#$X&#125;      # 123ABCabc</span><br><span class="line">echo $&#123;stringZ##$X&#125;     # abc</span><br><span class="line">                        # As above</span><br></pre></td></tr></table></figure><h3 id="数值计算与判断"><a href="#数值计算与判断" class="headerlink" title="数值计算与判断"></a>数值计算与判断</h3><p>循环是根据奇偶性做出不同处理，switch flag</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># HOW TO FIND A NUMBER IS EVEN OR ODD IN SHELL SCRIPT</span><br><span class="line"># WRITTEN BY SURAJ MAITY</span><br><span class="line"># TUTORIALSINHAND.COM</span><br><span class="line">clear </span><br><span class="line">echo &quot;---- EVEN OR ODD IN SHELL SCRIPT -----&quot;</span><br><span class="line">echo -n &quot;Enter a number:&quot;</span><br><span class="line">read n</span><br><span class="line">echo -n &quot;RESULT: &quot;</span><br><span class="line">if [ `expr $n % 2` == 0 ]</span><br><span class="line">then</span><br><span class="line"> echo &quot;$n is even&quot;</span><br><span class="line">else</span><br><span class="line"> echo &quot;$n is Odd&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h4 id="2-”-”号的使用"><a href="#2-”-”号的使用" class="headerlink" title="2.”%”号的使用"></a>2.”%”号的使用</h4><p><code>$&#123;string%substring&#125;</code><br>Deletes shortest match of <code>$substring</code> from back of <code>$string</code>.<br><code>string%%substring&#125;</code><br>Deletes longest match of <code>$substring</code> from back of <code>$string</code>.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">stringZ=abcABC123ABCabc</span><br><span class="line">#                    ||     shortest</span><br><span class="line">#        |------------|     longest</span><br><span class="line"></span><br><span class="line">echo $&#123;stringZ%b*c&#125;      # abcABC123ABCa</span><br><span class="line"># Strip out shortest match between &#x27;b&#x27; and &#x27;c&#x27;, from back of $stringZ.</span><br><span class="line"></span><br><span class="line">echo $&#123;stringZ%%b*c&#125;     # a</span><br><span class="line"># Strip out longest match between &#x27;b&#x27; and &#x27;c&#x27;, from back of $stringZ.</span><br></pre></td></tr></table></figure><h4 id="3-删除中间匹配的字符串"><a href="#3-删除中间匹配的字符串" class="headerlink" title="3.删除中间匹配的字符串"></a>3.删除中间匹配的字符串</h4><p>这种需求可以使用替换来完成<br>替换</p><div class="table-container"><table><thead><tr><th>pattern</th><th>explain</th></tr></thead><tbody><tr><td><code>$&#123;string/substring/replacement&#125;</code></td><td>使用<code>$replacement</code>, 来代替第一个匹配的<code>$substring</code></td></tr><tr><td><code>$&#123;string//substring/replacement&#125;</code></td><td>使用<code>$replacement</code>, 代替所有匹配的<code>$substring</code></td></tr><tr><td><code>$&#123;string/#substring/replacement&#125;</code></td><td>如果<code>$string</code>的前缀匹配<code>$substring</code>, 那么就用<code>$replacement</code>来代替匹配到的<code>$substring</code></td></tr><tr><td><code>$&#123;string/%substring/replacement&#125;</code></td><td>如果<code>$string</code>的后缀匹配<code>$substring</code>, 那么就用<code>$replacement</code>来代替匹配到的<code>$substring</code></td></tr></tbody></table></div><h3 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h3><p><a href="https://www.cnblogs.com/zhangzongjian/p/10708222.html">https://www.cnblogs.com/zhangzongjian/p/10708222.html</a></p><h4 id="先检索指定位置，然后替换（非全局替换）"><a href="#先检索指定位置，然后替换（非全局替换）" class="headerlink" title="先检索指定位置，然后替换（非全局替换）"></a>先检索指定位置，然后替换（非全局替换）</h4><p><a href="https://www.golinuxhub.com/2017/09/sed-perform-search-and-replace-only-on/">https://www.golinuxhub.com/2017/09/sed-perform-search-and-replace-only-on/</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; cat /tmp/file</span><br><span class="line">four five six</span><br><span class="line">one</span><br><span class="line">seve eight nine</span><br><span class="line">one two three</span><br><span class="line">one</span><br><span class="line">ten eleven twelve</span><br><span class="line">one</span><br><span class="line"></span><br><span class="line">&gt;&gt; sed -e &#x27;/two/s/one/replaced/g&#x27; /tmp/file</span><br><span class="line">four five six</span><br><span class="line">one</span><br><span class="line">seve eight nine</span><br><span class="line">replaced two three</span><br><span class="line">one</span><br><span class="line">ten eleven twelve</span><br><span class="line">one</span><br></pre></td></tr></table></figure><p>sed -e ’command-1’ -e ‘command-2’ -e ‘command-3’ file.txt<br>sed -e 用来执行一系列操作，例如多个替换：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -e &#x27;/seve/s/nine/replaced/g&#x27; -e &#x27;/two/s/one/replaced/g&#x27; /tmp/file</span><br></pre></td></tr></table></figure><p>sed -i -e xxxx 在执行多个的同时<strong>本地替换</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -i -e &quot;/validation_data_path/s#recpro#yuanwenwu3#g&quot; -e &quot;/output_path/s#recpro#yuanwenwu3#g&quot; -e &quot;/summary_path/s#recpro#yuanwenwu3#g&quot; $&#123;conf_path&#125;</span><br><span class="line">sed -i -e &quot;/conf_file/s#conf_file=.*#conf_file=&#x27;$&#123;conf&#125;&#x27;#g&quot; -e &quot;s#&#x27;node&#x27;:.*,#&#x27;node&#x27;:&#x27;$&#123;node&#125;&#x27;,#g&quot; tfconf.py</span><br></pre></td></tr></table></figure><h4 id="匹配并选择部分替换"><a href="#匹配并选择部分替换" class="headerlink" title="匹配并选择部分替换"></a>匹配并选择部分替换</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sed -i &quot;s#\(statPath=\).*#\1$&#123;statPath&#125;#g&quot; $&#123;conf_dir&#125;/stat.conf</span><br><span class="line">sed -i &quot;s#\(output=\).*#\1$&#123;output&#125;#g;s#\(statPath=\).*#\1$&#123;statPath&#125;#g&quot; $&#123;conf_dir&#125;/train.conf</span><br><span class="line">#sed -i &quot;s#\(output=\).*#\1$&#123;output&#125;#g;s#\(statPath=\).*#\1$&#123;statPath&#125;#g;&quot; $&#123;conf_dir&#125;/train_id2i</span><br></pre></td></tr></table></figure><h4 id="带变量的替换"><a href="#带变量的替换" class="headerlink" title="带变量的替换"></a>带变量的替换</h4><p>如果有<strong>shell变量</strong>，则需要使用<strong>双引号</strong>即可,如果使用单引号则不会替换shell变量，而将<code>$&#123;var&#125;</code>视为一个字符串</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var=&quot;hello&quot;</span><br><span class="line">sed -n &quot;s/$[var&#125;/word/g&quot; xxx.dat</span><br><span class="line">#sed -n &#x27;s/$&#123;var&#125;/wor/g&#x27; xxx.dat 不会得到预期结果</span><br></pre></td></tr></table></figure><h4 id="一般用法"><a href="#一般用法" class="headerlink" title="一般用法"></a>一般用法</h4><p>参考: <a href="http://bbs.linuxtone.org/thread-1731-1-1.html">http://bbs.linuxtone.org/thread-1731-1-1.html</a></p><ol><li>当前行进行替换:<code>s/XXX/YYY/g</code><br>XXX是需要替换的字符串,YYY是替换后的字符串。</li><li>全局替换:<code>% s/XXX/YYY/g</code>.</li><li>对指定部分进行替换用V进入visual模式,再进行:<code>s/XXX/YYY/g</code>. <font color="green">ps(命令模式，显示的<code>:&#39;&lt;,&#39;&gt;</code>的是区域选择的意思，不要删除，紧接着在后面用<code>s/xxx/yyy/g</code>即可)</font></li></ol><p>比如，要将目录/modules下面所有文件中的zhangsan都修改成lisi，这样做：<br>sed -i “s/zhangsan/lisi/g” <code>grep zhangsan -rl /modules</code></p><p>解释一下：</p><p>-i 表示inplace edit，就地修改文件<br>-r 表示搜索子目录<br>-l 表示输出匹配的文件名</p><p>这个命令组合很强大，要注意备份文件。</p><ol><li>字典映射</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed &#x27;y/1234567890/ABCDEFGHIJ/&#x27; test_sed</span><br><span class="line">sed &#x27;y/1234567890/ABCDEFGHIJ/&#x27; filename</span><br></pre></td></tr></table></figure><p>ABCDEFGHIJ<br>BCDEFGHIJA<br>CDEFGHIJAB<br>DEFGHIJABC<br>注意变换关系是按两个list的位置对应变换<br>其中：test_sed的内容是：<br>1234567890<br>2345678901<br>3456789012<br>4567890123</p><ol><li>替换每行所有匹配<br><code>sed &#39;s/01/Ab/g&#39; test_sed</code><br>1234567890<br>23456789Ab<br>3456789Ab2<br>456789Ab23<br>注意：第一行的0，1没有分别替换为A,b</li></ol><h4 id="删除：d命令"><a href="#删除：d命令" class="headerlink" title="删除：d命令"></a>删除：d命令</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sed &#x27;2d&#x27; example          #删除example文件的第二行。</span><br><span class="line">sed &#x27;2,$d&#x27; example        #删除example文件的第二行到末尾所有行。</span><br><span class="line">sed &#x27;$d&#x27; example          #删除example文件的最后一行。</span><br><span class="line">sed &#x27;/test/&#x27;d example     #匹配&#x27;test&#x27;并删除 </span><br></pre></td></tr></table></figure><p>example——-删除example文件所有包含test的行。</p><p>替换：s命令<br><code>$ sed &#39;s/test/mytest/g&#39; example</code>——-在整行范围内把test替换为mytest。如果没有g标记，则只有每行第一个匹配的test被替换成mytest。<br><code>$ sed -n &#39;s/^test/mytest/p&#39; example</code>——-(-n)选项和p标志一起使用表示只打印那些发生替换的行。也就是说，如果某一行开头的test被替换成mytest，就打印它。<br><code>$ sed &#39;s/^192.168.0.1/&amp;localhost/&#39;example</code>——-&amp;符号表示替换换字符串中被找到的部份。所有以192.168.0.1开头的行都会被替换成它自已加localhost，变成192.168.0.1localhost。<br><code>$ sed -n &#39;s/\(love\)able/\1rs/p&#39; example</code>——-love被标记为1，所有loveable会被替换成lovers，而且替换的行会被打印出来。<br><code>$ sed &#39;s#10#100#g&#39; example</code>——-不论什么字符，紧跟着s命令的都被认为是新的分隔符，所以，“#”在这里是分隔符，代替了默认的“/”分隔符。表示把所有10替换成100。</p><p>选定行的范围：逗号<br><code>$ sed -n &#39;/test/,/check/p&#39; example</code>——-所有在模板test和check所确定的范围内的行都被打印。<br><code>$ sed -n &#39;5,/^test/p&#39; example</code>——-打印从第五行开始到第一个包含以test开始的行之间的所有行。<br><code>$ sed &#39;/test/,/check/s/$/sed test/&#39; example</code>——-对于模板test和west之间的行，每行的末尾用字符串sed test替换。</p><p>多点编辑：e命令<br><code>$ sed -e &#39;1,5d&#39; -e &#39;s/test/check/&#39;example</code>——-(-e)选项允许在同一行里执行多条命令。如例子所示，第一条命令删除1至5行，第二条命令用check替换test。命令的执行顺序对结果有影响。如果两个命令都是替换命令，那么第一个替换命令将影响第二个替换命令的结果。<br><code>$ sed --expression=&#39;s/test/check/&#39; --expression=&#39;/love/d&#39; example</code>——-一个比-e更好的命令是—expression。它能给sed表达式赋值。</p><p>从文件读入：r命令<br><code>$ sed &#39;/test/r file&#39; example</code>——-file里的内容被读进来，显示在与test匹配的行后面，如果匹配多行，则file的内容将显示在所有匹配行的下面。</p><p>写入文件：w命令<br><code>$ sed -n &#39;/test/w file&#39; example</code>——-在example中所有包含test的行都被写入file里。</p><p>追加命令：a命令<br><code>$ sed &#39;/^test/a\\---&gt;this is a example&#39; example</code>&lt;——-‘this is a example’被追加到以test开头的行后面，sed要求命令a后面有一个反斜杠。</p><p>插入：i命令<br><code>$ sed &#39;/test/i\\ new line -------------------------&#39; example</code><br>如果test被匹配，则把反斜杠后面的文本插入到匹配行的前面。<br>下一个：n命令<br><code>$ sed &#39;/test/&#123; n; s/aa/bb/; &#125;&#39; example</code>——-如果test被匹配，则移动到匹配行的下一行，替换这一行的aa，变为bb，并打印该行，然后继续。</p><p>变形：y命令<br><code>$ sed &#39;1,10y/abcde/ABCDE/&#39; example</code>——-把1—10行内所有abcde转变为大写，注意，正则表达式元字符不能使用这个命令。</p><p>退出：q命令<br><code>$ sed &#39;10q&#39; example</code>——-打印完第10行后，退出sed。</p><p>保持和获取：h命令和G命令<br><code>$ sed -e &#39;/test/h&#39; -e</code><br>example——-在sed处理文件的时候，每一行都被保存在一个叫模式空间的临时缓冲区中，除非行被删除或者输出被取消，否则所有被处理的行都将打印在屏幕上。接着模式空间被清空，并存入新的一行等待处理。在这个例子里，匹配test的行被找到后，将存入模式空间，h命令将其复制并存入一个称为保持缓存区的特殊缓冲区内。第二条语句的意思是，当到达最后一行后，G命令取出保持缓冲区的行，然后把它放回模式空间中，且追加到现在已经存在于模式空间中的行的末尾。在这个例子中就是追加到最后一行。简单来说，任何包含test的行都被复制并追加到该文件的末尾。</p><p>保持和互换：h命令和x命令<br><code>$ sed -e &#39;/test/h&#39; -e &#39;/check/x&#39; example</code> ——-互换模式空间和保持缓冲区的内容。也就是把包含test与check的行互换。</p><p>7.脚本</p><p>Sed脚本是一个sed的命令清单，启动Sed时以-f选项引导脚本文件名。Sed对于脚本中输入的命令非常挑剔，在命令的末尾不能有任何空白或文本，如果在一行中有多个命令，要用分号分隔。以#开头的行为注释行，且不能跨行。</p><p>8.小技巧<br>在sed的命令行中引用shell变量时要使用双引号，而不是通常所用的单引号。下面是一个根据name变量的内容来删除named.conf文件中zone段的脚本：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name=&#x27;zone\ &quot;localhost&quot;&#x27;</span><br><span class="line">sed &quot;/$name/,/&#125;;/d&quot; named.conf</span><br><span class="line">sed -i &quot;s/oldstring/newstring/g&quot; `grep oldstring -rl yourdir`</span><br></pre></td></tr></table></figure><p>例如：替换/home下所有文件中的www.itbbs.cn为chinafar.com</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &quot;s/www.itbbs.cn/chinafar.com/g&quot; `grep www.itbbs.cn -rl /home` </span><br></pre></td></tr></table></figure><h2 id="vim-amp-vi"><a href="#vim-amp-vi" class="headerlink" title="vim &amp; vi"></a>vim &amp; vi</h2><h3 id="自己使用的简单配置template"><a href="#自己使用的简单配置template" class="headerlink" title="自己使用的简单配置template"></a>自己使用的简单配置template</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># ~/.vimrc</span><br><span class="line">hi CursorLine   cterm=NONE ctermbg=lightgray ctermfg=white guibg=lightgray guifg=white</span><br><span class="line">hi CursorLine term=bold cterm=bold ctermbg=237</span><br><span class="line">hi CursorColumn   cterm=NONE ctermbg=lightgray ctermfg=white guibg=lightgray guifg=white</span><br><span class="line">hi CursorColumn term=bold cterm=bold ctermbg=237</span><br><span class="line"></span><br><span class="line">set ts=4</span><br><span class="line">set expandtab</span><br><span class="line"></span><br><span class="line">set smartindent</span><br><span class="line">set tabstop=4</span><br><span class="line">set shiftwidth=4</span><br><span class="line">set expandtab</span><br><span class="line">set softtabstop=4</span><br><span class="line"></span><br><span class="line"># https://www.dyxmq.cn/linux/vim-setting-mouse-place.html</span><br><span class="line"># 设置vim打开上次编辑地方</span><br><span class="line">au BufReadPost * if line(&quot;&#x27;\&quot;&quot;) &gt; 0 | if line(&quot;&#x27;\&quot;&quot;) &lt;= line(&quot;$&quot;) | exe(&quot;norm &#x27;\&quot;&quot;) | else |exe &quot;norm $&quot;| endif | endif</span><br></pre></td></tr></table></figure><h3 id="多功能templete"><a href="#多功能templete" class="headerlink" title="多功能templete"></a>多功能templete</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br></pre></td><td class="code"><pre><span class="line">&quot;=========================================================================</span><br><span class="line">&quot; DesCRiption: 适合自己使用的vimrc文件，for Linux/Windows, GUI/Console</span><br><span class="line">&quot;</span><br><span class="line">&quot; Last Change: 2010年08月02日 15时13分</span><br><span class="line">&quot;</span><br><span class="line">&quot; Version:     1.80</span><br><span class="line">&quot;</span><br><span class="line">&quot;=========================================================================</span><br><span class="line"></span><br><span class="line">set nocompatible            &quot; 关闭 vi 兼容模式</span><br><span class="line">syntax on                   &quot; 自动语法高亮</span><br><span class="line">&quot;colorscheme molokai         &quot; 设定配色方案</span><br><span class="line">set number                  &quot; 显示行号</span><br><span class="line">set noswapfile                          &quot; 不产生.swap, .swo文件</span><br><span class="line">&quot;set cursorline              &quot; 突出显示当前行</span><br><span class="line">set ruler                   &quot; 打开状态栏标尺</span><br><span class="line">set shiftwidth=4            &quot; 设定 &lt;&lt; 和 &gt;&gt; 命令移动时的宽度为 4</span><br><span class="line">set softtabstop=4           &quot; 使得按退格键时可以一次删掉 4 个空格</span><br><span class="line">set tabstop=4               &quot; 设定 tab 长度为 4</span><br><span class="line">set nobackup                &quot; 覆盖文件时不备份</span><br><span class="line">&quot;set autochdir               &quot; 自动切换当前目录为当前文件所在的目录</span><br><span class="line">filetype plugin indent on   &quot; 开启插件</span><br><span class="line">set backupcopy=yes          &quot; 设置备份时的行为为覆盖</span><br><span class="line">set ignorecase smartcase    &quot; 搜索时忽略大小写，但在有一个或以上大写字母时仍保持对大小写敏感</span><br><span class="line">&quot;set nowrapscan              &quot; 禁止在搜索到文件两端时重新搜索</span><br><span class="line">set incsearch               &quot; 输入搜索内容时就显示搜索结果</span><br><span class="line">set hlsearch                &quot; 搜索时高亮显示被找到的文本</span><br><span class="line">set noerrorbells            &quot; 关闭错误信息响铃</span><br><span class="line">set novisualbell            &quot; 关闭使用可视响铃代替呼叫</span><br><span class="line">set t_vb=                   &quot; 置空错误铃声的终端代码</span><br><span class="line">&quot; set showmatch               &quot; 插入括号时，短暂地跳转到匹配的对应括号</span><br><span class="line">&quot; set matchtime=2             &quot; 短暂跳转到匹配括号的时间</span><br><span class="line">set magic                   &quot; 设置魔术</span><br><span class="line">set hidden                  &quot; 允许在有未保存的修改时切换缓冲区，此时的修改由 vim 负责保存</span><br><span class="line">set guioptions-=T           &quot; 隐藏工具栏</span><br><span class="line">set guioptions-=m           &quot; 隐藏菜单栏</span><br><span class="line">set smartindent             &quot; 开启新行时使用智能自动缩进</span><br><span class="line">set backspace=indent,eol,start</span><br><span class="line">                            &quot; 不设定在插入状态无法用退格键和 Delete 键删除回车符</span><br><span class="line">set cmdheight=1             &quot; 设定命令行的行数为 1</span><br><span class="line">set laststatus=2            &quot; 显示状态栏 (默认值为 1, 无法显示状态栏)</span><br><span class="line">set statusline=\ %&lt;%F[%1*%M%*%n%R%H]%=\ %y\ %0(%&#123;&amp;fileformat&#125;\ %&#123;&amp;encoding&#125;\ %c:%l/%L%)\</span><br><span class="line">                            &quot; 设置在状态行显示的信息</span><br><span class="line">&quot;set foldenable              &quot; 开始折叠</span><br><span class="line">&quot;set foldmethod=syntax       &quot; 设置语法折叠</span><br><span class="line">&quot;set foldcolumn=0            &quot; 设置折叠区域的宽度</span><br><span class="line">&quot;setlocal foldlevel=0        &quot; 设置折叠层数为</span><br><span class="line">&quot;set foldclose=all           &quot; 设置为自动关闭折叠</span><br><span class="line">&quot; nnoremap &lt;space&gt; @=((foldclosed(line(&#x27;.&#x27;)) &lt; 0) ? &#x27;zc&#x27; : &#x27;zo&#x27;)&lt;CR&gt;</span><br><span class="line">                            &quot; 用空格键来开关折叠</span><br><span class="line">au BufReadPost * if line(&quot;&#x27;\&quot;&quot;) &gt; 0 | if line(&quot;&#x27;\&quot;&quot;) &lt;= line(&quot;$&quot;) | exe(&quot;norm &#x27;\&quot;&quot;) | else |exe &quot;norm $&quot;| endif | endif</span><br><span class="line">hi CursorLine   cterm=NONE ctermbg=lightgray ctermfg=white guibg=lightgray guifg=white</span><br><span class="line">hi CursorLine term=bold cterm=bold ctermbg=237</span><br><span class="line">hi CursorColumn   cterm=NONE ctermbg=lightgray ctermfg=white guibg=lightgray guifg=white</span><br><span class="line">hi CursorColumn term=bold cterm=bold ctermbg=237</span><br><span class="line"></span><br><span class="line">&quot; return OS type, eg: windows, or linux, mac, et.st..</span><br><span class="line">function! MySys()</span><br><span class="line">    if has(&quot;win16&quot;) || has(&quot;win32&quot;) || has(&quot;win64&quot;) || has(&quot;win95&quot;)</span><br><span class="line">        return &quot;windows&quot;</span><br><span class="line">    elseif has(&quot;unix&quot;)</span><br><span class="line">        return &quot;linux&quot;</span><br><span class="line">    endif</span><br><span class="line">endfunction</span><br><span class="line"></span><br><span class="line">&quot; 用户目录变量$VIMFILES</span><br><span class="line">if MySys() == &quot;windows&quot;</span><br><span class="line">    let $VIMFILES = $VIM.&#x27;/vimfiles&#x27;</span><br><span class="line">elseif MySys() == &quot;linux&quot;</span><br><span class="line">    let $VIMFILES = $HOME.&#x27;/.vim&#x27;</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">&quot; 设定doc文档目录</span><br><span class="line">let helptags=$VIMFILES.&#x27;/doc&#x27;</span><br><span class="line"></span><br><span class="line">&quot; 设置字体 以及中文支持</span><br><span class="line">if has(&quot;win32&quot;)</span><br><span class="line">    set guifont=Inconsolata:h12:cANSI</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">&quot; 配置多语言环境</span><br><span class="line">if has(&quot;multi_byte&quot;)</span><br><span class="line">    &quot; UTF-8 编码</span><br><span class="line">    set encoding=utf-8</span><br><span class="line">    set termencoding=utf-8</span><br><span class="line">    set formatoptions+=mM</span><br><span class="line">    set fencs=utf-8,gbk</span><br><span class="line"></span><br><span class="line">    if v:lang =~? &#x27;^\(zh\)\|\(ja\)\|\(ko\)&#x27;</span><br><span class="line">        set ambiwidth=double</span><br><span class="line">    endif</span><br><span class="line"></span><br><span class="line">    if has(&quot;win32&quot;)</span><br><span class="line">        source $VIMRUNTIME/delmenu.vim</span><br><span class="line">        source $VIMRUNTIME/menu.vim</span><br><span class="line">        language messages zh_CN.utf-8</span><br><span class="line">    endif</span><br><span class="line">else</span><br><span class="line">    echoerr &quot;Sorry, this version of (g)vim was not compiled with +multi_byte&quot;</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">&quot; Buffers操作快捷方式!</span><br><span class="line">nnoremap &lt;C-RETURN&gt; :bnext&lt;CR&gt;</span><br><span class="line">nnoremap &lt;C-S-RETURN&gt; :bprevious&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot; Tab操作快捷方式!</span><br><span class="line">nnoremap &lt;C-TAB&gt; :tabnext&lt;CR&gt;</span><br><span class="line">nnoremap &lt;C-S-TAB&gt; :tabprev&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot;关于tab的快捷键</span><br><span class="line">&quot; map tn :tabnext&lt;cr&gt;</span><br><span class="line">&quot; map tp :tabprevious&lt;cr&gt;</span><br><span class="line">&quot; map td :tabnew .&lt;cr&gt;</span><br><span class="line">&quot; map te :tabedit</span><br><span class="line">&quot; map tc :tabclose&lt;cr&gt;</span><br><span class="line"></span><br><span class="line">&quot;窗口分割时,进行切换的按键热键需要连接两次,比如从下方窗口移动</span><br><span class="line">&quot;光标到上方窗口,需要&lt;c-w&gt;&lt;c-w&gt;k,非常麻烦,现在重映射为&lt;c-k&gt;,切换的</span><br><span class="line">&quot;时候会变得非常方便.</span><br><span class="line">nnoremap &lt;C-h&gt; &lt;C-w&gt;h</span><br><span class="line">nnoremap &lt;C-j&gt; &lt;C-w&gt;j</span><br><span class="line">nnoremap &lt;C-k&gt; &lt;C-w&gt;k</span><br><span class="line">nnoremap &lt;C-l&gt; &lt;C-w&gt;l</span><br><span class="line"></span><br><span class="line">&quot;一些不错的映射转换语法（如果在一个文件中混合了不同语言时有用）</span><br><span class="line">nnoremap &lt;leader&gt;1 :set filetype=xhtml&lt;CR&gt;</span><br><span class="line">nnoremap &lt;leader&gt;2 :set filetype=css&lt;CR&gt;</span><br><span class="line">nnoremap &lt;leader&gt;3 :set filetype=javascript&lt;CR&gt;</span><br><span class="line">nnoremap &lt;leader&gt;4 :set filetype=php&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot; set fileformats=unix,dos,mac</span><br><span class="line">&quot; nmap &lt;leader&gt;fd :se fileformat=dos&lt;CR&gt;</span><br><span class="line">&quot; nmap &lt;leader&gt;fu :se fileformat=unix&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot; use Ctrl+[l|n|p|cc] to list|next|previous|jump to count the result</span><br><span class="line">&quot; map &lt;C-x&gt;l &lt;ESC&gt;:cl&lt;CR&gt;</span><br><span class="line">&quot; map &lt;C-x&gt;n &lt;ESC&gt;:cn&lt;CR&gt;</span><br><span class="line">&quot; map &lt;C-x&gt;p &lt;ESC&gt;:cp&lt;CR&gt;</span><br><span class="line">&quot; map &lt;C-x&gt;c &lt;ESC&gt;:cc&lt;CR&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot; 让 Tohtml 产生有 CSS 语法的 html</span><br><span class="line">&quot; syntax/2html.vim，可以用:runtime! syntax/2html.vim</span><br><span class="line">let html_use_css=1</span><br><span class="line"></span><br><span class="line">&quot; Python 文件的一般设置，比如不要 tab 等</span><br><span class="line">autocmd FileType python set tabstop=4 shiftwidth=4 expandtab</span><br><span class="line">autocmd FileType python map &lt;F12&gt; :!python %&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot; 选中状态下 Ctrl+c 复制</span><br><span class="line">vmap &lt;C-c&gt; &quot;+y</span><br><span class="line"></span><br><span class="line">&quot; 打开javascript折叠</span><br><span class="line">let b:javascript_fold=1</span><br><span class="line">&quot; 打开javascript对dom、html和css的支持</span><br><span class="line">let javascript_enable_domhtmlcss=1</span><br><span class="line">&quot; 设置字典 ~/.vim/dict/文件的路径</span><br><span class="line">autocmd filetype javascript set dictionary=$VIMFILES/dict/javascript.dict</span><br><span class="line">autocmd filetype css set dictionary=$VIMFILES/dict/css.dict</span><br><span class="line">autocmd filetype php set dictionary=$VIMFILES/dict/php.dict</span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin - bufexplorer.vim Buffers切换</span><br><span class="line">&quot; \be 全屏方式查看全部打开的文件列表</span><br><span class="line">&quot; \bv 左右方式查看   \bs 上下方式查看</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin - taglist.vim  查看函数列表，需要ctags程序</span><br><span class="line">&quot; F4 打开隐藏taglist窗口</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">if MySys() == &quot;windows&quot;                &quot; 设定windows系统中ctags程序的位置</span><br><span class="line">    let Tlist_Ctags_Cmd = &#x27;&quot;&#x27;.$VIMRUNTIME.&#x27;/ctags.exe&quot;&#x27;</span><br><span class="line">elseif MySys() == &quot;linux&quot;              &quot; 设定windows系统中ctags程序的位置</span><br><span class="line">    let Tlist_Ctags_Cmd = &#x27;/usr/bin/ctags&#x27;</span><br><span class="line">endif</span><br><span class="line">nnoremap &lt;silent&gt;&lt;F4&gt; :TlistToggle&lt;CR&gt;</span><br><span class="line">let Tlist_Show_One_File = 1            &quot; 不同时显示多个文件的tag，只显示当前文件的</span><br><span class="line">let Tlist_Exit_OnlyWindow = 1          &quot; 如果taglist窗口是最后一个窗口，则退出vim</span><br><span class="line">let Tlist_Use_Right_Window = 1         &quot; 在右侧窗口中显示taglist窗口</span><br><span class="line">let Tlist_File_Fold_Auto_Close=1       &quot; 自动折叠当前非编辑文件的方法列表</span><br><span class="line">let Tlist_Auto_Open = 0</span><br><span class="line">let Tlist_Auto_Update = 1</span><br><span class="line">let Tlist_Hightlight_Tag_On_BufEnter = 1</span><br><span class="line">let Tlist_Enable_Fold_Column = 0</span><br><span class="line">let Tlist_Process_File_Always = 1</span><br><span class="line">let Tlist_Display_Prototype = 0</span><br><span class="line">let Tlist_Compact_Format = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin - mark.vim 给各种tags标记不同的颜色，便于观看调式的插件。</span><br><span class="line">&quot; \m  mark or unmark the word under (or before) the cursor</span><br><span class="line">&quot; \r  manually input a regular expression. 用于搜索.</span><br><span class="line">&quot; \n  clear this mark (i.e. the mark under the cursor), or clear all highlighted marks .</span><br><span class="line">&quot; \*  当前MarkWord的下一个     \#  当前MarkWord的上一个</span><br><span class="line">&quot; \/  所有MarkWords的下一个    \?  所有MarkWords的上一个</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin - NERD_tree.vim 以树状方式浏览系统中的文件和目录</span><br><span class="line">&quot; :ERDtree 打开NERD_tree         :NERDtreeClose    关闭NERD_tree</span><br><span class="line">&quot; o 打开关闭文件或者目录         t 在标签页中打开</span><br><span class="line">&quot; T 在后台标签页中打开           ! 执行此文件</span><br><span class="line">&quot; p 到上层目录                   P 到根目录</span><br><span class="line">&quot; K 到第一个节点                 J 到最后一个节点</span><br><span class="line">&quot; u 打开上层目录                 m 显示文件系统菜单（添加、删除、移动操作）</span><br><span class="line">&quot; r 递归刷新当前目录             R 递归刷新当前根目录</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; F3 NERDTree 切换</span><br><span class="line">map &lt;F3&gt; :NERDTreeToggle&lt;CR&gt;</span><br><span class="line">imap &lt;F3&gt; &lt;ESC&gt;:NERDTreeToggle&lt;CR&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin - NERD_commenter.vim   注释代码用的，</span><br><span class="line">&quot; [count],cc 光标以下count行逐行添加注释(7,cc)</span><br><span class="line">&quot; [count],cu 光标以下count行逐行取消注释(7,cu)</span><br><span class="line">&quot; [count],cm 光标以下count行尝试添加块注释(7,cm)</span><br><span class="line">&quot; ,cA 在行尾插入 /* */,并且进入插入模式。 这个命令方便写注释。</span><br><span class="line">&quot; 注：count参数可选，无则默认为选中行或当前行</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">let NERDSpaceDelims=1       &quot; 让注释符与语句之间留一个空格</span><br><span class="line">let NERDCompactSexyComs=1   &quot; 多行注释时样子更好看</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin - DoxygenToolkit.vim  由注释生成文档，并且能够快速生成函数标准注释</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">let g:DoxygenToolkit_authorName=&quot;Asins - asinsimple AT gmail DOT com&quot;</span><br><span class="line">let g:DoxygenToolkit_briefTag_funcName=&quot;yes&quot;</span><br><span class="line">map &lt;leader&gt;da :DoxAuthor&lt;CR&gt;</span><br><span class="line">map &lt;leader&gt;df :Dox&lt;CR&gt;</span><br><span class="line">map &lt;leader&gt;db :DoxBlock&lt;CR&gt;</span><br><span class="line">map &lt;leader&gt;dc a /*  */&lt;LEFT&gt;&lt;LEFT&gt;&lt;LEFT&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin – ZenCoding.vim 很酷的插件，HTML代码生成</span><br><span class="line">&quot; 插件最新版：http://github.com/mattn/zencoding-vim</span><br><span class="line">&quot; 常用命令可看：http://nootn.com/blog/Tool/23/</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin – checksyntax.vim    JavaScript常见语法错误检查</span><br><span class="line">&quot; 默认快捷方式为 F5</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">let g:checksyntax_auto = 0 &quot; 不自动检查</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin - NeoComplCache.vim    自动补全插件</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">let g:AutoComplPop_NotEnableAtStartup = 1</span><br><span class="line">let g:NeoComplCache_EnableAtStartup = 1</span><br><span class="line">let g:NeoComplCache_SmartCase = 1</span><br><span class="line">let g:NeoComplCache_TagsAutoUpdate = 1</span><br><span class="line">let g:NeoComplCache_EnableInfo = 1</span><br><span class="line">let g:NeoComplCache_EnableCamelCaseCompletion = 1</span><br><span class="line">let g:NeoComplCache_MinSyntaxLength = 3</span><br><span class="line">let g:NeoComplCache_EnableSkipCompletion = 1</span><br><span class="line">let g:NeoComplCache_SkipInputTime = &#x27;0.5&#x27;</span><br><span class="line">let g:NeoComplCache_SnippetsDir = $VIMFILES.&#x27;/snippets&#x27;</span><br><span class="line">&quot; &lt;TAB&gt; completion.</span><br><span class="line">inoremap &lt;expr&gt;&lt;TAB&gt; pumvisible() ? &quot;\&lt;C-n&gt;&quot; : &quot;\&lt;TAB&gt;&quot;</span><br><span class="line">&quot; snippets expand key</span><br><span class="line">imap &lt;silent&gt; &lt;C-e&gt; &lt;Plug&gt;(neocomplcache_snippets_expand)</span><br><span class="line">&quot;smap &lt;silent&gt; &lt;C-e&gt; &lt;Plug&gt;(neocomplcache_snippets_expand)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin - matchit.vim   对%命令进行扩展使得能在嵌套标签和语句之间跳转</span><br><span class="line">&quot; % 正向匹配      g% 反向匹配</span><br><span class="line">&quot; [% 定位块首     ]% 定位块尾</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin - vcscommand.vim   对%命令进行扩展使得能在嵌套标签和语句之间跳转</span><br><span class="line">&quot; SVN/git管理工具</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">&quot; plugin – a.vim</span><br><span class="line">&quot;-----------------------------------------------------------------</span><br><span class="line">imap &lt;F9&gt; &lt;esc&gt;:tabN&lt;cr&gt;</span><br><span class="line">imap &lt;F10&gt; &lt;esc&gt;:tabn&lt;cr&gt;</span><br><span class="line">nmap &lt;F9&gt; :tabN&lt;cr&gt;</span><br><span class="line">nmap &lt;F10&gt; :tabn&lt;cr&gt;</span><br><span class="line">&quot;set showtabline=1</span><br><span class="line">hi Comment ctermfg=2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">highlight Visual cterm=bold ctermbg=Blue ctermfg=NONE #visual 选中高亮的底色变成浅色</span><br></pre></td></tr></table></figure><h3 id="Vimdiff"><a href="#Vimdiff" class="headerlink" title="Vimdiff"></a>Vimdiff</h3><p>更改对比颜色</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:colo desert</span><br></pre></td></tr></table></figure><h3 id="vi语法高亮shell脚本"><a href="#vi语法高亮shell脚本" class="headerlink" title="vi语法高亮shell脚本"></a>vi语法高亮shell脚本</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># ~/.vimrc</span><br><span class="line">filetype plugin indent on</span><br><span class="line">syntax on</span><br></pre></td></tr></table></figure><h3 id="vim-amp-vi-配置"><a href="#vim-amp-vi-配置" class="headerlink" title="vim &amp; vi 配置"></a>vim &amp; vi 配置</h3><p><a href="https://www.dazhuanlan.com/2019/10/02/5d94884599d6c/">https://www.dazhuanlan.com/2019/10/02/5d94884599d6c/</a></p><p>在vimrc中加入:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hi CursorLine term=bold cterm=bold ctermbg=Red</span><br><span class="line"># 在vi中使用</span><br><span class="line">set cursorline</span><br><span class="line">or</span><br><span class="line">set cul</span><br></pre></td></tr></table></figure><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 高亮显示搜索匹配的词</span><br><span class="line">:set hlsearch    </span><br><span class="line"></span><br><span class="line"># 每输入一个字符，搜索一次，表现是同时高亮多个正则匹配</span><br><span class="line"># 在普通搜索前执行此命令</span><br><span class="line">:set incsearch</span><br><span class="line"></span><br><span class="line"># 忽略大小写</span><br><span class="line">:set ignorecase   </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>查找当前光标所在单词:<br>* 向下查找全部匹配的字符串（按住shift+*键），同时左下角会显示等效的命令模式指令<br># 向上查找全部匹配的字符（按住shift+#键），同时左下角会显示等效的命令模式指令<br>g* 向下查找包含当前字符的匹配字符串（按住shift+*键），同时左下角会显示等效的命令模式指令<br>g# 向上查找包含当前字符的匹配字符串（按住shift+#键），同时左下角会显示等效的命令模式指令<br>\% 括号匹配 包括 () [] { }.</p><h3 id="全部替换"><a href="#全部替换" class="headerlink" title="全部替换"></a>全部替换</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">:[addr]s/源字符串/目标字符串/[option]</span><br><span class="line"># 全局替换</span><br><span class="line">:%s/源字符串/目标字符串/g</span><br><span class="line"></span><br><span class="line"># 全部替换和添加确认环节</span><br><span class="line">:%s/search_for_this/replace_with_this/    - search whole file and replace</span><br><span class="line">:%s/search_for_this/replace_with_this/c   - confirm each replace</span><br></pre></td></tr></table></figure><h3 id="cursor颜色"><a href="#cursor颜色" class="headerlink" title="cursor颜色"></a>cursor颜色</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">set cursorline</span><br><span class="line">hi CursorLine   cterm=NONE ctermbg=lightgray ctermfg=white guibg=lightgray guifg=white</span><br><span class="line">set cursorcolumn</span><br><span class="line">hi CursorColumn   cterm=NONE ctermbg=lightgray ctermfg=white guibg=lightgray guifg=white</span><br><span class="line"># 设置更浅的灰色</span><br><span class="line">hi CursorLine term=bold cterm=bold ctermbg=237</span><br></pre></td></tr></table></figure><h3 id="空格替换tab"><a href="#空格替换tab" class="headerlink" title="空格替换tab"></a>空格替换tab</h3><p><a href="https://blog.csdn.net/jiang1013nan/article/details/6298727">https://blog.csdn.net/jiang1013nan/article/details/6298727</a><br>在.vimrc中添加以下代码后，重启vim即可实现按TAB产生4个空格：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#~/.vimrc</span><br><span class="line">set ts=4  (注：ts是tabstop的缩写，设TAB宽4个空格)</span><br><span class="line">set expandtab</span><br></pre></td></tr></table></figure><p>对于已保存的文件，可以使用下面的方法进行空格和TAB的替换：<br>TAB替换为空格：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">:set ts=4</span><br><span class="line">:set expandtab</span><br><span class="line">:%retab!</span><br></pre></td></tr></table></figure><p>空格替换为TAB：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">:set ts=4</span><br><span class="line">:set noexpandtab</span><br><span class="line">:%retab!</span><br></pre></td></tr></table></figure><h2 id="后台运行"><a href="#后台运行" class="headerlink" title="后台运行"></a>后台运行</h2><p>单纯的后天运行直接似使用<br>参考：[link][2]</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">command &amp; #后台运行</span><br><span class="line">ctrl + z #将一个正在前台执行的命令放到后台，并且暂停</span><br><span class="line">jobs -l</span><br><span class="line">fg %1 #前台显示</span><br><span class="line">bg %1 #将任务后台运行，比如cltr+z后会挂起任务，并显示任务号，此时就可以用这个命令让其后台运行</span><br></pre></td></tr></table></figure><h3 id="nohup"><a href="#nohup" class="headerlink" title="nohup"></a><a href="https://www.cnblogs.com/jinxiao-pu/p/9131057.html">nohup</a></h3><p>nohup 命令运行由 Command参数和任何相关的 Arg参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （ 表示“and”的符号）到命令的尾部。</p><p><strong>nohup 是 no hang up 的缩写，就是不挂断的意思。</strong></p><h3 id="nohup和-amp-的区别"><a href="#nohup和-amp-的区别" class="headerlink" title="nohup和 &amp; 的区别"></a><a href="https://www.cnblogs.com/jinxiao-pu/p/9131057.html">nohup和 &amp; 的区别</a></h3><p>&amp; ： 指在后台运行<br>nohup ： 不挂断的运行，注意并没有后台运行的功能，，就是指，用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系，例如我们断开SSH连接都不会影响他的运行，注意了nohup没有后台运行的意思；&amp;才是后台运行</p><h3 id="获得nohup后台运行进程的PID"><a href="#获得nohup后台运行进程的PID" class="headerlink" title="获得nohup后台运行进程的PID"></a><a href="https://www.jianshu.com/p/5a04e2452e3f">获得nohup后台运行进程的PID</a></h3><p>nohup command &gt; logfile.txt &amp; echo $! &gt; pidfile.txt<br>其实也可以在command.sh里面写入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo current pid = $$</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>变量名</th><th>含义</th></tr></thead><tbody><tr><td>$$</td><td>Shell本身的PID（ProcessID）</td></tr><tr><td>$!</td><td>Shell最后运行的后台Process的PID</td></tr><tr><td>$?</td><td>最后运行的命令的结束代码（返回值）</td></tr><tr><td>$-</td><td>使用Set命令设定的Flag一览</td></tr><tr><td>$*</td><td>所有参数列表。如”$*”用「”」括起来的情况、以”$1 $2 …$n”的形式输出所有参数。</td></tr><tr><td>$@</td><td>所有参数列表。如”$@”用「”」括起来的情况、以”$1” “$2” … “$n” 的形式输出所有参数。</td></tr><tr><td>$#</td><td>添加到Shell的参数个数</td></tr><tr><td>$0</td><td>Shell本身的文件名</td></tr><tr><td>$1-$n</td><td>添加到Shell的各参数值。$1是第1参数、$2是第2参数…。</td></tr></tbody></table></div><h3 id="2-gt-amp-1解析"><a href="#2-gt-amp-1解析" class="headerlink" title="2&gt;&amp;1解析"></a><a href="https://www.cnblogs.com/zzyoucan/p/7764590.html">2&gt;&amp;1解析</a></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmmand &gt;out.file 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><ul><li>command&gt;out.file是将command的输出重定向到out.file文件，即输出内容不打印到屏幕上，而是输出到out.file文件中。</li><li>2&gt;&amp;1 是将标准出错重定向到标准输出，这里的标准输出已经重定向到了out.file文件，即将标准出错也输出到out.file文件中。最后一个&amp;， 是让该命令在后台执行。</li><li>试想2&gt;1代表什么，2与&gt;结合代表错误重定向，而1则代表错误重定向到一个文件1，而不代表标准输出；换成2&gt;&amp;1，&amp;与1结合就代表标准输出了，就变成错误重定向到标准输出.</li></ul><h3 id="查看后台任务或进程"><a href="#查看后台任务或进程" class="headerlink" title="查看后台任务或进程"></a><a href="https://www.cnblogs.com/baby123/p/6477429.html">查看后台任务或进程</a></h3><ul><li>jobs -l<br>jobs命令只看当前终端生效的，关闭终端后，在另一个终端jobs已经无法看到后台跑得程序了，此时利用ps（进程查看命令）</li><li>ps -ef</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s -aux|grep chat.js</span><br><span class="line"> a:显示所有程序 </span><br><span class="line"> u:以用户为主的格式来显示 </span><br><span class="line"> x:显示所有程序，不以终端机来区分</span><br></pre></td></tr></table></figure><h3 id="wait-命令-获取上一个后台进程的进程号以及状态"><a href="#wait-命令-获取上一个后台进程的进程号以及状态" class="headerlink" title="wait 命令+获取上一个后台进程的进程号以及状态"></a>wait 命令+获取上一个后台进程的进程号以及状态</h3><p><code>wait_test.sh</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">echo &quot;current job pid: &quot; $$</span><br><span class="line"></span><br><span class="line">bash wait_error_job.sh 1 &amp;</span><br><span class="line">job_1=$!</span><br><span class="line">bash wait_error_job.sh 2 &amp;</span><br><span class="line">job_2=$!</span><br><span class="line"></span><br><span class="line">wait $job_1   </span><br><span class="line">job_1_status=$?</span><br><span class="line">wait $job_2</span><br><span class="line">job_2_status=$?</span><br><span class="line"></span><br><span class="line">echo &quot;job 1 pid: &quot; $&#123;job_1&#125; &quot; status: &quot; $&#123;job_1_status&#125;</span><br><span class="line">echo &quot;job 2 pid: &quot; $&#123;job_2&#125; &quot; status: &quot; $&#123;job_2_status&#125;</span><br></pre></td></tr></table></figure><p><code>wait_error_job.sh</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">echo &quot;I am job: &quot; $1 &quot;my pid is: &quot; $$</span><br><span class="line">sleep 5 </span><br><span class="line">if [ $1 -eq 1 ];then</span><br><span class="line">    echo &quot;this is job 1, success&quot;</span><br><span class="line">else</span><br><span class="line">    echo &quot;this is job 2, failed&quot;</span><br><span class="line">    lls # 拼写错误的命令，用来报错</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="disown"><a href="#disown" class="headerlink" title="disown"></a>disown</h3><p>场景：<a href="http://www.ibm.com/developerworks/cn/linux/l-cn-nohup/">http://www.ibm.com/developerworks/cn/linux/l-cn-nohup/</a><br>我们已经知道，如果事先在命令前加上 nohup 或者 setsid 就可以避免 HUP 信号的影响。但是如果我们未加任何处理就已经提交了命令，该如何补救才能让它避免 HUP 信号的影响呢？<br>解决方法：<br>这时想加 nohup 或者 setsid 已经为时已晚，只能通过作业调度和 disown 来解决这个问题了。让我们来看一下 disown 的帮助信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">disown [-ar] [-h] [jobspec ...]</span><br><span class="line"> Without options, each jobspec is  removed  from  the  table  of</span><br><span class="line"> active  jobs.   If  the -h option is given, each jobspec is not</span><br><span class="line"> removed from the table, but is marked so  that  SIGHUP  is  not</span><br><span class="line"> sent  to the job if the shell receives a SIGHUP.  If no jobspec</span><br><span class="line"> is present, and neither the -a nor the -r option  is  supplied,</span><br><span class="line"> the  current  job  is  used.  If no jobspec is supplied, the -a</span><br><span class="line"> option means to remove or mark all jobs; the -r option  without</span><br><span class="line"> a  jobspec  argument  restricts operation to running jobs.  The</span><br><span class="line"> return value is 0 unless a jobspec does  not  specify  a  valid</span><br><span class="line"> job.</span><br></pre></td></tr></table></figure><p>可以看出，我们可以用如下方式来达成我们的目的。<br>灵活运用 CTRL-z<br>在我们的日常工作中，我们可以用 CTRL-z 来将当前进程挂起到后台暂停运行，执行一些别的操作，然后再用 fg 来将挂起的进程重新放回前台（也可用 bg 来将挂起的进程放在后台）继续运行。这样我们就可以在一个终端内灵活切换运行多个任务，这一点在调试代码时尤为有用。因为将代码编辑器挂起到后台再重新放回时，光标定位仍然停留在上次挂起时的位置，避免了重新定位的麻烦。<br>用disown -h jobspec来使某个作业忽略HUP信号。<br>用disown -ah 来使所有的作业都忽略HUP信号。<br>用disown -rh 来使正在运行的作业忽略HUP信号。<br>需要注意的是，当使用过 disown 之后，会将把目标作业从作业列表中移除，我们将不能再使用jobs来查看它，但是依然能够用ps -ef查找到它。<br>但是还有一个问题，这种方法的操作对象是作业，如果我们在运行命令时在结尾加了”&amp;”来使它成为一个作业并在后台运行，那么就万事大吉了，我们可以通过jobs命令来得到所有作业的列表。但是如果并没有把当前命令作为作业来运行，如何才能得到它的作业号呢？答案就是用 CTRL-z（按住Ctrl键的同时按住z键）了！<br>CTRL-z 的用途就是将当前进程挂起（Suspend），然后我们就可以用jobs命令来查询它的作业号，再用bg jobspec来将它放入后台并继续运行。需要注意的是，如果挂起会影响当前进程的运行结果，请慎用此方法。<br>disown 示例1（如果提交命令时已经用“&amp;”将命令放入后台运行，则可以直接使用“disown”）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@pvcent107 build]# cp -r testLargeFile largeFile &amp;</span><br><span class="line">[1] 4825</span><br><span class="line">[root@pvcent107 build]# jobs</span><br><span class="line">[1]+  Running                 cp -i -r testLargeFile largeFile &amp;</span><br><span class="line">[root@pvcent107 build]# disown -h %1</span><br><span class="line">[root@pvcent107 build]# ps -ef |grep largeFile</span><br><span class="line">root      4825   968  1 09:46 pts/4    00:00:00 cp -i -r testLargeFile largeFile</span><br><span class="line">root      4853   968  0 09:46 pts/4    00:00:00 grep largeFile</span><br><span class="line">[root@pvcent107 build]# logout</span><br></pre></td></tr></table></figure><p>disown 示例2（如果提交命令时未使用“&amp;”将命令放入后台运行，可使用 CTRL-z 和“bg”将其放入后台，再使用“disown”）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@pvcent107 build]# cp -r testLargeFile largeFile2</span><br><span class="line"></span><br><span class="line">[1]+  Stopped                 cp -i -r testLargeFile largeFile2</span><br><span class="line">[root@pvcent107 build]# bg %1</span><br><span class="line">[1]+ cp -i -r testLargeFile largeFile2 &amp;</span><br><span class="line">[root@pvcent107 build]# jobs</span><br><span class="line">[1]+  Running                 cp -i -r testLargeFile largeFile2 &amp;</span><br><span class="line">[root@pvcent107 build]# disown -h %1</span><br><span class="line">[root@pvcent107 build]# ps -ef |grep largeFile2</span><br><span class="line">root      5790  5577  1 10:04 pts/3    00:00:00 cp -i -r testLargeFile largeFile2</span><br><span class="line">root      5824  5577  0 10:05 pts/3    00:00:00 grep largeFile2</span><br><span class="line">[root@pvcent107 build]#</span><br></pre></td></tr></table></figure><h3 id="screen"><a href="#screen" class="headerlink" title="screen"></a>screen</h3><p>用screen -dmS session name来建立一个处于断开模式下的会话（并指定其会话名）。<br>用screen -list 来列出所有会话。<br>用screen -r session name来重新连接指定会话。<br>用快捷键CTRL-a d 来暂时断开当前会话。<br>screen 示例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@pvcent107 ~]# screen -dmS Urumchi</span><br><span class="line">[root@pvcent107 ~]# screen -list</span><br><span class="line">There is a screen on:</span><br><span class="line">        12842.Urumchi   (Detached)</span><br><span class="line">1 Socket in /tmp/screens/S-root.</span><br><span class="line"></span><br><span class="line">[root@pvcent107 ~]# screen -r Urumchi</span><br></pre></td></tr></table></figure><p>1.未使用 screen 时新进程的进程树</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@pvcent107 ~]# ping www.google.com &amp;</span><br><span class="line">[1] 9499</span><br><span class="line">[root@pvcent107 ~]# pstree -H 9499</span><br><span class="line">init─┬─Xvnc</span><br><span class="line">     ├─acpid</span><br><span class="line">     ├─atd</span><br><span class="line">     ├─2*[sendmail] </span><br><span class="line">     ├─sshd─┬─sshd───bash───pstree</span><br><span class="line">     │       └─sshd───bash───ping</span><br><span class="line">我们可以看出，未使用 screen 时我们所处的 bash 是 sshd 的子进程，当 ssh 断开连接时，HUP 信号自然会影响到它下面的所有子进程（包括我们新建立的 ping 进程）。</span><br></pre></td></tr></table></figure><p>2.使用了 screen 后新进程的进程树</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@pvcent107 ~]# screen -r Urumchi</span><br><span class="line">[root@pvcent107 ~]# ping www.ibm.com &amp;</span><br><span class="line">[1] 9488</span><br><span class="line">[root@pvcent107 ~]# pstree -H 9488</span><br><span class="line">init─┬─Xvnc</span><br><span class="line">     ├─acpid</span><br><span class="line">     ├─atd</span><br><span class="line">     ├─screen───bash───ping</span><br><span class="line">     ├─2*[sendmail]</span><br></pre></td></tr></table></figure><p>而使用了 screen 后就不同了，此时 bash 是 screen 的子进程，而 screen 是 init（PID为1）的子进程。那么当 ssh 断开连接时，HUP 信号自然不会影响到 screen 下面的子进程了。</p><h2 id="TOP-命令"><a href="#TOP-命令" class="headerlink" title="TOP 命令"></a>TOP 命令</h2><p><a href="https://www.binarytides.com/linux-top-command/">https://www.binarytides.com/linux-top-command/</a><br><a href="https://www.zhihu.com/question/378345922/answer/1069674567">https://www.zhihu.com/question/378345922/answer/1069674567</a></p><h2 id="批量下载图片"><a href="#批量下载图片" class="headerlink" title="批量下载图片"></a>批量下载图片</h2><p><a href="https://www.jb51.net/article/122242.htm">参考代码</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="keyword">while</span> 循环读取文件，文件放在 <span class="keyword">done</span> 后面</span></span><br><span class="line">while read line;</span><br><span class="line">do</span><br><span class="line">    #echo &quot;read line&quot; $i &quot;:&quot; $line | tee -a $log_file</span><br><span class="line">    let &quot;i=$i+1&quot;</span><br><span class="line">    arr=($line)</span><br><span class="line">    rnd=$(rand 0 6)</span><br><span class="line">    curl_cmd=&quot;curl -o $&#123;img_dir&#125;$&#123;arr[0]&#125;.jpg $&#123;host[$rnd]&#125;$&#123;arr[1]&#125;&quot;</span><br><span class="line">    echo $curl_cmd</span><br><span class="line">    eval &quot;$curl_cmd &quot;</span><br><span class="line">done &lt; $sku_info</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="随机数"><a href="#随机数" class="headerlink" title="随机数"></a>随机数</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">function rand()&#123;</span><br><span class="line">    min=$1</span><br><span class="line">    max=$(($2-$min+1))</span><br><span class="line">    num=$(cat /proc/sys/kernel/random/uuid | cksum | awk -F &#x27; &#x27; &#x27;&#123;print $1&#125;&#x27;)</span><br><span class="line">    echo $(($num%$max+$min))</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用方法</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt; rnd=$(rand 0 10) <span class="comment">#0-10内的整数</span></span></span><br></pre></td></tr></table></figure><h3 id="随机筛选数据"><a href="#随机筛选数据" class="headerlink" title="随机筛选数据"></a>随机筛选数据</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shuf dataset.dat -n 20 -o dataset_sample.dat</span><br></pre></td></tr></table></figure><h2 id="判断文件是否存在"><a href="#判断文件是否存在" class="headerlink" title="判断文件是否存在"></a>判断文件是否存在</h2><p><a href="https://www.jb51.net/article/122242.htm">参考文件</a></p><h3 id="1-文件夹不存在则创建"><a href="#1-文件夹不存在则创建" class="headerlink" title="1.文件夹不存在则创建"></a>1.文件夹不存在则创建</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if [ ! -d &quot;/data/&quot; ];then</span><br><span class="line">mkdir /data</span><br><span class="line">else</span><br><span class="line">echo &quot;文件夹已经存在&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="2-文件存在则删除"><a href="#2-文件存在则删除" class="headerlink" title="2.文件存在则删除"></a>2.文件存在则删除</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if [ ! -f &quot;/data/filename&quot; ];then</span><br><span class="line">echo &quot;文件不存在&quot;</span><br><span class="line">else</span><br><span class="line">rm -f /data/filename</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="3-判断文件夹是否存在"><a href="#3-判断文件夹是否存在" class="headerlink" title="3.判断文件夹是否存在"></a>3.判断文件夹是否存在</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if [ -d &quot;/data/&quot; ];then</span><br><span class="line">echo &quot;文件夹存在&quot;</span><br><span class="line">else</span><br><span class="line">echo &quot;文件夹不存在&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="4-判断文件是否存在"><a href="#4-判断文件是否存在" class="headerlink" title="4.判断文件是否存在"></a>4.判断文件是否存在</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if [ -f &quot;/data/filename&quot; ];then</span><br><span class="line">echo &quot;文件存在&quot;</span><br><span class="line">else</span><br><span class="line">echo &quot;文件不存在&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h2 id="日期处理"><a href="#日期处理" class="headerlink" title="日期处理"></a>日期处理</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">n 天后的日期 yyyy-mm-dd</span></span><br><span class="line">n_days_later=`date --date &quot;$&#123;cur_day&#125; n day&quot; +%Y-%m-%d`</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">n 天前的日期</span> </span><br><span class="line">n_days_ago=`date --date &quot;$&#123;cur_day&#125; n day ago&quot; +%Y-%m-%d`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 获取时间戳，用以比较大小</span></span></span><br><span class="line">today_t=`date -d &quot;$&#123;today&#125;&quot; +%s`</span><br><span class="line">tomorrow_t=`date -d &quot;$&#123;tomorrow&#125;&quot; +%s`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 循环一段时间 yyyy-mm-dd</span></span></span><br><span class="line">start_day=2019-09-08</span><br><span class="line">end_day=2019-09-17</span><br><span class="line">dt=$&#123;start_day&#125; </span><br><span class="line">while [ &quot;$&#123;dt&#125;&quot; != &quot;$&#123;end_day&#125;&quot; ];do</span><br><span class="line">    echo &quot;-------------统计日期: $&#123;dt&#125;----------------&quot;</span><br><span class="line">    predt=$(date -I -d &quot;$&#123;dt&#125; - 1 day&quot;)</span><br><span class="line">    dt=$(date -I -d &quot;$&#123;dt&#125; + 1 day&quot;)</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="条件语句-if-while）"><a href="#条件语句-if-while）" class="headerlink" title="条件语句(if,while）"></a>条件语句(if,while）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># while 条件语句</span></span></span><br><span class="line">while [ $&#123;today_t&#125; -le $&#123;tomorrow&#125; ];</span><br><span class="line">do</span><br><span class="line">    # do sth</span><br><span class="line">done</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># if 条件语句</span></span></span><br><span class="line">if [ $&#123;today_t&#125; -le $&#123;tomorrow_t&#125; ];</span><br><span class="line">then</span><br><span class="line">    #do sth</span><br><span class="line">    else</span><br><span class="line">    #do otherthing</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="if-条件判断大括号，中括号，圆括号"><a href="#if-条件判断大括号，中括号，圆括号" class="headerlink" title="if 条件判断大括号，中括号，圆括号"></a>if 条件判断大括号，中括号，圆括号</h3><p><a href="https://www.jianshu.com/p/3e1eaaa3fee8">https://www.jianshu.com/p/3e1eaaa3fee8</a></p><h3 id="判断文件、文件夹是否存在"><a href="#判断文件、文件夹是否存在" class="headerlink" title="判断文件、文件夹是否存在"></a>判断文件、文件夹是否存在</h3><p><a href="https://www.cnblogs.com/emanlee/p/3583769.html">https://www.cnblogs.com/emanlee/p/3583769.html</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if [ ! -d &quot;$folder&quot;]; then</span><br><span class="line">  mkdir &quot;$folder&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="判断变量是否为空"><a href="#判断变量是否为空" class="headerlink" title="判断变量是否为空"></a>判断变量是否为空</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 1.判断变量</span><br><span class="line">if [ ! -n &quot;$var&quot; ];then ...</span><br><span class="line"># 2.判断输入参数</span><br><span class="line">if [ ! -n &quot;$1&quot; ];then ...</span><br><span class="line"># 3.直接变量判断</span><br><span class="line">if [ ! $var ];then ...</span><br><span class="line"># 4.使用test判断</span><br><span class="line">if test -z &quot;$var&quot; then ...</span><br><span class="line"># 5.使用&quot;&quot;判断</span><br><span class="line">if [ &quot;$var&quot; == &quot;&quot; ] then ...</span><br></pre></td></tr></table></figure><p>2.</p><p>3.</p><h2 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h2><h3 id="查找文件"><a href="#查找文件" class="headerlink" title="查找文件"></a>查找文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#find 搜索目录 -name 目标名字</span><br><span class="line">#eg.</span><br><span class="line">find / -name filename  # /代表是全盘搜索,也可以指定目录搜索</span><br><span class="line"> </span><br><span class="line">##find 搜索文件的命令格式：</span><br><span class="line">##find [搜索范围] [匹配条件]</span><br><span class="line">#选项：</span><br><span class="line">#    -name  根据名字查找（精确查找）</span><br><span class="line">#    -iname 根据文件名查找，但是不区分大小写</span><br><span class="line">#    -size  根据文件大小查找, +,-:大于设置的大小,直接写大小是等于</span><br><span class="line">#    -user  查找用户名的所有者的所有文件</span><br><span class="line">#    -group 根据所属组查找相关文件</span><br><span class="line">#    -type  根据文件类型查找(f文件,d目录,l软链接文件)</span><br><span class="line">#    -inum  根据i节点查找</span><br><span class="line">#    -amin  访问时间access</span><br><span class="line">#    -cmin  文件属性change</span><br><span class="line">#    -mmin  文件内容modify</span><br><span class="line">#example    </span><br><span class="line">find /etc -iname &quot;*.sh&quot;</span><br><span class="line">find /etc -iname &quot;*.service&quot; 2&gt; /dev/null</span><br></pre></td></tr></table></figure><h2 id="重定向与文件操作符"><a href="#重定向与文件操作符" class="headerlink" title="重定向与文件操作符"></a>重定向与文件操作符</h2><p><a href="https://www.zhihu.com/question/53295083/answer/135258024">https://www.zhihu.com/question/53295083/answer/135258024</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 分开写</span><br><span class="line">cmd 2&gt;stderr.txt 1&gt;stdout.txt</span><br><span class="line"># 写入一个文件</span><br><span class="line">cmd &gt; output.txt 2&gt;&amp;1</span><br><span class="line">cmd &amp;&gt; output.txt</span><br><span class="line">cmd &gt;&amp; output.txt  # 两个表达式效果一样哒~</span><br></pre></td></tr></table></figure><p><a href="https://zhuanlan.zhihu.com/p/58419951">https://zhuanlan.zhihu.com/p/58419951</a><br>find /etc -iname “*.service” 2&gt;&amp;1 1&gt;services.txt<br>这是因为 Bash 从左到右处理 find 的每个结果。这样想：当 Bash 到达 2&gt;&amp;1 时，stdout （1）仍然是指向终端的通道。如果 find 给 Bash 的结果包含一个错误，它将被弹出到 2，转移到 1，然后留在终端！</p><p>相比之下，在：<br>find /etc -iname “*.service” 1&gt;services.txt 2&gt;&amp;1<br>1 从一开始就指向 services.txt，因此任何弹出到 2 的内容都会导向到 1 ，而 1 已经指向最终去的位置 services.txt，这就是它工作的原因。</p><p>在任何情况下，如上所述 &amp;&gt; 都是“标准输出和标准错误”的缩写，即 2&gt;&amp;1。</p><h2 id="shell函数返回字符串参数"><a href="#shell函数返回字符串参数" class="headerlink" title="shell函数返回字符串参数"></a>shell函数返回字符串参数</h2><p><a href="https://roc-wong.github.io/blog/2017/03/shell-%E5%87%BD%E6%95%B0%E8%BF%94%E5%9B%9E%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%96%B9%E6%B3%95.html">参考博客</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">function</span> 关键字可以省略，<span class="built_in">return</span> value只能是整数，代表返回状态</span></span><br><span class="line">function function_name () &#123;</span><br><span class="line">    list of commands</span><br><span class="line">    [ return value ]</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">赋值方式</span></span><br><span class="line">function fun1()&#123;</span><br><span class="line">    res=`cmd xxxx`</span><br><span class="line">    echo $res</span><br><span class="line">&#125;</span><br><span class="line">res=`fun1`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">传参赋值方式</span></span><br><span class="line">function fun2()&#123;</span><br><span class="line">    tmp=`res`</span><br><span class="line">    eval &quot;$1=$res&quot;</span><br><span class="line">&#125;</span><br><span class="line">res=&quot;&quot;</span><br><span class="line">fun2 $res</span><br><span class="line">echo $res</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th>variable</th><th>含义</th></tr></thead><tbody><tr><td style="text-align:center">$0</td><td>脚本本身的名字；</td></tr><tr><td style="text-align:center">$#</td><td>传给脚本的参数个数；</td></tr><tr><td style="text-align:center">$@</td><td>传给脚本的所有参数的列表，即被扩展为”$1” “$2” “$3”等；</td></tr><tr><td style="text-align:center">$*</td><td>以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个即被扩展成”$1c$2c$3”，其中c是IFS的第一个字符；</td></tr><tr><td style="text-align:center">$$</td><td>是脚本运行的当前进程ID号；</td></tr><tr><td style="text-align:center">$?</td><td>是显示最后命令的退出状态，0表示没有错误，其他表示有错误；</td></tr><tr><td style="text-align:center">$n</td><td>获取参数的值，$1表示第一个参数，当n&gt;=10时，需要使用${n}来获取参数。</td></tr></tbody></table></div><h2 id="Shell-中-”-的区别"><a href="#Shell-中-”-的区别" class="headerlink" title="Shell 中 $(())”, $(), ``, ${} 的区别"></a>Shell 中 $(())”, $(), ``, ${} 的区别</h2><p>$()和``类似，对当中的表达式计算得出结果,<br>$(()) 计算数学表达式<br>参考：<a href="https://www.cnblogs.com/chengd/p/7803664.html">https://www.cnblogs.com/chengd/p/7803664.html</a><br>注意</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">file.txt</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">hello world</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">this is a <span class="built_in">test</span> file</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下面这种<span class="keyword">for</span>循环结果并不是按行显示，其实未按字符显示，主要原因是`<span class="built_in">cat</span> xxx`命令的到的结果是<span class="string">&quot;hello&#123;space&#125;world&#123;\n&#125;this&#123;sapce&#125;is……</span></span></span><br><span class="line">for line in `cat file.txt`</span><br><span class="line">do </span><br><span class="line">echo $line</span><br><span class="line">done;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">正确应该用如下方式</span></span></span><br><span class="line">while read line</span><br><span class="line">do</span><br><span class="line">echo $line</span><br><span class="line">done &lt; file.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="多个命令先后执行"><a href="#多个命令先后执行" class="headerlink" title="多个命令先后执行"></a>多个命令先后执行</h2><p>[在命令行中同时输入多个语句][3]：<br>直接在linux命令行中可以依次执行多个命令，多个命令间可采用“;”、“&amp;&amp;”和”||”分割，三个分隔符作用不同：<br>（1）;分割符：前后命令间没有必然的联系，前一个执行结束后、再执行第二个，没有逻辑关联；<br>（2）&amp;&amp;分隔符：前后命令有逻辑关联，后面的命令是否执行取决于前面的命令是否执行成功，前者执行成功，才会执行后面的命令。<br>（3）||分隔符：前后命令有逻辑关联，与&amp;&amp;相反，前面的命令执行失败后才能执行后面的命令。</p><p>  [3]: <a href="https://blog.csdn.net/cooperdoctor/article/details/84333686">https://blog.csdn.net/cooperdoctor/article/details/84333686</a>“</p><h2 id="selenium"><a href="#selenium" class="headerlink" title="selenium"></a>selenium</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> selenium</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">auto_check</span>():</span><br><span class="line"> </span><br><span class="line"> driverOptions = webdriver.ChromeOptions()</span><br><span class="line"> driverOptions.add_argument(<span class="string">r&quot;user-data-dir=C:\Users\yuanwenwu3\AppData\Local\Google\Chrome\User Data&quot;</span>)</span><br><span class="line"> driverOptions.add_argument(<span class="string">&quot;--log-level=3&quot;</span>)</span><br><span class="line"> driver = webdriver.Chrome(<span class="string">&quot;chromedriver&quot;</span>,<span class="number">0</span>,driverOptions)</span><br><span class="line"> </span><br><span class="line"> <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> ProfilesIni allProfiles = new ProfilesIni();</span></span><br><span class="line"><span class="string">    FirefoxProfile profile = allProfiles.getProfile(&quot;default&quot;); </span></span><br><span class="line"><span class="string">    WebDriever driver  = new FirefoxDriver(profile)</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="comment">#driver.get(&quot;http://erp.jd.com/portal/navMenu/subPage?menuId=50570&quot;)</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">#driver.find_element_by_css_selector(&quot;#subDiv &gt; div.aside &gt; div.jquery-accordion-menu.jdskin &gt; div &gt; ul &gt; li:nth-child(5) &gt; a&quot;).click()</span></span><br><span class="line"></span><br><span class="line"> driver.get(<span class="string">&quot;http://kaoqin.jd.com/&quot;</span>)</span><br><span class="line"></span><br><span class="line"> time.sleep(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"> <span class="keyword">try</span>:</span><br><span class="line">  driver.find_element_by_css_selector(<span class="string">&quot;body &gt; div &gt; div &gt; div &gt; div.login_pop_inner.login_withpc.eye-protector-processed &gt; form &gt; div.login_form_row.formsubmit &gt; input&quot;</span>).click()</span><br><span class="line">  driver.find_element_by_css_selector(<span class="string">&quot;#clockIn&quot;</span>).click()</span><br><span class="line"> <span class="keyword">except</span> selenium.common.exceptions.NoSuchElementException <span class="keyword">as</span> e:</span><br><span class="line">  driver.find_element_by_css_selector(<span class="string">&quot;#clockIn&quot;</span>).click()</span><br><span class="line"></span><br><span class="line"> time.sleep(<span class="number">3</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"> auto_check()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;数组&quot;&gt;&lt;a href=&quot;#数组&quot; class=&quot;headerlink&quot; title=&quot;数组&quot;&gt;&lt;/a&gt;数组&lt;/h2&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;# &lt;/span&gt;&lt;span class=&quot;language-bash&quot;&gt;创建数组(注意不需要逗号，以空格分隔)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;array=(1 2 3 4)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;language-bash&quot;&gt;获取所有元素&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;echo $&amp;#123;array[@]&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;language-bash&quot;&gt;获取第一个元素&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;echo $&amp;#123;array[0]&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;language-bash&quot;&gt;获取数组元素个数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;echo $&amp;#123;#array[@]&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;language-bash&quot;&gt;如果某个元素是字符串，还可以通过指定下标的方式获得该元素的长度，如下所示：&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;echo $&amp;#123;#array[2]&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta prompt_&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;language-bash&quot;&gt;因为字符串获取长度如下&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;str=&amp;quot;hello world&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;echo $&amp;#123;#str&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>linear-algebra</title>
    <link href="http://yoursite.com/2024/02/29/linear-algebra/"/>
    <id>http://yoursite.com/2024/02/29/linear-algebra/</id>
    <published>2024-02-29T09:24:28.000Z</published>
    <updated>2025-05-22T05:50:40.080Z</updated>
    
    <content type="html"><![CDATA[<p>在学习SVM时，遇到了dot product的问题，一时忘了在algebra下定义的向量内积和在geometry下定义的向量内积为何相等，查找了一下资料，发现很有趣，故记录如下。<br>This operation can be defined either algebraically or geometrically.</p><ul><li>Algebraically, it is the sum of the products of the corresponding entries of the two sequences of numbers.</li><li>Geometrically, it is the product of the Euclidean magnitudes of the two vectors and the cosine of the angle between them.</li></ul><h2 id="Algebraic-definition"><a href="#Algebraic-definition" class="headerlink" title="Algebraic definition"></a>Algebraic definition</h2><p>The dot product of two vectors A = [A1, A2, …, An] and B = [B1, B2, …, Bn] is defined as:</p><script type="math/tex; mode=display">\mathbf{A}\cdot \mathbf{B} = \sum_{i=1}^n A_iB_i = A_1B_1 + A_2B_2 + \cdots + A_nB_n</script><h2 id="Geometric-definition"><a href="#Geometric-definition" class="headerlink" title="Geometric definition"></a>Geometric definition</h2><p>In Euclidean space, a Euclidean vector is a geometrical object that possesses both a magnitude and a direction. A vector can be pictured as an arrow. Its magnitude is its length, and its direction is the direction that the arrow points. The magnitude of a vector A is denoted by $|\mathbf{A}|$.<br>The dot product of two Euclidean vectors A and B is defined by</p><script type="math/tex; mode=display">\mathbf{A}\cdot\mathbf{B} = |\mathbf{A}||\mathbf{B}|\cos\theta</script><p>where θ is the angle between A and B.</p><h2 id="Equivalence-of-the-definitions"><a href="#Equivalence-of-the-definitions" class="headerlink" title="Equivalence of the definitions"></a>Equivalence of the definitions</h2><p>If e1,…,en are the standard basis vectors in Rn, then we may write</p><script type="math/tex; mode=display">\begin{align}\mathbf A &= [A_1,\dots,A_n] = \sum_i A_i\mathbf e_i\\\mathbf B &= [B_1,\dots,B_n] = \sum_i B_i\mathbf e_i.\end{align}</script><p>The vectors $e_i$ are an orthonormal basis, which means that they have unit length and are at right angles to each other. Hence since these vectors have unit length<br>$\mathbf e_i\cdot\mathbf e_i=1$<br>and since they form right angles with each other, if $i ≠ j$,<br>$\mathbf e_i\cdot\mathbf e_j = 0.$<br>Also, by the geometric definition, for any vector ei and a vector A, we note<br>$\mathbf A\cdot\mathbf e_i = |\mathbf A|\,|\mathbf e_i|\cos\theta = |\mathbf A|\cos\theta = A_i$,<br>where Ai is the component of vector A in the direction of ei.<br>Now applying the distributivity of the geometric version of the dot product gives</p><script type="math/tex; mode=display">\mathbf A\cdot\mathbf B = \mathbf A\cdot\sum_i B_i\mathbf e_i = \sum_i B_i(\mathbf A\cdot\mathbf e_i) = \sum_i B_iA_i</script><p>which is precisely the algebraic definition of the dot product. So the (geometric) dot product equals the (algebraic) dot product.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在学习SVM时，遇到了dot product的问题，一时忘了在algebra下定义的向量内积和在geometry下定义的向量内积为何相等，查找了一下资料，发现很有趣，故记录如下。&lt;br&gt;This operation can be defined either algebra</summary>
      
    
    
    
    <category term="math" scheme="http://yoursite.com/categories/math/"/>
    
    
    <category term="math" scheme="http://yoursite.com/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>gitNote</title>
    <link href="http://yoursite.com/2024/02/20/gitNote/"/>
    <id>http://yoursite.com/2024/02/20/gitNote/</id>
    <published>2024-02-20T05:28:00.000Z</published>
    <updated>2025-05-22T05:50:40.064Z</updated>
    
    <content type="html"><![CDATA[<h2 id="新建（关联）远程分支"><a href="#新建（关联）远程分支" class="headerlink" title="新建（关联）远程分支"></a>新建（关联）远程分支</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### Git global setup</span></span><br><span class="line">git config --<span class="keyword">global</span> user.name <span class="string">&quot;yuanwenwu3&quot;</span></span><br><span class="line">git config --<span class="keyword">global</span> user.email <span class="string">&quot;yuanwenwu3@jd.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Create a new repository</span></span><br><span class="line"></span><br><span class="line">git clone git@git.jd.com:yuanwenwu3/draw_tensorboard.git</span><br><span class="line">cd draw_tensorboard</span><br><span class="line">touch README.md</span><br><span class="line">git add README.md</span><br><span class="line">git commit -m <span class="string">&quot;add README&quot;</span></span><br><span class="line">git push -u origin master</span><br><span class="line"></span><br><span class="line"><span class="comment">### Push an existing folder</span></span><br><span class="line">cd existing_folder</span><br><span class="line">git init</span><br><span class="line">git remote add origin git@git.jd.com:yuanwenwu3/draw_tensorboard.git</span><br><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">&quot;Initial commit&quot;</span></span><br><span class="line">git push -u origin master</span><br><span class="line"></span><br><span class="line"><span class="comment">### Push an existing Git repository</span></span><br><span class="line">cd existing_repo</span><br><span class="line">git remote rename origin old-origin</span><br><span class="line">git remote add origin git@git.jd.com:yuanwenwu3/draw_tensorboard.git</span><br><span class="line">git push -u origin --<span class="built_in">all</span></span><br><span class="line">git push -u origin --tags</span><br><span class="line"></span><br><span class="line"><span class="comment">### 迁移项目</span></span><br><span class="line"><span class="comment"># 新建一个空的repository, 例如地址为url-destination</span></span><br><span class="line"><span class="comment"># 在当前项目主分支上</span></span><br><span class="line">git remote add destination $&#123;url-destination&#125;</span><br><span class="line">git push -u origin --<span class="built_in">all</span></span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="已经commit的回退到add状态"><a href="#已经commit的回退到add状态" class="headerlink" title="已经commit的回退到add状态"></a>已经commit的回退到add状态</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --soft HEAD~<span class="number">1</span></span><br></pre></td></tr></table></figure><h2 id="最近一次修改了那些文件（列表形式展示"><a href="#最近一次修改了那些文件（列表形式展示" class="headerlink" title="最近一次修改了那些文件（列表形式展示)"></a>最近一次修改了那些文件（列表形式展示)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git diff --name-only HEAD^ HEAD</span><br><span class="line">git log --name-only <span class="comment">#修改的文件列表</span></span><br><span class="line">git log --stat <span class="comment">#修改的文件列表, 及文件修改的统计</span></span><br><span class="line">git log --name-status <span class="comment">#修改的文件列表, 显示状态</span></span><br></pre></td></tr></table></figure><h2 id="git-查看日志精简"><a href="#git-查看日志精简" class="headerlink" title="git 查看日志精简"></a>git 查看日志精简</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git log --pretty=oneline --author=<span class="string">&quot;vinyuan&quot;</span></span><br><span class="line"></span><br><span class="line">15f3e2fa840fa49d0a576eb5e3f63a295a0ea522 Merged PR <span class="number">1211</span>: fix shopping bpr large scale dag file</span><br><span class="line">c1a323928e399357c427ec507c3b6c7927e3f60f Merged PR <span class="number">1208</span>: shopping_bpr modify lookbackwindow</span><br><span class="line">945c30534c71fee996757a3fb730cc9f7ee3bf67 Merged PR <span class="number">1207</span>: shopping bpr fix scope timezone problem</span><br><span class="line">……</span><br></pre></td></tr></table></figure><h2 id="Git-补充commit"><a href="#Git-补充commit" class="headerlink" title="Git 补充commit"></a>Git 补充commit</h2><p><a href="https://blog.csdn.net/chilun8494/article/details/100645862">https://blog.csdn.net/chilun8494/article/details/100645862</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 第一次commit内容</span><br><span class="line">$ echo &#x27;Hello world&#x27; &gt; README.md</span><br><span class="line">$ git add .</span><br><span class="line">$ git commit -m &quot;Add README.md&quot;</span><br><span class="line">$ git log --oneline</span><br><span class="line">c56f680 Add README.md</span><br><span class="line"># 修改文件内容并合并到上一次的commit变更当中</span><br><span class="line">$ echo &#x27;Hello voidint&#x27; &gt;&gt; README.md</span><br><span class="line">$ git add .</span><br><span class="line">$ git commit --amend --no-edit</span><br><span class="line">$ git log --oneline</span><br><span class="line">eb6c8cb Add README.md // hash值发生了变化</span><br></pre></td></tr></table></figure><h2 id="ssh配置多个git账户"><a href="#ssh配置多个git账户" class="headerlink" title="ssh配置多个git账户"></a>ssh配置多个git账户</h2><p>情景：<a href="https://blog.csdn.net/onTheRoadToMine/article/details/79029331">【参考博客】</a><br>同一台机器有多个git账户的问题。在配置git权限时，需要配置ssh-keygen，会运行下面命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;vinyuan@microsoft.com&quot;</span></span><br></pre></td></tr></table></figure><p>命令会在<code>~/.ssh/</code>目录下生成两个文件: <code>id_rsa</code> 和 <code>id_rsa.pub</code>，然后将<code>id_rsa.pub</code>的内容复制到git或者gitLab中的<code>ssh setting</code>中即可。但如果有多个用户就会面临如下问题：每个用户都需要配置自己的ssh setting，生成一个私钥就会覆盖之前的 <code>id_rsa</code> 和<code>id_ras.pub</code>。如何避免？</p><p>答案是在 “~/.ssh/config” (如果没有可以建一个）中配置。<br>~/.ssh/config 的规则可以查看<a href="https://deepzz.com/post/how-to-setup-ssh-config.html">【参考链接】</a><br>常用的参数有如下几个：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Host example                       <span class="comment"># 关键词</span></span><br><span class="line">    HostName example.com           <span class="comment"># 主机地址</span></span><br><span class="line">    User root                      <span class="comment"># 用户名</span></span><br><span class="line">    IdentityFile ~/.ssh/id_ecdsa <span class="comment"># 认证文件</span></span><br><span class="line">    Port <span class="number">22</span>                      <span class="comment"># 指定端口</span></span><br></pre></td></tr></table></figure><p>~/.ssh/config 的作用可使你通过别名（即关键词）登录目标服务器，例如<code>ssh example</code>而不必 <code>ssh -p xxx admin@xxx.xxx.xxx.xxx</code><br>这个文件还可以用来管理多git用户。<br>以两个用户user1, user2为例，先后生成各自的公钥、密钥：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">**ssh-keygen -t rsa -C <span class="string">&quot;user1@hotmail.com&quot;</span>**</span><br><span class="line"> 填写密钥存放位置：例如<span class="string">&quot;~/.ssh/user1_id_rsa</span></span><br><span class="line"><span class="string"> ssh-keygen -t rsa -C &quot;</span>user2@gmail.com<span class="string">&quot;</span></span><br><span class="line"><span class="string"> 填写密钥存放位置：例如&quot;</span>~/.ssh/user2_id_rsa</span><br><span class="line"> 生成完成后会在~/.ssh/下出现四个文件</span><br><span class="line"> ls ~/.ssh/</span><br><span class="line">.</span><br><span class="line">├── user1_id_rsa</span><br><span class="line">├── user1_id_rsa.pub</span><br><span class="line">├── user2_id_rsa</span><br><span class="line">└── user2_id_rsa.pub</span><br></pre></td></tr></table></figure><p>之后可以在~/.ssh/config 配置不同用户的ssh连接方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">github user1@hotmail.com</span><br><span class="line">host github.com  <span class="comment">#别名，随便定 后面配置地址有用</span></span><br><span class="line">    Hostname github.com <span class="comment">#要连接的服务器</span></span><br><span class="line">    User user1 <span class="comment">#用户名</span></span><br><span class="line">    IdentityFile ~/.ssh/user1_id_rsa  <span class="comment">#密钥文件的地址，注意是私钥</span></span><br><span class="line"></span><br><span class="line">github user2@gmail.com</span><br><span class="line">host user2 <span class="comment">#别名，随便定</span></span><br><span class="line">    Hostname github.com</span><br><span class="line">    User user2</span><br><span class="line">    IdentityFile ~/.ssh/user2_id_rsa</span><br></pre></td></tr></table></figure><p>使用ssh的ssh-add命令将密钥添加到 ssh-agent 的高速缓存中，这样在当前会话中就不需要再次输入密码了 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> ssh-agent bash</span><br><span class="line">//A账户的私钥</span><br><span class="line">ssh-add ~/.ssh/user1_id_rsa</span><br><span class="line">//B账户的私钥</span><br><span class="line"> ssh-add ~/.ssh/user2_id_rsa</span><br></pre></td></tr></table></figure><p>配置完成后可以使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@user1</span><br><span class="line">会返回 Welcome to GitLab, @user1!</span><br></pre></td></tr></table></figure><p>来测试连接<br>每个git project 目录下面都有一个”.git/config”文件，里面配置了远程仓库的地址,<br>这时候，我们需要修改跟密钥对应的地址，上面在配置ssh时，为每个Hostname配置了一个host的别名，这时候，我们就不能使用原来的Hostname来提交了，要用别名来代替Hostname。</p><blockquote><p>url = git@<strong>github.com</strong>:user2/Sample.git<br>改成<br>url = git@<strong>user2</strong>:user2/Sample.git</p></blockquote><p>可以看到host起到了别名的作用，并且在不同的项目不同的账户可以配置自己的私钥方式，通过配置不同的xxx_id_rsa，达到互不影响的效果。</p><p>经过这样配置后，再git push时就会经过不同的公钥，私钥验证而互不影响了</p><h3 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h3><h4 id="1-生成密钥"><a href="#1-生成密钥" class="headerlink" title="1. 生成密钥"></a>1. 生成密钥</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C “yuanwenwu3@jd.com”</span><br></pre></td></tr></table></figure><h4 id="2-堡垒机配置-ssh-config"><a href="#2-堡垒机配置-ssh-config" class="headerlink" title="2.堡垒机配置~/.ssh/config"></a>2.堡垒机配置~/.ssh/config</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Host yuanwenwu3</span><br><span class="line">    HostName git.jd.com</span><br><span class="line">    User yuanwenwu3</span><br><span class="line">    IdentityFile /home/rec/yuanwenwu3/.ssh/id_rsa</span><br><span class="line">    IdentitiesOnly yes</span><br></pre></td></tr></table></figure><h4 id="3-堡垒机git项目下-git-config配置"><a href="#3-堡垒机git项目下-git-config配置" class="headerlink" title="3. 堡垒机git项目下.git/config配置"></a>3. 堡垒机git项目下.git/config配置</h4><p>注意下面<code>git@git.jd.com</code>被换成了<code>git@yuanwenwu3</code>，对应上面Host名称</p><p>```python<br>[core]<br>    repositoryformatversion = 0<br>    filemode = true<br>    bare = false<br>    logallrefupdates = true<br>[remote “origin”]<br>    url = git@yuanwenwu3:yuanwenwu3/dnn-convert-tfrecord.git<br>    fetch = +refs/heads/<em>:refs/remotes/origin/</em><br>[branch “master”]<br>    remote = origin<br>    merge = refs/heads/master<br>[user]<br>    name = yuanwenwu3<br>    email = yuanwenwu3@jd.com</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;新建（关联）远程分支&quot;&gt;&lt;a href=&quot;#新建（关联）远程分支&quot; class=&quot;headerlink&quot; title=&quot;新建（关联）远程分支&quot;&gt;&lt;/a&gt;新建（关联）远程分支&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;### Git global setup&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git config --&lt;span class=&quot;keyword&quot;&gt;global&lt;/span&gt; user.name &lt;span class=&quot;string&quot;&gt;&amp;quot;yuanwenwu3&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git config --&lt;span class=&quot;keyword&quot;&gt;global&lt;/span&gt; user.email &lt;span class=&quot;string&quot;&gt;&amp;quot;yuanwenwu3@jd.com&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;### Create a new repository&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git clone git@git.jd.com:yuanwenwu3/draw_tensorboard.git&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd draw_tensorboard&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;touch README.md&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git add README.md&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git commit -m &lt;span class=&quot;string&quot;&gt;&amp;quot;add README&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git push -u origin master&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;### Push an existing folder&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd existing_folder&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git init&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git remote add origin git@git.jd.com:yuanwenwu3/draw_tensorboard.git&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git add .&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git commit -m &lt;span class=&quot;string&quot;&gt;&amp;quot;Initial commit&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git push -u origin master&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;### Push an existing Git repository&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd existing_repo&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git remote rename origin old-origin&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git remote add origin git@git.jd.com:yuanwenwu3/draw_tensorboard.git&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git push -u origin --&lt;span class=&quot;built_in&quot;&gt;all&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git push -u origin --tags&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;### 迁移项目&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 新建一个空的repository, 例如地址为url-destination&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 在当前项目主分支上&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git remote add destination $&amp;#123;url-destination&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git push -u origin --&lt;span class=&quot;built_in&quot;&gt;all&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    
    <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
  </entry>
  
</feed>
